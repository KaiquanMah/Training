https://docs.microsoft.com/en-us/learn/modules/explore-analyze-data-with-python/2-exercise-explore-data




Terminal
To run a command as administrator (user "root"), use "sudo <command>".
See "man sudo_root" for details.
azureuser@compute123:/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute123/code$ cd Users

azureuser@compute123:/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute123/code/Users$ git clone https://github.com/microsoftdocs/ml-basics
Cloning into 'ml-basics'...
remote: Enumerating objects: 37, done.
remote: Counting objects: 100% (37/37), done.
remote: Compressing objects: 100% (34/34), done.
remote: Total 1923 (delta 14), reused 9 (delta 3), pack-reused 1886
Receiving objects: 100% (1923/1923), 8.27 MiB | 7.55 MiB/s, done.
Resolving deltas: 100% (713/713), done.
Checking connectivity... done.
Checking out files: 100% (1641/1641), done.










data = [50,50,47,97,49,3,53,42,26,74,82,62,37,15,70,27,36,35,48,52,63,64]
print(data)
[50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64]







#turn list of numbers into an n-dimenional array
import numpy as np

grades = np.array(data)
print(grades)

[50 50 47 97 49  3 53 42 26 74 82 62 37 15 70 27 36 35 48 52 63 64]








#check output if X2
#multiplying a list by 2 creates a new list of twice the length with the original sequence of list elements repeated.
print (type(data),'x 2:', data * 2)
print('---')
#Multiplying a NumPy array on the other hand performs an element-wise calculation in which the array behaves like a vector, so we end up with an array of the same size in which each element has been multiplied by 2.
print (type(grades),'x 2:', grades * 2)


<class 'list'> x 2: [50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64, 50, 50, 47, 97, 49, 3, 53, 42, 26, 74, 82, 62, 37, 15, 70, 27, 36, 35, 48, 52, 63, 64]
---
<class 'numpy.ndarray'> x 2: [100 100  94 194  98   6 106  84  52 148 164 124  74  30 140  54  72  70
  96 104 126 128]








#The shape confirms that this array has only one dimension, which contains 22 elements (there are 22 grades in the original list).
grades.shape
(22,)

#You can access the individual elements in the array by their zero-based ordinal position. Let's get the first element (the one in position 0).
grades[0]
50

grades.mean()
49.18181818181818















# Define an array of study hours
study_hours = [10.0,11.5,9.0,16.0,9.25,1.0,11.5,9.0,8.5,14.5,15.5,
               13.75,9.0,8.0,15.5,8.0,9.0,6.0,10.0,12.0,12.5,12.0]

# Create a 2D array (an array of arrays)
student_data = np.array([study_hours, grades])

# display the array
student_data
array([[10.  , 11.5 ,  9.  , 16.  ,  9.25,  1.  , 11.5 ,  9.  ,  8.5 ,
        14.5 , 15.5 , 13.75,  9.  ,  8.  , 15.5 ,  8.  ,  9.  ,  6.  ,
        10.  , 12.  , 12.5 , 12.  ],
       [50.  , 50.  , 47.  , 97.  , 49.  ,  3.  , 53.  , 42.  , 26.  ,
        74.  , 82.  , 62.  , 37.  , 15.  , 70.  , 27.  , 36.  , 35.  ,
        48.  , 52.  , 63.  , 64.  ]])
        
        
#Now the data consists of a 2-dimensional array - an array of arrays. Let's look at its shape.
# Show shape of 2D array
student_data.shape
(2, 22)




# Show the first element of the first element
student_data[0][0]
10.0

# Get the mean value of each sub-array
avg_study = student_data[0].mean()
avg_grade = student_data[1].mean()

print('Average study hours: {:.2f}\nAverage grade: {:.2f}'.format(avg_study, avg_grade))
Average study hours: 10.52
Average grade: 49.18




#dataframe
import pandas as pd

df_students = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic', 'Jimmie', 
                                     'Rhonda', 'Giovanni', 'Francesca', 'Rajab', 'Naiyana', 'Kian', 'Jenny',
                                     'Jakeem','Helena','Ismat','Anila','Skye','Daniel','Aisha'],
                            'StudyHours':student_data[0],
                            'Grade':student_data[1]})

df_students 

	Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0
5	Vicky	1.00	3.0
6	Frederic	11.50	53.0
7	Jimmie	9.00	42.0
8	Rhonda	8.50	26.0
9	Giovanni	14.50	74.0
10	Francesca	15.50	82.0
11	Rajab	13.75	62.0
12	Naiyana	9.00	37.0
13	Kian	8.00	15.0
14	Jenny	15.50	70.0
15	Jakeem	8.00	27.0
16	Helena	9.00	36.0
17	Ismat	6.00	35.0
18	Anila	10.00	48.0
19	Skye	12.00	52.0
20	Daniel	12.50	63.0
21	Aisha	12.00	64.0



# Get the data for index value 5
df_students.loc[5]

Name          Vicky
StudyHours        1
Grade             3
Name: 5, dtype: object


# Get the rows with index values from 0 to 5
df_students.loc[0:5]

	Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0
5	Vicky	1.00	3.0



#In addition to being able to use the **loc** method to find rows based on the index, you can use the **iloc** method to find rows based on their ordinal position in the DataFrame (regardless of the index):
# Get data in the first five rows
df_students.iloc[0:5]

Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0


#find the values for the columns in positions 1 and 2 in row 0:
df_students.iloc[0,[1,2]]

StudyHours    10
Grade         50
Name: 0, dtype: object


df_students.loc[0,'Grade']
50.0


#df_students.loc[df_students['Name']=='Aisha']
#df_students[df_students['Name']=='Aisha']
#df_students[df_students.Name == 'Aisha']
#df_students.query('Name=="Aisha"')
Name	StudyHours	Grade
21	Aisha	12.0	64.0






# Loading a DataFrame from a  file
df_students = pd.read_csv('data/grades.csv',delimiter=',',header='infer')
df_students.head()

	Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0





#Handling missing values
#which individual values are null
df_students.isnull()

	Name	StudyHours	Grade
0	False	False	False
1	False	False	False
2	False	False	False
3	False	False	False
4	False	False	False
5	False	False	False
6	False	False	False
7	False	False	False
8	False	False	False
9	False	False	False
10	False	False	False
11	False	False	False
12	False	False	False
13	False	False	False
14	False	False	False
15	False	False	False
16	False	False	False
17	False	False	False
18	False	False	False
19	False	False	False
20	False	False	False
21	False	False	False
22	False	False	True
23	False	True	True






#sum of missing values for each column
df_students.isnull().sum()

Name          0
StudyHours    1
Grade         2
dtype: int64


#So now we know that there's one missing StudyHours value, and two missing Grade values.
#To see them in context, we can filter the dataframe to include only rows where any of the columns (axis 1 of the DataFrame) are null.
df_students[df_students.isnull().any(axis=1)]
	
  Name	StudyHours	Grade
22	Bill	8.0	NaN
23	Ted	NaN	NaN

#When the DataFrame is retrieved, the missing numeric values show up as **NaN** (*not a number*).
#So now that we've found the null values, what can we do about them?
#One common approach is to *impute* replacement values. For example, if the number of study hours is missing, we could just assume that the student studied for an average amount of time and replace the missing value with the mean study hours. To do this, we can use the **fillna** method, like this:
df_students.StudyHours = df_students.StudyHours.fillna(df_students.StudyHours.mean())
df_students

	Name	StudyHours	Grade
0	Dan	10.000000	50.0
1	Joann	11.500000	50.0
2	Pedro	9.000000	47.0
3	Rosie	16.000000	97.0
4	Ethan	9.250000	49.0
5	Vicky	1.000000	3.0
6	Frederic	11.500000	53.0
7	Jimmie	9.000000	42.0
8	Rhonda	8.500000	26.0
9	Giovanni	14.500000	74.0
10	Francesca	15.500000	82.0
11	Rajab	13.750000	62.0
12	Naiyana	9.000000	37.0
13	Kian	8.000000	15.0
14	Jenny	15.500000	70.0
15	Jakeem	8.000000	27.0
16	Helena	9.000000	36.0
17	Ismat	6.000000	35.0
18	Anila	10.000000	48.0
19	Skye	12.000000	52.0
20	Daniel	12.500000	63.0
21	Aisha	12.000000	64.0
22	Bill	8.000000	NaN
23	Ted	10.413043	NaN







#Alternatively, it might be important to ensure that you only use data you know to be absolutely correct; so you can drop rows or columns that contains null values by using the dropna method. In this case, we'll remove rows (axis 0 of the DataFrame) where any of the columns contain null values.
df_students = df_students.dropna(axis=0, how='any')
df_students

	Name	StudyHours	Grade
0	Dan	10.00	50.0
1	Joann	11.50	50.0
2	Pedro	9.00	47.0
3	Rosie	16.00	97.0
4	Ethan	9.25	49.0
5	Vicky	1.00	3.0
6	Frederic	11.50	53.0
7	Jimmie	9.00	42.0
8	Rhonda	8.50	26.0
9	Giovanni	14.50	74.0
10	Francesca	15.50	82.0
11	Rajab	13.75	62.0
12	Naiyana	9.00	37.0
13	Kian	8.00	15.0
14	Jenny	15.50	70.0
15	Jakeem	8.00	27.0
16	Helena	9.00	36.0
17	Ismat	6.00	35.0
18	Anila	10.00	48.0
19	Skye	12.00	52.0
20	Daniel	12.50	63.0
21	Aisha	12.00	64.0








#Explore data in the DataFrame
#Now that we've cleaned up the missing values, we're ready to explore the data in the DataFrame. Let's start by comparing the mean study hours and grades.

# Get the mean study hours using the column name as an index
mean_study = df_students['StudyHours'].mean()

# Get the mean grade using the column name as a property (just to make the point!)
mean_grade = df_students.Grade.mean()

# Print the mean study hours and mean grade
print('Average weekly study hours: {:.2f}\nAverage grade: {:.2f}'.format(mean_study, mean_grade))
Average weekly study hours: 10.52
Average grade: 49.18




#students who studied for more than the average amount of time.
# Get students who studied for the mean or more hours
df_students[df_students.StudyHours > mean_study]


Name	StudyHours	Grade
1	Joann	11.50	50.0
3	Rosie	16.00	97.0
6	Frederic	11.50	53.0
9	Giovanni	14.50	74.0
10	Francesca	15.50	82.0
11	Rajab	13.75	62.0
14	Jenny	15.50	70.0
19	Skye	12.00	52.0
20	Daniel	12.50	63.0
21	Aisha	12.00	64.0

