Regularizing models with Twitter data
You will work with the Twitter data expressing customers' sentiment about airline companies. The X matrix of features and y vector of labels have been created for you. In addition, the training and testing split has been performed. You can work with the X_train, X_test, y_train and y_test arrays directly.
You will train regularized and a more flexible models and evaluate them using different model performance metrics.
All required packages have been imported for you.

Train two logistic regressions: one with regularization parameter of 100 and a second of 0.1.
Print the accuracy scores of both models.
Print the confusion matrix of each model.

# Build a logistic regression with regularizarion parameter of 100
log_reg1 = LogisticRegression(C=100).fit(X_train, y_train)
# Build a logistic regression with regularizarion parameter of 0.1
log_reg2 = LogisticRegression(C=0.1).fit(X_train, y_train)

# Predict the labels for each model
y_predict1 = log_reg1.predict(X_test)
y_predict2 = log_reg2.predict(X_test)

# Print performance metrics for each model
print('Accuracy of model 1: ', accuracy_score(y_test, y_predict1))
print('Accuracy of model 2: ', accuracy_score(y_test, y_predict2))
print('Confusion matrix of model 1: \n' , confusion_matrix(y_test, y_predict1)/len(y_test))
print('Confusion matrix of model 2: \n', confusion_matrix(y_test, y_predict2)/len(y_test))


<script.py> output:
    Accuracy of model 1:  0.8310580204778157
    Accuracy of model 2:  0.810580204778157
    
    Confusion matrix of model 1: 
     [[0.56484642 0.05631399 0.00682594]
     [0.01023891 0.17235495 0.02389078]
     [0.01706485 0.05460751 0.09385666]]
     
         Confusion matrix of model 2: 
     [[0.60068259 0.02559727 0.00170648]
     [0.06313993 0.12627986 0.01706485]
     [0.03754266 0.0443686  0.08361775]]
     
     
You have trained a more and less flexible logistic regressions to predict the sentiment of tweets and evaluated them using different performance metrics. In this case, we again sacrificed some accuracy when we imposed regularizarion.

     
