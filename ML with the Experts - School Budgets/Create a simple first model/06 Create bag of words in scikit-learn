#In this exercise, you'll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns.
#You will focus on one feature only, the Position_Extra column, which describes any additional information not captured by the Position_Type label.
#For example, in the Shell you can check out the budget item in row 8960 of the data using df.loc[8960]. Looking at the output reveals that this Object_Description is overtime pay. For who? The Position Type is merely "other", but the Position Extra elaborates: "BUS DRIVER". Explore the column further to see more instances. It has a lot of NaN values.
#Your task is to turn the raw text in this column into a bag-of-words representation by creating tokens that contain only alphanumeric characters.
#For comparison purposes, the first 15 tokens of vec_basic, which splits df.Position_Extra into tokens when it encounters only whitespace characters, have been printed along with the length of the representation.

#There are 135 tokens in Position_Extra if tokens are any non-whitespace
['&', '(no', '-', '1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'art', 'assessment']


df.loc[8960]
#Function                                         Student Transportation
Use                                                                 O&M
Sharing                                                 Shared Services
Reporting                                                    Non-School
Student_Type                                                Unspecified
Position_Type                                                     Other
Object_Type                                  Other Compensation/Stipend
Pre_K                                                          Non PreK
Operating_Status                                      PreK-12 Operating
Object_Description        Extra Duty Pay/Overtime For Support Personnel
Text_2                                                              NaN
SubFund_Description                                          Operations
Job_Title_Description                     TRANSPORTATION,BUS DR., RADIO
Text_3                                                              NaN
Text_4                                     transportation - Second Runs
Sub_Object_Description    Extra Duty Pay/Overtime For Support Personnel
Location_Description                                        Unallocated
FTE                                                                 NaN
Function_Description                                     Transportation
Facility_or_Department                        Transportation Department
Position_Extra                                               BUS DRIVER
Total                                                           1752.45
Program_Description                                       Undistributed
Fund_Description                                 General Operating Fund
Text_1                                                    EXTENDED DAYS
Name: 8960, dtype: object


# Import CountVectorizer
#Import CountVectorizer from sklearn.feature_extraction.text
from sklearn.feature_extraction.text import CountVectorizer

# Create the token pattern: TOKENS_ALPHANUMERIC
TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\s+)'

#Fill missing values in df.Position_Extra using .fillna('') to replace NaNs with empty strings. Specify the additional keyword argument inplace=True so that you don't have to assign the result back to df.
# Fill missing values in df.Position_Extra
df.Position_Extra.fillna('', inplace=True)

#Instantiate the CountVectorizer as vec_alphanumeric by specifying the token_pattern to be TOKENS_ALPHANUMERIC.
# Instantiate the CountVectorizer: vec_alphanumeric
vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)

#Fit vec_alphanumeric to df.Position_Extra.
# Fit to the data
vec_alphanumeric.fit(df.Position_Extra)

#see the len of the fitted representation as well as the first 15 elements, and compare to vec_basic.
# Print the number of tokens and first 15 tokens
msg = "There are {} tokens in Position_Extra if we split on non-alpha numeric"
print(msg.format(len(vec_alphanumeric.get_feature_names())))
print(vec_alphanumeric.get_feature_names()[:15])


#Great work! Treating only alpha-numeric characters as tokens gives you a smaller number of more meaningful tokens. You've got bag-of-words in the bag!

