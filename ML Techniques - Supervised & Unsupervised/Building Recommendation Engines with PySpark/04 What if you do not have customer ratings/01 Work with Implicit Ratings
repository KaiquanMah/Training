MSD summary statistics
Let's get familiar with the Million Songs Echo Nest Taste Profile data subset. For purposes of this course, we'll just call it the Million Songs dataset or msd. Let's get the number of users and the number of songs. Let's also see which songs have the most plays from this subset.
#additional readings
#https://labrosa.ee.columbia.edu/
#https://www.ee.columbia.edu/~dpwe/
#http://millionsongdataset.com/


# Look at the data
msd.show()


+------+------+---------+
|userId|songId|num_plays|
+------+------+---------+
|   148|   148|        0|
|   243|   496|        0|
|    31|   471|        0|
|   137|   463|        0|
|   251|   623|        0|
|    85|   392|        0|
|    65|   540|        0|
|   255|   243|        0|
|    53|   516|        0|
|   133|    31|        0|
|   296|    85|        0|
|    78|   451|        0|
|   108|   580|        0|
|   155|   137|        0|
|   193|   251|        0|
|   211|    65|        0|
|    34|   458|        0|
|   115|    53|        0|
|   126|   255|        0|
|   101|   588|        0|
+------+------+---------+
only showing top 20 rows




# Count the number of distinct userIds
user_count = msd.select("userId").distinct().count()
print("Number of users: ", user_count)

# Count the number of distinct songIds
song_count = msd.select("songId").distinct().count()
print("Number of songs: ", song_count)
    Number of users:  321
    Number of songs:  729















Grouped summary statistics
In this exercise, we are going to combine the .groupBy() and .filter() methods that you've used previously to calculate the min() and avg() number of users that have rated each song, and the min() and avg() number of songs that each user has rated.

Because our data now includes 0's for items not yet consumed, we'll need to .filter() them out when doing grouped summary statistics like this. The msd dataset is provided for you here. The col(), min(), and avg() functions from pyspark.sql.functions have been imported for you.


# Min num implicit ratings for a song
print("Minimum implicit ratings for a song: ")
msd.filter(col("num_plays") > 0).groupBy("songId").count().select(min("count")).show()

# Avg num implicit ratings per songs
print("Average implicit ratings per song: ")
msd.filter(col("num_plays") > 0).groupBy("songId").count().select(avg("count")).show()

# Min num implicit ratings from a user
print("Minimum implicit ratings from a user: ")
msd.filter(col("num_plays") > 0).groupBy("userId").count().select(min("count")).show()

# Avg num implicit ratings for users
print("Average implicit ratings per user: ")
msd.filter(col("num_plays") > 0).groupBy("userId").count().select(avg("count")).show()


    Minimum implicit ratings for a song: 
    +----------+
    |min(count)|
    +----------+
    |         3|
    +----------+
    
    Average implicit ratings per song: 
    +------------------+
    |        avg(count)|
    +------------------+
    |35.251063829787235|
    +------------------+
    
    Minimum implicit ratings from a user: 
    +----------+
    |min(count)|
    +----------+
    |        21|
    +----------+
    
    Average implicit ratings per user: 
    +-----------------+
    |       avg(count)|
    +-----------------+
    |77.42056074766356|
    +-----------------+

Users have at least 21 implicit ratings with an average of 77 and each song has at least 3 implicit ratings with an average of 35.













Add Zeros
Many recommendation engines use implicit ratings. In many cases these datasets don't include behavior counts for items that a user has never purchased. In these cases, you'll need to add them and include zeros. The dataframe Z is provided for you. It contains userId's, productId's and num_purchases which is the number of times a user has purchased a specific product.

# View the data
Z.show()

+------+---------+-------------+
|userId|productId|num_purchases|
+------+---------+-------------+
|  2112|      777|            1|
|     7|       44|           23|
|  1132|      227|            9|
|   686|     1981|            2|
|    42|     2390|            5|
|    13|     1662|           21|
|  2112|     1492|            8|
|    22|     1811|           96|
+------+---------+-------------+



# Extract distinct userIds and productIds
users = Z.select("userId").distinct()
products = Z.select("productId").distinct()

# Cross join users and products
cj = users.crossJoin(products)


+------+---------+
|userId|productId|
+------+---------+
|    22|       44|
|    22|      777|
|    22|     1811|
|    22|      227|
|    22|     1662|
|    22|     1492|
|    22|     2390|
|    22|     1981|
|   686|       44|
|   686|      777|
|   686|     1811|
|   686|      227|
|   686|     1662|
|   686|     1492|
|   686|     2390|
|   686|     1981|
|    13|       44|
|    13|      777|
|    13|     1811|
|    13|      227|
+------+---------+
only showing top 20 rows





# Join cj and Z
Z_expanded = cj.join(Z, ["userId", "productId"], "left").fillna(0)

# View Z_expanded
Z_expanded.show()

    +------+---------+-------------+
    |userId|productId|num_purchases|
    +------+---------+-------------+
    |    22|       44|            0|
    |    22|      777|            0|
    |    22|     1811|           96|
    |    22|      227|            0|
    |    22|     1662|            0|
    |    22|     1492|            0|
    |    22|     2390|            0|
    |    22|     1981|            0|
    |   686|       44|            0|
    |   686|      777|            0|
    |   686|     1811|            0|
    |   686|      227|            0|
    |   686|     1662|            0|
    |   686|     1492|            0|
    |   686|     2390|            0|
    |   686|     1981|            2|
    |    13|       44|            0|
    |    13|      777|            0|
    |    13|     1811|            0|
    |    13|      227|            0|
    +------+---------+-------------+
    only showing top 20 rows
Notice how the dataset expanded significantly as a result of adding zeros.




