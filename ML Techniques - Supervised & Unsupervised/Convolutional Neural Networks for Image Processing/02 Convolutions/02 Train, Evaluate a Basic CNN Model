Convolutional network for image classification
Convolutional networks for classification are constructed from a sequence of convolutional layers (for image processing) and fully connected (Dense) layers (for readout). In this exercise, you will construct a small convolutional network for classification of the data from the fashion dataset.

# Import the necessary components from Keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten

# Initialize the model object
model = Sequential()


#Add a Conv2D layer to construct the input layer of the network. Use a kernel size of 3 by 3. You can use the img_rows and img_cols objects available in your workspace to define the input_shape of this layer.
# Add a convolutional layer
model.add(Conv2D(10, kernel_size=3, activation='relu', 
               input_shape=(img_rows,img_cols,1)))

# Flatten the output of the convolutional layer
model.add(Flatten())
# Add an output layer for the 3 categories
model.add(Dense(3, activation='softmax'))

You just built a model with one convolutional layer.










Training a CNN to classify clothing types
Before training a neural network it needs to be compiled with the right cost function, using the right optimizer. During compilation, you can also define metrics that the network calculates and reports in every epoch. Model fitting requires a training data set, together with the training labels to the network.

The Conv2D model you built in the previous exercise is available in your workspace.

#Compile the network using the 'adam' optimizer and the 'categorical_crossentropy' cost function. In the metrics list define that the network to report 'accuracy'.
# Compile the model 
model.compile(optimizer='adam', 
              loss='categorical_crossentropy', 
              metrics=['accuracy'])


#Fit the network on train_data and train_labels. Train for 3 epochs with a batch size of 10 images. In training, set aside 20% of the data as a validation set, using the validation_split keyword argument.
# Fit the model on a training set
model.fit(train_data, train_labels, 
          validation_split=0.2, 
          epochs=3, batch_size=10)
          
          
    Train on 40 samples, validate on 10 samples
    Epoch 1/3
    
    10/40 [======>.......................] - ETA: 0s - loss: 1.1084 - acc: 0.3000
    40/40 [==============================] - 0s 7ms/step - loss: 0.9589 - acc: 0.4750 - val_loss: 0.6300 - val_acc: 0.9000
    Epoch 2/3
    
    10/40 [======>.......................] - ETA: 0s - loss: 0.7656 - acc: 0.9000
    40/40 [==============================] - 0s 669us/step - loss: 0.6735 - acc: 0.8500 - val_loss: 0.4516 - val_acc: 1.0000
    Epoch 3/3
    
    10/40 [======>.......................] - ETA: 0s - loss: 0.5395 - acc: 1.0000
    40/40 [==============================] - 0s 699us/step - loss: 0.4356 - acc: 0.9750 - val_loss: 0.3765 - val_acc: 1.0000
    
    Validation accuracy converges to 100%!








Evaluating a CNN with test data
To evaluate a trained neural network, you should provide a separate testing data set of labeled images. The model you fit in the previous exercise is available in your workspace.

    
    
#Use the same batch size that was used for fitting (10 images per batch).
# Evaluate the model on separate test data
model.evaluate(test_data,test_labels,batch_size=10)    
    <script.py> output:
    
    10/10 [==============================] - 0s 191us/step
The first number in the output is the value of the cross-entropy loss, the second is the value of the accuracy. For this model, it's 100%!


    
          
          
