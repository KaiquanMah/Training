When you call fit with scikit-learn, the logistic regression coefficients are automatically learned from your dataset. In this exercise you will explore how the decision boundary is represented by the coefficients. To do so, you will change the coefficients manually (instead of with fit), and visualize the resulting classifiers.

A 2D dataset is already loaded into the environment as X and y, along with a linear classifier object model.



plt.clf()
# Set the coefficients
model.coef_ = np.array([[1,1]])
model.intercept_ = np.array([0])

# Plot the data and decision boundary
plot_classifier(X,y,model)
# Print the number of errors
num_err = np.sum(y != model.predict(X))
print("Number of errors:", num_err)



#[intercept, slope]
model.coef_ = np.array([[1,1]])
#shift down "y-axis boundary" by -1 if 1 below; -2 if 2 below
model.intercept_ = np.array([0])


Great job! As you've been experiencing, the coefficients determine the slope of the boundary and the intercept shifts it.

