It can significantly affect prediction results, as shown by the difference between the recall and accuracy scores. To solve the imbalance, equal weights are usually given to each class. Using the class_weight argument in sklearn's DecisionTreeClassifier, one can make the classes become "balanced".

Let’s correct our model by solving its imbalance problem:
first, you’re going to set up a model with balanced classes
then, you will fit it to the training data
finally, you will check its accuracy on the test set

The variables features_train, target_train,featurestestandtargettest` are already available in your workspace.



# Initialize the DecisionTreeClassifier 
model_depth_5_b = DecisionTreeClassifier(max_depth==5,class_weight="balanced",random_state=42)

# Fit the model
model_depth_5_b.fit(features_train,target_train)

# Print the accuracy of the prediction (in percentage points) for the test set
print(model_depth_5_b.score(features_test,prediction)*100)
