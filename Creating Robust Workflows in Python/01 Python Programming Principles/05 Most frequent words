Most frequent words
In the previous exercise, we created a list of words called filtered_words.
Now we will define a count_words() function to turn the word list into a dictionary of words and word counts.
To accomplish this, we will use a dictionary comprehension.
Dictionary comprehensions create key-value pairs from an iterable.
In this case, the iterable is the word list, the dictionary keys are words, and the values are the word counts.


After we create the dictionary, we will use turn it into a pandas DataFrame, so that we can use a series of methods to
sort the word counts
obtain the top 5 most frequent words
create a horizontal bar plot
remove the y axis label
The bar plot will show the frequency of the top words in the diabetes dataset.






Complete the dictionary comprehension inside the count_words() function definition.
Create the dictionary of words and word counts from the filtered_words variable that we created in the previous exercise.



def count_words(word_list):
    # Count the words in the input list
    return {word: word_list.count(word) for word in word_list}

# Create the dictionary of words and word counts
word_count_dictionary = count_words(filtered_words)

(pd.DataFrame(word_count_dictionary.items())
 .sort_values(by=1, ascending=False)
 .head()
 .plot(x=0, kind="barh", xticks=range(5), legend=False)
 .set_ylabel("")
)
plt.show()









In [2]: filtered_words
Out[2]: 
['diabetes',
 'dataset',
 'diabetes',
 'dataset',
 'baseline',
 'variables',
 'body',
 'mass',
 'index',
 'average',
 'blood',
 'pressure',
 'blood',
 'serum',
 'measurements',
 'were',
 'obtained',
 'each',
 'diabetes',
 'patients',
 'well',
 'response',
 'interest',
 'quantitative',
 'measure',
 'disease',
 'progression',
 'year',
 'after',
 'baseline',
 'data',
 'characteristics',
 'number',
 'instances',
 'number',
 'attributes',
 'first',
 'columns',
 'numeric',
 'predictive',
 'values',
 'target',
 'column',
 'quantitative',
 'measure',
 'disease',
 'progression',
 'year',
 'after',
 'baseline',
 'attribute',
 'information',
 'body',
 'mass',
 'index',
 'average',
 'blood',
 'pressure',
 'note',
 'each',
 'these',
 'feature',
 'variables',
 'have',
 'been',
 'mean',
 'centered',
 'scaled',
 'standard',
 'deviation',
 'times',
 'samples',
 'squares',
 'each',
 'column',
 'totals',
 'source',
 'https',
 'stat',
 'ncsu',
 'boos',
 'select',
 'diabetes',
 'html',
 'more',
 'information',
 'bradley',
 'efron',
 'trevor',
 'hastie',
 'iain',
 'johnstone',
 'robert',
 'tibshirani',
 'least',
 'angle',
 'regression',
 'annals',
 'statistics',
 'with',
 'discussion',
 'https',
 'stanford',
 'hastie',
 'papers',
 'lars',
 'leastangle']
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 In [2]: word_count_dictionary
Out[2]: 
{'diabetes': 4,
 'dataset': 2,
 'baseline': 3,
 'variables': 2,
 'body': 2,
 'mass': 2,
 'index': 2,
 'average': 2,
 'blood': 3,
 'pressure': 2,
 'serum': 1,
 'measurements': 1,
 'were': 1,
 'obtained': 1,
 'each': 3,
 'patients': 1,
 'well': 1,
 'response': 1,
 'interest': 1,
 'quantitative': 2,
 'measure': 2,
 'disease': 2,
 'progression': 2,
 'year': 2,
 'after': 2,
 'data': 1,
 'characteristics': 1,
 'number': 2,
 'instances': 1,
 'attributes': 1,
 'first': 1,
 'columns': 1,
 'numeric': 1,
 'predictive': 1,
 'values': 1,
 'target': 1,
 'column': 2,
 'attribute': 1,
 'information': 2,
 'note': 1,
 'these': 1,
 'feature': 1,
 'have': 1,
 'been': 1,
 'mean': 1,
 'centered': 1,
 'scaled': 1,
 'standard': 1,
 'deviation': 1,
 'times': 1,
 'samples': 1,
 'squares': 1,
 'totals': 1,
 'source': 1,
 'https': 2,
 'stat': 1,
 'ncsu': 1,
 'boos': 1,
 'select': 1,
 'html': 1,
 'more': 1,
 'bradley': 1,
 'efron': 1,
 'trevor': 1,
 'hastie': 2,
 'iain': 1,
 'johnstone': 1,
 'robert': 1,
 'tibshirani': 1,
 'least': 1,
 'angle': 1,
 'regression': 1,
 'annals': 1,
 'statistics': 1,
 'with': 1,
 'discussion': 1,
 'stanford': 1,
 'papers': 1,
 'lars': 1,
 'leastangle': 1}
 
 
 
 
 
 
 
 
 
 
 
 Wonderful word-ranking! We now have several independent, reusable functions at our disposal. In this coding exercise, we used a dictionary comprehension to link words with their counts and then sorted the words we obtained by their frequency. In the next video, we will learn about the last principle covered in this chapter.



