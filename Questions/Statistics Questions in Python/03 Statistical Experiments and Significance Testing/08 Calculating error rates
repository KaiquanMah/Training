Calculating error rates
We talked a bit about the multiple comparisons problem in the slides, but let's take things a step further. In this exercise, you'll look into how the phenomenon affects error rate more precisely.
Your colleague is strongly considering running 60 distinct hypothesis tests. In order to convince them otherwise, compute the probability of a Type I error for 60 hypothesis tests with a single-test 5% significance level.


Compute and print the probability of your colleague getting a Type I error.
# Print error rate for 60 tests with 5% significance
error_rate = 1 - (.95**(60))
print(error_rate)

<script.py> output:
    0.953930201013048
    
    

You successfully talked them down to 30 tests; adapt your code to compute and print the new error rate.
# Print error rate for 30 tests with 5% significance
error_rate = 1 - (.95**(30))
print(error_rate)

<script.py> output:
    0.7853612360570628
    


One last try; adapt your code to compute and print the error rate for 10 tests.
# Print error rate for 10 tests with 5% significance
error_rate = 1 - (.95**(10))
print(error_rate)

<script.py> output:
    0.4012630607616213

As you can see, the probability of encountering an error is still extremely high. This is where the Bonferroni correction comes in. While a bit conservative, it controls the family-wise error rate for circumstances like these to avoid the high probability of a Type I error. We'll go over this specific method in the next exercise!

