Imbalanced class metrics
Class imbalance is something that can hamper your model's performance in any machine learning context. This is especially relevant in a machine learning interview if you are asked what to do if you are given a dataset with an imbalanced class, as some data is imbalanced by design such as insurance fraud data.
In this exercise you'll use sklearn to create a logistic regression model and print the confusion matrix along with several evaluation metrics to get a better understanding of how to interpret Machine Learning models from datasets that have a class imbalance.
Recall the class imbalance you saw previously in loan_data. The number of observations with Loan Status of Fully Paid far outweighs those that are Charged Off.



Import the necessary modules to create a logistic regression model as well as confusion matrix, accuracy, precision, recall, and F1-scores.# Import
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score





Instantiate a logistic regression object, fit and predict.
# Instantiate, fit, predict
lr = LogisticRegression(solver='liblinear')
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)





Print the confusion matrix and accuracy score.
# Print evaluation metrics
print("Confusion matrix:\n {}".format(confusion_matrix(y_test, y_pred)))
print("Accuracy: {}".format(accuracy_score(y_test, y_pred)))

<script.py> output:
    Confusion matrix:
     [[  367  3868]
     [  318 10447]]
    Accuracy: 0.7209333333333333
    
    
    


Print the precision, recall, and F1-scores.
print("Precision: {}".format(precision_score(y_test, y_pred)))
print("Recall: {}".format(recall_score(y_test, y_pred)))
print("F1: {}".format(f1_score(y_test, y_pred)))

    Precision: 0.7297939224589591
    Recall: 0.9704598235020901
    F1: 0.8330940988835726
    
Nice job! The metrics aren't actually too bad. Precision of 0.72 means there might be a high number of false positives than you really want to see. Let's see if you can improve them in the next exercise with some resampling techniques!

    
