Random forest ensemble
Questions about ensemble models are common in a machine learning interview. If you're provided with a dataset and asked to build a highly accurate model, you will likely want to consider these more complex models.
Your challenge in the remainder of this last lesson in the course is to create and compare two different ensemble models for loan_data.
In this exercise, you will create a Random Forest Classifier model and compare its performance metrics to the model in the next exercise.
The data has already been split is available in your workspace as X_train, X_test, y_train, and y_test.





Import the modules to create a Random Forest model and create a confusion matrix, accuracy, precision, recall, and F1-scores.
Instantiate a RF classifier and set the appropriate argument to generate 50 estimators.
# Import
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

# Instantiate
rf_model = RandomForestClassifier(n_estimators=50, random_state=123, oob_score = True)







Fit the data to the instantiated Random Forest Classifier model object.
rf_model = rf_model.fit(X_train, y_train)



Create predictions using the trained model object.
rf_pred = rf_model.predict(X_test)



Evaluate the model fit.
# Print evaluation metrics
print("Random Forest Accuracy: {}".format(accuracy_score(y_test, rf_pred)))
print("Confusion matrix:\n {}".format(confusion_matrix(y_test, rf_pred)))
print("Precision: {}".format(precision_score(y_test, rf_pred)))
print("Recall: {}".format(recall_score(y_test, rf_pred)))
print("F1: {}".format(f1_score(y_test, rf_pred)))



<script.py> output:
    Random Forest Accuracy: 0.7250777940239194
    Confusion matrix:
     [[ 1923  5629]
     [ 1704 17417]]
    Precision: 0.7557493708235703
    Recall: 0.9108833220019873
    F1: 0.8260962363933881
    
    
    Amazing! Now you'll compare these metrics to a Gradient Boosting model in the next exercise!


    
