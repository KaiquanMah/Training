Training vs test set distributions and transformations
If the distribution of test data (not yet seen by the model) is significantly different than the distribution of the training data, what problems can occur? What transformations can be applied to data before passing them to an ML model and why should these transformations be performed?

Select the answer that is false:
If the test data has a different distribution than the training data used to build a model it will likely cause poor performance.
The Box-cox function transforms the data depending on the value of the lmbda keyword argument.
Log transform can normalize a feature which demonstrates a non-Gaussian distribution.

#yes - If the data used to train a model is only slightly different than test or future data, it won't matter and you can go ahead with model tuning.
Nice job! It's impossible to tell before passing data through a series of models which will be impacted by different distributions. Save time and ensure distribution similarity!

