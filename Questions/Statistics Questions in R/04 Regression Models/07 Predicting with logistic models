Predicting with logistic models
The logistic regression model computes the probabilities that the given observation belongs to one of the classes.
The logistic model with two explanatory variables has the following form:
1/ [1 + e^−(β0 + β1⋅x1 + β2⋅x2)]


The R functions do the hard work for the users, but knowing the mechanics behind them will give you confidence in their correct application during the interview.
In the previous exercise, you've used the parkinsons dataset and fitted the logistic regression model. These two objects and the new_person data frame are available in your environment.






Print data for the new_person.
Print the logistic regression model.
# Print the new person's data
print(new_person)

  NHR DFA
1 0.2 0.6




# Print the logistic model
print(model)

Call:  glm(formula = status ~ NHR + DFA, family = "binomial", data = parkinsons)

Coefficients:
(Intercept)          NHR          DFA  
     -8.707       49.188       12.702  

Degrees of Freedom: 194 Total (i.e. Null);  192 Residual
Null Deviance:	    217.6 
Residual Deviance: 187.7 	AIC: 193.7













Compute by hand the probability that the new_person has Parkinson's disease. Use three decimal places for the parameters.
Print the probability.
# Calculate the probability
probability <- 1 / (1 + exp(-(-8.707 + 49.188 * 0.2 + 12.702 * 0.6)))

# Print the probability
print(probability)

[1] 0.9998418








Compute the probability that the new_person has Parkinson's disease using a function.
# Predict the probability for the new person
predict(model, 
        newdata = new_person, 
        type = "response")

        1 
0.9998419


Excellent! The probability that the new_person has Parkinson's disease is greater than 99%. We would predict that this person does have Parkinson's. Logistic regression models are widely used in practice, so your skill will be a valuable asset for your future employer. In the next lesson, we will review model evaluation!

