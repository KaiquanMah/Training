#part 1
#What are word vectors?
#What are word vectors and how do they help with NLP?
Word vectors are multi-dimensional mathematical representations of words created using deep learning methods. They give us insight into relationships between words in a corpus.


#part 2
#Creating and querying a corpus with gensim
#It's time to apply the methods you learned in the previous video to create your first gensim dictionary and corpus!
#You'll use these data structures to investigate word trends and potential interesting topics in your document set. To get started, we have imported a few additional messy articles from Wikipedia, which were preprocessed by lowercasing all words, tokenizing them, and removing stop words and punctuation. These were then stored in a list of document tokens called articles. You'll need to do some light preprocessing and then generate the gensim dictionary and corpus.


# Import Dictionary from gensim.corpora.dictionary.
from gensim.corpora.dictionary import Dictionary

#Initialize a gensim Dictionary with the tokens in articles.
# Create a Dictionary from the articles: dictionary
dictionary = Dictionary(articles)


#Obtain the id for "computer" from dictionary. To do this, use its .token2id method which returns ids from text, and then chain which returns tokens from ids. Pass in "computer" as an argument to .get().
# Select the id for "computer": computer_id
computer_id = dictionary.token2id.get("computer")
#pass in token to get id
#219


# Use computer_id with the dictionary to print the word
print(dictionary.get(computer_id))
#pass in id to get token
#computer


#Use a list comprehension in which you iterate over articles to create a gensim MmCorpus from dictionary.
# Create a MmCorpus: corpus
corpus = [dictionary.doc2bow(article) for article in articles]

# Print the first 10 word ids with their frequency counts from the fifth document
print(corpus[4][:10])
