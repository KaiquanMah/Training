{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel and marginal modeling, a case study with the NHANES data\n",
    "\n",
    "\n",
    "This notebook is a counterpart to our introductory regression modeling\n",
    "case study for **independent data** using the NHANES data.  Here we will\n",
    "build on the basic **linear and logistic regression** approaches discussed\n",
    "in that notebook.  \n",
    "\n",
    "Then we will be exploring\n",
    "the use of some more **advanced regression approaches** that can be used\n",
    "**for data that are statistically dependent**.\n",
    "\n",
    "We begin by importing the libraries that we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can be *dependent*, or have a *mutilevel structure* for many\n",
    "reasons.  In practice, most datasets exhibit some form of dependence,\n",
    "and it is arguably independent data, not dependent data, that should\n",
    "be treated as the exceptional case. Here we will reconsider the NHANES\n",
    "data from the perspective of dependence, focusing in particular on\n",
    "**dependence in the data that arises due to clustering** which we will\n",
    "define below.\n",
    "\n",
    "First, we read in the data, as we have done before.  For simplicity,\n",
    "we remove all rows of data with missing values in the variables of\n",
    "interest (note that there are more sophisticated approaches for\n",
    "handling missing data that generally will give better results, but for\n",
    "simplicity we do not use them here).\n",
    "\n",
    "Note that we retain two variables here\n",
    "[SDMVSTRA](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#SDMVSTRA)\n",
    "and\n",
    "[SDMVPSU](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#SDMVPSU)\n",
    "that will be used below to define the clustering structure in these\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file\n",
    "da = pd.read_csv(\"nhanes_2015_2016.csv\")\n",
    "\n",
    "# Drop unused columns, drop rows with any missing values.\n",
    "vars = [\"BPXSY1\", \"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"BMXBMI\",\n",
    "        \"SMQ020\", \"SDMVSTRA\", \"SDMVPSU\"]\n",
    "da = da[vars].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to clustered data\n",
    "\n",
    "One common reason that data are dependent is that the data values were\n",
    "collected in clusters.  This essentially means that the population was\n",
    "partitioned into groups, a **limited number of these groups** were somehow\n",
    "selected, and then a **limited number of individuals were selected from\n",
    "each of the selected groups**.  In a proper survey, there is a\n",
    "well-planned design, in which both the groups, and the individuals\n",
    "within groups, are selected randomly.  The goal in doing this is to\n",
    "maximize the chances that the sample is representative of the\n",
    "population of interest in all relevant ways.  But many other data sets\n",
    "exhibit clustering structure, even when the data collection was not so\n",
    "carefully planned.\n",
    "\n",
    "Regardless of how the clustering in the sample arose, it is likely to\n",
    "be the case that observations within a cluster are more similar to\n",
    "observations in different clusters.  To make this concrete, note that\n",
    "clustering is often geographic.  Data may be collected by visiting\n",
    "several locations, then recruiting participants within each location.\n",
    "People within a location may share similarities, for example in\n",
    "demography and lifestyle, or they may share environmental\n",
    "circumstances such as climate.  When we have clustered data, it is\n",
    "usually advisable to account for this in the analysis.\n",
    "\n",
    "## Clustering structure in NHANES\n",
    "\n",
    "The detailed process of collecting data for a study like NHANES is\n",
    "very complex, so we will simplify things substantially here (more\n",
    "details can be found\n",
    "[here](https://wwwn.cdc.gov/nchs/nhanes/analyticguidelines.aspx) but\n",
    "are not needed for this course). Roughly speaking, in NHANES the data\n",
    "are collected by **selecting a limited number of counties in the U**,\n",
    "then **selecting subregions of these counties**, then **selecting people\n",
    "within these subregions**.  Since counties are geographically\n",
    "constrained, it is expected that people within a county are more\n",
    "similar to each other than they are to people in other counties.\n",
    "\n",
    "If we could obtain the county id where each NHANES participant\n",
    "resides, we could directly study this clustering structure.  However\n",
    "for privacy reasons this information is not released with the data.\n",
    "Instead, we have access to **\"masked variance units\" (MVUs), which are\n",
    "formed by combining subregions of different counties into artificial\n",
    "groups that are not geographically contiguous**.  While the MVUs are not\n",
    "the actual clusters of the survey, and are not truly contiguous\n",
    "geographic regions, they are deliberately selected to mimic these\n",
    "things, while **minimizing the risk that a subject can be \"unmasked\" in\n",
    "the data.**  For the remainder of this notebook, we will treat the MVUs\n",
    "as clusters, and explore the extent to which they induce correlations\n",
    "in some of the NHANES variables that we have been studying.\n",
    "\n",
    "The MVU identifiers can be obtained by combining the `SDMVSTRA` and\n",
    "`SDMVPSU` identifiers, which we do next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "da[\"group\"] = 10*da.SDMVSTRA + da.SDMVPSU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intraclass correlation\n",
    "\n",
    "Similarity among observations within a cluster can be measured using a\n",
    "statistic called the **intraclass correlation**, or ICC.  This is a\n",
    "distinct form of correlation from Pearson's correlation.  The ICC\n",
    "**takes on values from 0 to 1, with 1 corresponding to \"perfect\n",
    "clustering\"** -- the values within a cluster are identical, and **0\n",
    "corresponding to \"perfect independence\" -- the mean value within each\n",
    "cluster is identical across all the clusters.**\n",
    "\n",
    "We can assess ICC using two regression techniques, *marginal\n",
    "regression*, and *multilevel regression*.  We will start by using a\n",
    "technique called \"Generalized Estimating Equations\" (GEE) to fit\n",
    "marginal linear models, and to estimate the ICC for the NHANES\n",
    "clusters.\n",
    "\n",
    "We will first look at the ICC for systolic blood pressure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between two observations in the same cluster is 0.030\n"
     ]
    }
   ],
   "source": [
    "model = sm.GEE.from_formula(\"BPXSY1 ~ 1\", \n",
    "                            groups=\"group\",\n",
    "                            cov_struct=sm.cov_struct.Exchangeable(), \n",
    "                            data=da)\n",
    "result = model.fit()\n",
    "print(result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated ICC is 0.03, which is small but not negligible.\n",
    "Although an ICC is a type of correlation, its values are not directly\n",
    "comparable to Pearson correlation values.  While 0.03 would generally\n",
    "be considered to be very small as a Pearson correlation coefficient,\n",
    "it is not especially small as an ICC.\n",
    "\n",
    "To get a more systematic view of the ICC values induced by clustering\n",
    "in these data, we calculate the ICC for a number of different\n",
    "variables that appear in our analyses, either as outcomes or as\n",
    "predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPXSY1 The correlation between two observations in the same cluster is 0.030\n",
      "RIDAGEYR The correlation between two observations in the same cluster is 0.035\n",
      "BMXBMI The correlation between two observations in the same cluster is 0.039\n",
      "smq The correlation between two observations in the same cluster is 0.026\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.959\n"
     ]
    }
   ],
   "source": [
    "# Recode smoking to a simple binary variable\n",
    "da[\"smq\"] = da.SMQ020.replace({2: 0, 7: np.nan, 9: np.nan})\n",
    "\n",
    "for v in [\"BPXSY1\", \"RIDAGEYR\", \"BMXBMI\", \"smq\", \"SDMVSTRA\"]:\n",
    "    model = sm.GEE.from_formula(v + \" ~ 1\", groups=\"group\",\n",
    "           cov_struct=sm.cov_struct.Exchangeable(), data=da)\n",
    "    result = model.fit()\n",
    "    print(v, result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are generally similar to what we saw for blood pressure,\n",
    "except for `SDMVSTRA`, which is one component of the cluster\n",
    "definition itself, and therefore has a very high ICC.\n",
    "\n",
    "To illustrate that the ICC values shown above are not consistent with\n",
    "a complete absence of dependence, we simulate 10 sets of random data\n",
    "and calculate the ICC value for each set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDMVSTRA The correlation between two observations in the same cluster is 0.003\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.000\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.002\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.001\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.000\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.001\n",
      "SDMVSTRA The correlation between two observations in the same cluster is 0.004\n",
      "SDMVSTRA The correlation between two observations in the same cluster is -0.003\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    da[\"noise\"] = np.random.normal(size=da.shape[0])\n",
    "    model = sm.GEE.from_formula(\"noise ~ 1\", \n",
    "                                groups=\"group\",\n",
    "                                cov_struct=sm.cov_struct.Exchangeable(), \n",
    "                                data=da)\n",
    "    result = model.fit()\n",
    "    print(v, result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the estimated ICC for pure simulated noise is random but\n",
    "highly concentrated near zero, varying from around `-0.002` to\n",
    "`+0.002`.\n",
    "\n",
    "## Conditional intraclass correlation\n",
    "\n",
    "The ICC's studied above were *marginal*, in the sense that we were\n",
    "looking at whether, say, the SBP values were more similar within\n",
    "versus between clusters.  To the extent that such \"cluster effects\"\n",
    "are found, it may be largely explained by **demographic differences\n",
    "among the clusters**.  For example, we know from our previous analyses\n",
    "with the NHANES data that older people have higher SBP than younger\n",
    "people.  Also, **some clusters may contain a slightly older or younger\n",
    "set of people than others. Thus, by controlling for age, we might\n",
    "anticipate that the ICC will become smaller.**  This is shown in the\n",
    "next analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between two observations in the same cluster is 0.019\n"
     ]
    }
   ],
   "source": [
    "model = sm.GEE.from_formula(\"BPXSY1 ~ RIDAGEYR\", \n",
    "                            groups=\"group\",\n",
    "                            cov_struct=sm.cov_struct.Exchangeable(), \n",
    "                            data=da)\n",
    "result = model.fit()\n",
    "print(result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ICC for SBP drops from 0.03 to 0.02.  We can now assess whether it\n",
    "drops even further when we add additional covariates that we know to\n",
    "be predictive of blood pressure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between two observations in the same cluster is 0.013\n"
     ]
    }
   ],
   "source": [
    "# Create a labeled version of the gender variable\n",
    "da[\"RIAGENDRx\"] = da.RIAGENDR.replace({1: \"Male\", 2: \"Female\"})\n",
    "\n",
    "model = sm.GEE.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "                            groups=\"group\",\n",
    "                            cov_struct=sm.cov_struct.Exchangeable(), \n",
    "                            data=da)\n",
    "result = model.fit()\n",
    "print(result.cov_struct.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable\n",
    "[RIDRETH1](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#RIDRETH1)\n",
    "is a categorical variable containing 5 levels of race/ethnicity\n",
    "information.  Since NHANES **categorical variables are coded numerically,\n",
    "Statsmodels would have no way of knowing that these are codes and not\n",
    "quantitative data, thus we must use the `C()` syntax in the formula\n",
    "above to force this variable to be treated as being categorical.**  We\n",
    "see here that the ICC has further reduced, to 0.013, due to\n",
    "controlling for these additional factors including ethnicity.\n",
    "\n",
    "## Marginal linear models with dependent data\n",
    "\n",
    "Above we focused on quantifying the dependence induced by clustering.\n",
    "**By understanding the clustering structure, we have gained additional\n",
    "insight about the data that complements our understanding of the mean\n",
    "structure.**  Another facet of working with dependent data is that **while\n",
    "the mean structure (i.e. the regression coefficients) can be estimated\n",
    "without considering the dependence structure of the data, the standard\n",
    "errors and other statistics relating to uncertainty will be wrong when\n",
    "we ignore dependence in the data.**\n",
    "\n",
    "To illustrate this, below we fit two models with the same mean\n",
    "structure to the NHANES data.  The first is a multiple regression\n",
    "model fit using \"ordinary least squares\" (the default method for\n",
    "independent data).  The second is fit using GEE, which allows us to\n",
    "account for the dependence in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   OLS_params    OLS_SE  GEE_params    GEE_SE\n",
      "Intercept           91.736583  1.339378   92.168530  1.384309\n",
      "RIAGENDRx[T.Male]    3.671294  0.453763    3.650245  0.454498\n",
      "C(RIDRETH1)[T.2]     0.855488  0.819486    0.159296  0.767025\n",
      "C(RIDRETH1)[T.3]    -1.796132  0.671954   -2.233280  0.760228\n",
      "C(RIDRETH1)[T.4]     3.813314  0.732355    3.105654  0.881580\n",
      "C(RIDRETH1)[T.5]    -0.455347  0.808948   -0.439831  0.813675\n",
      "RIDAGEYR             0.478699  0.012901    0.474101  0.018493\n",
      "BMXBMI               0.278015  0.033285    0.280205  0.038553\n"
     ]
    }
   ],
   "source": [
    "# Fit a linear model with OLS\n",
    "model1 = sm.OLS.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "                             data=da)\n",
    "result1 = model1.fit()\n",
    "\n",
    "# Fit a marginal linear model using GEE to handle dependent data\n",
    "model2 = sm.GEE.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "                             groups=\"group\",\n",
    "                             cov_struct=sm.cov_struct.Exchangeable(), \n",
    "                             data=da)\n",
    "result2 = model2.fit()\n",
    "\n",
    "x = pd.DataFrame({\"OLS_params\": result1.params, \"OLS_SE\": result1.bse,\n",
    "                  \"GEE_params\": result2.params, \"GEE_SE\": result2.bse})\n",
    "x = x[[\"OLS_params\", \"OLS_SE\", \"GEE_params\", \"GEE_SE\"]]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results above, we see that the point estimates are similar\n",
    "between the OLS and GEE fits of the model, but the standard errors\n",
    "tend to be larger in the GEE fit.  For example, the standard errors\n",
    "for BMI and age are 20-40% larger in the GEE fit.  Since we know that\n",
    "there is dependence in these data that is driven by clustering, the\n",
    "OLS approach is not theoretically justified (the OLS parameter\n",
    "estimates remain meaningful, but the standard errors do not).  **GEE\n",
    "parameter estimates and standard errors are meaningful in the presence\n",
    "of dependence, as long as the dependence is exclusively between\n",
    "observations within the same cluster.**\n",
    "\n",
    "## Marginal logistic regression with dependent data\n",
    "\n",
    "Above we used GEE to fit marginal linear models in the presence of\n",
    "dependence.  GEE can also be used to fit any GLM in the presence of\n",
    "dependence.  We illustrate this using models relating smoking history\n",
    "to several demographic predictor variables.  These are the same models\n",
    "we fit in our previous notebook using GLM, which ignores the\n",
    "clustering.  Below we fit this same GLM again for comparison, then we\n",
    "fit the marginal model using GEE.  One thing to emphasize in doing\n",
    "this is that the GLM and GEE are both legitimate estimators of the\n",
    "marginal mean structure here.  However GLM will not give correct\n",
    "standard errors, so everything derived from standard errors\n",
    "(e.g. confidence intervals and hypothesis tests) will not be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS_params    OLS_SE  GEE_params    GEE_SE\n",
      "Intercept                     -2.305999  0.114308   -2.249820  0.140567\n",
      "RIAGENDRx[T.Male]              0.909597  0.060167    0.908682  0.062342\n",
      "C(DMDEDUC2x)[T.HS]             0.943364  0.089663    0.887965  0.095397\n",
      "C(DMDEDUC2x)[T.SomeCollege]    0.832227  0.084361    0.771636  0.104449\n",
      "C(DMDEDUC2x)[T.lt9]            0.266228  0.109183    0.321784  0.141327\n",
      "C(DMDEDUC2x)[T.x9_11]          1.098561  0.106697    1.062149  0.138401\n",
      "RIDAGEYR                       0.018257  0.001725    0.017416  0.001803\n"
     ]
    }
   ],
   "source": [
    "# Relabel the levels, convert rare categories to missing.\n",
    "da[\"DMDEDUC2x\"] = da.DMDEDUC2.replace({1: \"lt9\", 2: \"x9_11\", 3: \"HS\", 4: \"SomeCollege\",\n",
    "                                       5: \"College\", 7: np.nan, 9: np.nan})\n",
    "\n",
    "# Fit a basic GLM\n",
    "model1 = sm.GLM.from_formula(\"smq ~ RIDAGEYR + RIAGENDRx + C(DMDEDUC2x)\",\n",
    "                             family=sm.families.Binomial(), \n",
    "                             data=da)\n",
    "result1 = model1.fit()\n",
    "result1.summary()\n",
    "\n",
    "# Fit a marginal GLM using GEE\n",
    "model2 = sm.GEE.from_formula(\"smq ~ RIDAGEYR + RIAGENDRx + C(DMDEDUC2x)\",\n",
    "                             groups=\"group\", \n",
    "                             family=sm.families.Binomial(),\n",
    "                             cov_struct=sm.cov_struct.Exchangeable(), \n",
    "                             data=da)\n",
    "result2 = model2.fit(start_params=result1.params)\n",
    "\n",
    "x = pd.DataFrame({\"OLS_params\": result1.params, \"OLS_SE\": result1.bse,\n",
    "                  \"GEE_params\": result2.params, \"GEE_SE\": result2.bse})\n",
    "x = x[[\"OLS_params\", \"OLS_SE\", \"GEE_params\", \"GEE_SE\"]]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the results show that the GLM and the GEE give very\n",
    "similar estimates for the regression parameters.  However the **standard\n",
    "errors obtained using GEE are somewhat larger than those obtained\n",
    "using GLM.  This indicates that GLM understates the uncertainty in the\n",
    "estimated mean structure, which is a direct consequence of it ignoring\n",
    "the dependence structure**.  The GEE results do not suffer from this\n",
    "weakness.\n",
    "\n",
    "To the extent that the GLM and GEE parameter estimates differ, this is\n",
    "due to GEE attempting to exploit the dependence structure to obtain\n",
    "more efficient (i.e. more accurate) estimates of the model parameters.\n",
    "Thus, in summary, we can view GEE as trying to accomplish three things\n",
    "above and beyond what we obtain from GLM:\n",
    "\n",
    "* GEE gives us **insight into the dependence structure of the data**\n",
    "\n",
    "* GEE uses the dependence structure to obtain **meaningful standard errors** of\n",
    "the estimated model parameters.\n",
    "\n",
    "* GEE uses the dependence structure to **estimate the model parameters more accurately**\n",
    "\n",
    "In contrast, GLM does not achieve the first point at all, and in terms of\n",
    "the second point, the GLM standard errors can be far\n",
    "too optimistic (i.e. too small) -- note that in the analysis we are pursuing\n",
    "here, even weak clustering (ICC around 0.02-0.04) modifies some of the standard errors\n",
    "by 10-40%.  Finally, with regard to the third  point, **GEE should\n",
    "in general have an efficiency advantage over GLM, but GLM estimates\n",
    "remain \"valid\" and cannot be completely dismissed solely on this\n",
    "basis.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilevel models\n",
    "\n",
    "Multilevel modeling is a large topic, and some aspects of it are quite\n",
    "advanced.  Here, we will explore one facet of multilevel modeling --\n",
    "using it as an alternative way to accommodate dependence in clustered data.  In\n",
    "this sense, multilevel modeling is an alternative to the marginal\n",
    "regression analysis demonstrated above.\n",
    "\n",
    "In the setting of linear regression, mutilevel models and marginal\n",
    "models are similar in most ways (note that **more substantial differences\n",
    "between marginal and multilevel models emerge in the case of logistic\n",
    "regression, and in other generalized linear or nonlinear models).**\n",
    "Multilevel models and marginal models **estimate the same population\n",
    "target, but represent this target in different ways, and utilize\n",
    "different estimation procedures.**\n",
    "\n",
    "A multilevel model is usually expressed in terms of *random effects*.\n",
    "These are variables that we do not observe, but that we can\n",
    "nevertheless incorporate into a statistical model.  We cannot get into\n",
    "all of the technical details here, but it is important to understand\n",
    "that **while these random effects are not observed, their presence can\n",
    "be inferred through the data, as long as each random effect is modeled as\n",
    "influencing at least two observations.**\n",
    "\n",
    "In the present setting, we are focusing only on dependence that arises\n",
    "through a single level of clustering.  To put this in the context of\n",
    "multilevel modeling, we can imagine that **each cluster has a random\n",
    "effect that is shared by all observations in that cluster.**  For\n",
    "example, if SBP tends to be around 0.5 units higher in one cluster,\n",
    "then the random effect for that cluster would be 0.5, and it would add\n",
    "to the predicted SBP for every observation in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>BPXSY1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5102</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>30</td>          <td>Scale:</td>         <td>256.6952</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>106</td>       <td>Likelihood:</td>     <td>-21409.8702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>226</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>170.1</td>           <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th> <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th> <th>0.975]</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>92.173</td>   <td>1.402</td>  <td>65.752</td> <td>0.000</td> <td>89.426</td> <td>94.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th>  <td>3.650</td>   <td>0.452</td>   <td>8.084</td> <td>0.000</td>  <td>2.765</td>  <td>4.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.2]</th>   <td>0.153</td>   <td>0.887</td>   <td>0.172</td> <td>0.863</td> <td>-1.586</td>  <td>1.891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.3]</th>  <td>-2.238</td>   <td>0.758</td>  <td>-2.954</td> <td>0.003</td> <td>-3.723</td> <td>-0.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.4]</th>   <td>3.098</td>   <td>0.836</td>   <td>3.707</td> <td>0.000</td>  <td>1.460</td>  <td>4.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.5]</th>  <td>-0.439</td>   <td>0.878</td>  <td>-0.500</td> <td>0.617</td> <td>-2.161</td>  <td>1.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIDAGEYR</th>           <td>0.474</td>   <td>0.013</td>  <td>36.482</td> <td>0.000</td>  <td>0.449</td>  <td>0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMXBMI</th>             <td>0.280</td>   <td>0.033</td>   <td>8.404</td> <td>0.000</td>  <td>0.215</td>  <td>0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group Var</th>          <td>3.615</td>   <td>0.085</td>     <td></td>      <td></td>       <td></td>       <td></td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "           Mixed Linear Model Regression Results\n",
       "============================================================\n",
       "Model:             MixedLM  Dependent Variable:  BPXSY1     \n",
       "No. Observations:  5102     Method:              REML       \n",
       "No. Groups:        30       Scale:               256.6952   \n",
       "Min. group size:   106      Likelihood:          -21409.8702\n",
       "Max. group size:   226      Converged:           Yes        \n",
       "Mean group size:   170.1                                    \n",
       "------------------------------------------------------------\n",
       "                  Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
       "------------------------------------------------------------\n",
       "Intercept         92.173    1.402 65.752 0.000 89.426 94.921\n",
       "RIAGENDRx[T.Male]  3.650    0.452  8.084 0.000  2.765  4.535\n",
       "C(RIDRETH1)[T.2]   0.153    0.887  0.172 0.863 -1.586  1.891\n",
       "C(RIDRETH1)[T.3]  -2.238    0.758 -2.954 0.003 -3.723 -0.753\n",
       "C(RIDRETH1)[T.4]   3.098    0.836  3.707 0.000  1.460  4.737\n",
       "C(RIDRETH1)[T.5]  -0.439    0.878 -0.500 0.617 -2.161  1.282\n",
       "RIDAGEYR           0.474    0.013 36.482 0.000  0.449  0.500\n",
       "BMXBMI             0.280    0.033  8.404 0.000  0.215  0.346\n",
       "group Var          3.615    0.085                           \n",
       "============================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a multilevel (mixed effects) model to handle dependent data\n",
    "model = sm.MixedLM.from_formula(\"BPXSY1 ~ RIDAGEYR + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "                                groups=\"group\", \n",
    "                                data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **\"variance structure parameters\" are what distinguish a mixed model\n",
    "from a marginal model.  Here we only have one such parameter, which is\n",
    "the variance for groups, estimated to be 3.615**.  This means that **.if we\n",
    "were to choose two groups at random, their random effects would differ\n",
    "on average by around 2.69 (this is calculated as the square root of\n",
    "`2*3.615`).**.  This is a sizable shift, comparable to the difference\n",
    "between females and males, or to around 6 years of aging.\n",
    "\n",
    "We have seen here that it least in this setting, the mixed modeling\n",
    "procedure accommodates dependence in the data, provides rigorous\n",
    "estimates of the strength of this dependence, and accounts for the\n",
    "dependence in both estimation and inference for the regression\n",
    "parameters.  In this sense, the multilevel model has the same\n",
    "desirable properties as GEE (at least in this setting).  In fact, each\n",
    "of these two methods is very useful and widely utilized.  There are\n",
    "some settings where either GEE or multilevel modeling can be argued to\n",
    "have an advantage, but neither uniformly dominates the other.\n",
    "\n",
    "**Multilevel models can also be used to estimate ICC values.  In the\n",
    "case of a model with one level, which is what we have here, the ICC is\n",
    "the variance of the grouping variable (3.615) divided by the sum of\n",
    "the variance of the grouping variable and the unexplained variance\n",
    "(256.7).** Note that the **unexplained variance is in upper part of the\n",
    "output, labeled *scale*.**  This ICC ratio is around 0.014, which is very\n",
    "similar to the estimated ICC obtained using GEE.\n",
    "\n",
    "### Predicted random effects\n",
    "\n",
    "While the actual random effects in a multilevel model are never\n",
    "observable, we can predict them from the data.  This is sometimes\n",
    "useful, although the **emphasis in multilevel regression usually lies\n",
    "with the structural parameters that underlie the random effects, and\n",
    "not the random effects themselves.**  In the NHANES analysis, for\n",
    "example, we could use the predicted random effects to quantify the\n",
    "uniqueness of each county relative to the mean.\n",
    "\n",
    "The **predicted random effects** for the 30 groups in this analysis\n",
    "are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1191: group   -1.630976\n",
       " dtype: float64, 1192: group   -0.086162\n",
       " dtype: float64, 1201: group   -2.042661\n",
       " dtype: float64, 1202: group   -0.147472\n",
       " dtype: float64, 1211: group    0.280623\n",
       " dtype: float64, 1212: group    1.580732\n",
       " dtype: float64, 1221: group    0.283347\n",
       " dtype: float64, 1222: group    0.131512\n",
       " dtype: float64, 1231: group   -2.038171\n",
       " dtype: float64, 1232: group    0.617651\n",
       " dtype: float64, 1241: group    2.878488\n",
       " dtype: float64, 1242: group   -0.519364\n",
       " dtype: float64, 1251: group    2.064967\n",
       " dtype: float64, 1252: group    1.521281\n",
       " dtype: float64, 1261: group   -1.261975\n",
       " dtype: float64, 1262: group    0.980846\n",
       " dtype: float64, 1271: group    0.118031\n",
       " dtype: float64, 1272: group   -0.128397\n",
       " dtype: float64, 1281: group   -0.384862\n",
       " dtype: float64, 1282: group   -3.582111\n",
       " dtype: float64, 1291: group   -3.271017\n",
       " dtype: float64, 1292: group   -0.829538\n",
       " dtype: float64, 1301: group   -0.884171\n",
       " dtype: float64, 1302: group    2.790657\n",
       " dtype: float64, 1311: group   -0.585201\n",
       " dtype: float64, 1312: group    1.198291\n",
       " dtype: float64, 1321: group   -0.195692\n",
       " dtype: float64, 1322: group    1.955515\n",
       " dtype: float64, 1331: group   -0.305559\n",
       " dtype: float64, 1332: group    1.491389\n",
       " dtype: float64}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.random_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these predicted random effects (also known as *BLUPs*), we\n",
    "see, for example, that cluster 1241 has unusually high SBP, and\n",
    "cluster 1282 has unusually low SBP.  These deviations from what is\n",
    "expected are observed after adjusting for the covariates in the model,\n",
    "and hence are presumably driven by other characteristics of these\n",
    "clusters that are not reflected in the covariates.\n",
    "\n",
    "### Random slopes\n",
    "\n",
    "Multilevel modeling is a broad framework that allows many different\n",
    "types of models to be specified and fit.  Here we are primarily\n",
    "focusing on the **\"random intercept models\", that allow the data in each\n",
    "cluster to be shifted by a common amount, in order to account for\n",
    "stable confounders within clusters.  Above we found some evidence that\n",
    "such clustering is present in the data.**  \n",
    "\n",
    "**Next** we consider a more\n",
    "subtle form of cluster effect, in which the **slope for a specific\n",
    "covariate varies from cluster to cluster.  This is called a *random\n",
    "slopes model*.**  To demonstrate, below we fit a model in which SBP has\n",
    "**cluster-specific intercepts, and cluster-specific slopes** for the age\n",
    "covariate.  That is, we ask whether the rate at which blood pressure\n",
    "increases with age might differ from one cluster to the next.\n",
    "\n",
    "We fit two variations on this model.  \n",
    "* In the **first model, the\n",
    "cluster-specific intercepts and slopes are independent random\n",
    "variables.**  \n",
    "* That is, a cluster with unusually high SBP is no more or\n",
    "less likely to have unusually rapid increase of SBP with age.  \n",
    "* **Note\n",
    "that when working with random slopes, it is usually advisable to\n",
    "center any covariate which has a random slope.  This does not change\n",
    "the fundamental interpretation of the model, but it does often result\n",
    "in models that converge faster and more robustly.**  \n",
    "* Here we **center\n",
    "within each cluster, although it is also common to center in the\n",
    "entire dataset**, rather than centering separately by cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/regression/mixed_linear_model.py:2045: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>BPXSY1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5102</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>30</td>          <td>Scale:</td>         <td>263.7323</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>106</td>       <td>Likelihood:</td>     <td>-21469.9240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>226</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>170.1</td>           <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>115.207</td>   <td>1.209</td>  <td>95.265</td> <td>0.000</td> <td>112.836</td> <td>117.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th>  <td>3.643</td>    <td>0.457</td>   <td>7.962</td> <td>0.000</td>  <td>2.746</td>   <td>4.539</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.2]</th>   <td>1.167</td>    <td>0.827</td>   <td>1.412</td> <td>0.158</td> <td>-0.453</td>   <td>2.787</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.3]</th>  <td>-1.659</td>    <td>0.679</td>  <td>-2.444</td> <td>0.015</td> <td>-2.989</td>  <td>-0.328</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.4]</th>   <td>3.610</td>    <td>0.739</td>   <td>4.884</td> <td>0.000</td>  <td>2.161</td>   <td>5.058</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.5]</th>  <td>-1.208</td>    <td>0.816</td>  <td>-1.480</td> <td>0.139</td> <td>-2.807</td>   <td>0.392</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen</th>            <td>0.467</td>    <td>0.018</td>  <td>26.235</td> <td>0.000</td>  <td>0.432</td>   <td>0.502</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMXBMI</th>             <td>0.288</td>    <td>0.034</td>   <td>8.574</td> <td>0.000</td>  <td>0.222</td>   <td>0.353</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen Var</th>        <td>0.004</td>    <td>0.000</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "             Mixed Linear Model Regression Results\n",
       "===============================================================\n",
       "Model:              MixedLM   Dependent Variable:   BPXSY1     \n",
       "No. Observations:   5102      Method:               REML       \n",
       "No. Groups:         30        Scale:                263.7323   \n",
       "Min. group size:    106       Likelihood:           -21469.9240\n",
       "Max. group size:    226       Converged:            Yes        \n",
       "Mean group size:    170.1                                      \n",
       "---------------------------------------------------------------\n",
       "                   Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
       "---------------------------------------------------------------\n",
       "Intercept         115.207    1.209 95.265 0.000 112.836 117.577\n",
       "RIAGENDRx[T.Male]   3.643    0.457  7.962 0.000   2.746   4.539\n",
       "C(RIDRETH1)[T.2]    1.167    0.827  1.412 0.158  -0.453   2.787\n",
       "C(RIDRETH1)[T.3]   -1.659    0.679 -2.444 0.015  -2.989  -0.328\n",
       "C(RIDRETH1)[T.4]    3.610    0.739  4.884 0.000   2.161   5.058\n",
       "C(RIDRETH1)[T.5]   -1.208    0.816 -1.480 0.139  -2.807   0.392\n",
       "age_cen             0.467    0.018 26.235 0.000   0.432   0.502\n",
       "BMXBMI              0.288    0.034  8.574 0.000   0.222   0.353\n",
       "age_cen Var         0.004    0.000                             \n",
       "===============================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da[\"age_cen\"] = da.groupby(\"group\").RIDAGEYR.transform(lambda x: x - x.mean())\n",
    "\n",
    "model = sm.MixedLM.from_formula(\"BPXSY1 ~ age_cen + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "                                groups=\"group\", \n",
    "                                vc_formula={\"age_cen\": \"0+age_cen\"}, \n",
    "                                data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that the estimated variance for random age slopes is 0.004,\n",
    "which translates to a standard deviation of 0.06.  That is, from one\n",
    "cluster to another, the age slopes fluctuate by $\\pm 0.06-0.12$ (1-2\n",
    "standard deviations).  \n",
    "* These cluster-specific fluctuations are\n",
    "added/subtracted from the fixed effect for age, which is 0.467.  Thus,\n",
    "in some clusters SBP may increase by around `0.467 + 0.06 = 0.527`\n",
    "mm/Hg per year, while in other clusters SBP may increase by only\n",
    "around `0.467 - 0.06 = 0.407` mm/Hg per year.  Note also that the\n",
    "fitting algorithm produces a warning that the estimated variance\n",
    "parameter is close to the boundary.  In this case, however, the\n",
    "algorithm seems to have converged to a point just short of the\n",
    "boundary.\n",
    "\n",
    "**Next**, we fit a **model in which the cluster-specific\n",
    "intercepts and slopes are allowed to be correlated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/statsmodels/regression/mixed_linear_model.py:2045: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td>Model:</td>       <td>MixedLM</td> <td>Dependent Variable:</td>   <td>BPXSY1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>No. Observations:</td>  <td>5102</td>         <td>Method:</td>          <td>REML</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>No. Groups:</td>      <td>30</td>          <td>Scale:</td>         <td>255.4451</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Min. group size:</td>    <td>106</td>       <td>Likelihood:</td>     <td>-21413.6193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Max. group size:</td>    <td>226</td>       <td>Converged:</td>          <td>Yes</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Mean group size:</td>   <td>170.1</td>           <td></td>                <td></td>      \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>            <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>   <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>115.467</td>   <td>1.340</td>  <td>86.173</td> <td>0.000</td> <td>112.840</td> <td>118.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RIAGENDRx[T.Male]</th>    <td>3.662</td>    <td>0.451</td>   <td>8.121</td> <td>0.000</td>  <td>2.778</td>   <td>4.546</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.2]</th>     <td>0.023</td>    <td>0.898</td>   <td>0.025</td> <td>0.980</td> <td>-1.738</td>   <td>1.783</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.3]</th>    <td>-2.251</td>    <td>0.778</td>  <td>-2.893</td> <td>0.004</td> <td>-3.775</td>  <td>-0.726</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.4]</th>     <td>3.011</td>    <td>0.854</td>   <td>3.524</td> <td>0.000</td>  <td>1.336</td>   <td>4.686</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(RIDRETH1)[T.5]</th>    <td>-0.585</td>    <td>0.893</td>  <td>-0.655</td> <td>0.512</td> <td>-2.336</td>   <td>1.165</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen</th>              <td>0.466</td>    <td>0.018</td>  <td>26.286</td> <td>0.000</td>  <td>0.431</td>   <td>0.501</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMXBMI</th>               <td>0.283</td>    <td>0.033</td>   <td>8.497</td> <td>0.000</td>  <td>0.218</td>   <td>0.349</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group Var</th>            <td>8.655</td>    <td>0.169</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group x age_cen Cov</th>  <td>0.119</td>    <td>0.004</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_cen Var</th>          <td>0.004</td>    <td>0.000</td>     <td></td>      <td></td>       <td></td>        <td></td>    \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "              Mixed Linear Model Regression Results\n",
       "=================================================================\n",
       "Model:                MixedLM   Dependent Variable:   BPXSY1     \n",
       "No. Observations:     5102      Method:               REML       \n",
       "No. Groups:           30        Scale:                255.4451   \n",
       "Min. group size:      106       Likelihood:           -21413.6193\n",
       "Max. group size:      226       Converged:            Yes        \n",
       "Mean group size:      170.1                                      \n",
       "-----------------------------------------------------------------\n",
       "                     Coef.  Std.Err.   z    P>|z|  [0.025  0.975]\n",
       "-----------------------------------------------------------------\n",
       "Intercept           115.467    1.340 86.173 0.000 112.840 118.093\n",
       "RIAGENDRx[T.Male]     3.662    0.451  8.121 0.000   2.778   4.546\n",
       "C(RIDRETH1)[T.2]      0.023    0.898  0.025 0.980  -1.738   1.783\n",
       "C(RIDRETH1)[T.3]     -2.251    0.778 -2.893 0.004  -3.775  -0.726\n",
       "C(RIDRETH1)[T.4]      3.011    0.854  3.524 0.000   1.336   4.686\n",
       "C(RIDRETH1)[T.5]     -0.585    0.893 -0.655 0.512  -2.336   1.165\n",
       "age_cen               0.466    0.018 26.286 0.000   0.431   0.501\n",
       "BMXBMI                0.283    0.033  8.497 0.000   0.218   0.349\n",
       "group Var             8.655    0.169                             \n",
       "group x age_cen Cov   0.119    0.004                             \n",
       "age_cen Var           0.004    0.000                             \n",
       "=================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.MixedLM.from_formula(\"BPXSY1 ~ age_cen + RIAGENDRx + BMXBMI + C(RIDRETH1)\",\n",
    "                                groups=\"group\", \n",
    "                                re_formula=\"1+age_cen\", \n",
    "                                data=da)\n",
    "result = model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we get a warning that the algorithm is close to the boundary.\n",
    "The estimated correlation coefficient between random slopes and random\n",
    "intercepts is estimated to be `0.119/sqrt(8.655*0.004)`, which is\n",
    "around `0.64`.  This indicates that the clusters with unusually high\n",
    "average SBP also tend to have SBP increasing faster with age.  Note\n",
    "however that these structural parameters are only estimates, and due\n",
    "to the variance parameter falling close to the boundary, the estimates\n",
    "may not be particularly precise."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# correlationCoefficientAB\n",
    "# = covarianceAB / sqrt(varA * varB)\n",
    "= \"group x age_cen Cov\" coefficient / sqrt(\"group Var\" coefficient * \"age_cen Var\" coefficient) \n",
    "= 0.119/sqrt(8.655*0.004)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilevel logistic regression\n",
    "\n",
    "Logistic regression models with random effects can be fit using a\n",
    "technique that is somewhat analogous to the way that we fit mixed\n",
    "linear models.  The computational algorithms used to fit these models\n",
    "are quite advanced.  Versions of these algorithms have been\n",
    "implemented in the development version of Statsmodels, but are not yet\n",
    "released.  At this point, it may not be practical to fit multilevel\n",
    "logistic models in Python, but this should become a possibility in the\n",
    "near future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
