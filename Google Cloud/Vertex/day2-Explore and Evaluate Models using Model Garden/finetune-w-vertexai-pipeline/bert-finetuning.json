{"components":{"comp-bert-fine-tuning":{"executorLabel":"exec-bert-fine-tuning","inputDefinitions":{"parameters":{"accelerator_count":{"defaultValue":1,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"accelerator_type":{"defaultValue":"NVIDIA_TESLA_T4","isOptional":true,"parameterType":"STRING"},"dropout":{"defaultValue":0.35,"isOptional":true,"parameterType":"NUMBER_DOUBLE"},"encryption_spec_key_name":{"isOptional":true,"parameterType":"STRING"},"eval_batch_size":{"defaultValue":32,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"initial_learning_rate":{"defaultValue":0.0001,"isOptional":true,"parameterType":"NUMBER_DOUBLE"},"input_data_path":{"parameterType":"STRING"},"input_format":{"defaultValue":"JSONL","isOptional":true,"parameterType":"STRING"},"location":{"parameterType":"STRING"},"machine_type":{"defaultValue":"n1-highmem-8","isOptional":true,"parameterType":"STRING"},"model_architecture":{"defaultValue":"MULTILINGUAL_BERT_BASE_CASED","isOptional":true,"parameterType":"STRING"},"natural_language_task_type":{"defaultValue":"CLASSIFICATION","isOptional":true,"parameterType":"STRING"},"num_epochs":{"defaultValue":30,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"optimizer_type":{"defaultValue":"lamb","isOptional":true,"parameterType":"STRING"},"project":{"parameterType":"STRING"},"random_seed":{"defaultValue":0,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"test_steps_per_epoch":{"defaultValue":-1,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"train_batch_size":{"defaultValue":32,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"train_steps_per_epoch":{"defaultValue":-1,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"validation_steps_per_epoch":{"defaultValue":-1,"isOptional":true,"parameterType":"NUMBER_INTEGER"},"warmup":{"defaultValue":0.1,"isOptional":true,"parameterType":"NUMBER_DOUBLE"}}},"outputDefinitions":{"artifacts":{"model_output_path":{"artifactType":{"schemaTitle":"system.Artifact","schemaVersion":"0.0.1"}}},"parameters":{"gcp_resources":{"parameterType":"STRING"}}}},"comp-convert-classification-export-for-batch-predict":{"executorLabel":"exec-convert-classification-export-for-batch-predict","inputDefinitions":{"parameters":{"classification_type":{"parameterType":"STRING"},"file_paths":{"parameterType":"LIST"}}},"outputDefinitions":{"parameters":{"output_dir":{"parameterType":"LIST"},"output_files":{"parameterType":"LIST"}}}},"comp-get-task-type":{"executorLabel":"exec-get-task-type","inputDefinitions":{"parameters":{"classification_type":{"parameterType":"STRING"}}},"outputDefinitions":{"parameters":{"Output":{"parameterType":"STRING"}}}},"comp-get-vertex-model":{"executorLabel":"exec-get-vertex-model","inputDefinitions":{"parameters":{"model_name":{"description":"Vertex model resource name in the format of\nprojects/{project}/locations/{location}/models/{model} or\nprojects/{project}/locations/{location}/models/{model}@{model_version_id\nor model_version_alias}.","parameterType":"STRING"},"model_version":{"defaultValue":"","description":"The desired Vertex Model version to get. If model_name and\nmodel_version are provided, model_version will override any version or\nalias if present in model_name.","isOptional":true,"parameterType":"STRING"}}},"outputDefinitions":{"artifacts":{"model":{"artifactType":{"schemaTitle":"google.VertexModel","schemaVersion":"0.0.1"}}},"parameters":{"gcp_resources":{"parameterType":"STRING"}}}},"comp-model-batch-predict":{"executorLabel":"exec-model-batch-predict","inputDefinitions":{"artifacts":{"model":{"artifactType":{"schemaTitle":"google.VertexModel","schemaVersion":"0.0.1"},"description":"The Model used to get predictions via this job. Must share the same\nancestor Location. Starting this job has no impact on any existing\ndeployments of the Model and their resources. Either this or\n``unmanaged_container_model`` must be specified.","isOptional":true},"unmanaged_container_model":{"artifactType":{"schemaTitle":"google.UnmanagedContainerModel","schemaVersion":"0.0.1"},"description":"The unmanaged container model used to get predictions via this job.\nThis should be used for models that are not uploaded to Vertex. Either\nthis or model must be specified.","isOptional":true}},"parameters":{"accelerator_count":{"defaultValue":0,"description":"The number of accelerators to attach\nto the ``machine_type``. Only used if ``machine_type`` is set.  For more\ndetails about the machine spec, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec","isOptional":true,"parameterType":"NUMBER_INTEGER"},"accelerator_type":{"defaultValue":"","description":"The type of accelerator(s) that may be\nattached to the machine as per ``accelerator_count``. Only used if\n``machine_type`` is set.  For more details about the machine spec, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec","isOptional":true,"parameterType":"STRING"},"bigquery_destination_output_uri":{"defaultValue":"","description":"The BigQuery project location where the output is to be written to. In\nthe given project a new dataset is created with name\n``prediction_<model-display-name>_<job-create-time>`` where is made\nBigQuery-dataset-name compatible (for example, most special characters\nbecome underscores), and timestamp is in YYYY_MM_DDThh_mm_ss_sssZ\n\"based on ISO-8601\" format. In the dataset two tables will be created,\n``predictions``, and ``errors``. If the Model has both ``instance``\nand ``prediction`` schemata defined then the tables have columns as\nfollows: The ``predictions`` table contains instances for which the\nprediction succeeded, it has columns as per a concatenation of the\nModel's instance and prediction schemata. The ``errors`` table\ncontains rows for which the prediction has failed, it has instance\ncolumns, as per the instance schema, followed by a single \"errors\"\ncolumn, which as values has `google.rpc.Status <Status>`_\nrepresented as a STRUCT, and containing only ``code`` and\n``message``. For more details about this output config, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#OutputConfig.","isOptional":true,"parameterType":"STRING"},"bigquery_source_input_uri":{"defaultValue":"","description":"BigQuery URI to a table, up to 2000 characters long. For example:\n``projectId.bqDatasetId.bqTableId``  For more details about this input\nconfig, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#InputConfig.","isOptional":true,"parameterType":"STRING"},"encryption_spec_key_name":{"defaultValue":"","description":"Customer-managed encryption\nkey options for a BatchPredictionJob. If this is set, then all\nresources created by the BatchPredictionJob will be encrypted with the\nprovided encryption key.  Has the form:\n``projects/my-project/locations/my-location/keyRings/my-kr/cryptoKeys/my-key``.\nThe key needs to be in the same region as where the compute resource\nis created.","isOptional":true,"parameterType":"STRING"},"excluded_fields":{"defaultValue":[],"description":"Fields that will be excluded in the prediction instance that is\nsent to the Model.\nExcluded will be attached to the batch prediction output if\nkey_field is not specified.\nWhen ``excluded_fields`` is populated, ``included_fields`` must be empty.\nThe input must be JSONL with objects at each line, CSV, BigQuery\nor TfRecord.\nmay be specified via the Model's ``parameters_schema_uri``.","isOptional":true,"parameterType":"LIST"},"explanation_metadata":{"defaultValue":{},"description":"Explanation metadata\nconfiguration for this BatchPredictionJob. Can be specified only if\n``generate_explanation`` is set to `True`.  This value overrides the\nvalue of ``Model.explanation_metadata``. All fields of\n``explanation_metadata`` are optional in the request. If a field of the\n``explanation_metadata`` object is not populated, the corresponding\nfield of the `Model.explanation_metadata` object is inherited.  For\nmore details, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata.","isOptional":true,"parameterType":"STRUCT"},"explanation_parameters":{"defaultValue":{},"description":"Parameters to configure\nexplaining for Model's predictions. Can be specified only if\n``generate_explanation`` is set to `True`.  This value overrides the\nvalue of `Model.explanation_parameters`. All fields of\n``explanation_parameters`` are optional in the request. If a field of\nthe ``explanation_parameters`` object is not populated, the\ncorresponding field of the ``Model.explanation_parameters`` object is\ninherited.  For more details, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#ExplanationParameters.","isOptional":true,"parameterType":"STRUCT"},"gcs_destination_output_uri_prefix":{"defaultValue":"","description":"The Google Cloud\nStorage location of the directory where the output is to be written\nto. In the given directory a new directory is created. Its name is\n``prediction-<model-display-name>-<job-create-time>``, where timestamp\nis in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. Inside of it files\n``predictions_0001.<extension>``, ``predictions_0002.<extension>``,\n..., ``predictions_N.<extension>`` are created where ``<extension>``\ndepends on chosen ``predictions_format``, and N may equal 0001 and\ndepends on the total number of successfully predicted instances. If\nthe Model has both ``instance`` and ``prediction`` schemata defined\nthen each such file contains predictions as per the\n``predictions_format``. If prediction for any instance failed\n(partially or completely), then an additional\n``errors_0001.<extension>``, ``errors_0002.<extension>``,...,\n``errors_N.<extension>`` files are created (N depends on total number\nof failed predictions). These files contain the failed instances, as\nper their schema, followed by an additional ``error`` field which as\nvalue has ``google.rpc.Status`` containing only ``code`` and\n``message`` fields.  For more details about this output config, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#OutputConfig.","isOptional":true,"parameterType":"STRING"},"gcs_source_uris":{"defaultValue":[],"description":"Google Cloud Storage URI(-s) to your instances to run batch prediction\non. They must match ``instances_format``. May contain wildcards. For more\ninformation on wildcards, see `WildcardNames <https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames>`_.\nFor more details about this input config, see `InputConfig <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#InputConfig>`_.","isOptional":true,"parameterType":"LIST"},"generate_explanation":{"defaultValue":false,"description":"Generate explanation along with\nthe batch prediction results. This will cause the batch prediction\noutput to include explanations based on the ``prediction_format``: -\n``bigquery``: output includes a column named ``explanation``. The value is\na struct that conforms to the [aiplatform.gapic.Explanation] object. -\n``jsonl``: The JSON objects on each line include an additional entry\nkeyed ``explanation``. The value of the entry is a JSON object that\nconforms to the [aiplatform.gapic.Explanation] object. - ``csv``:\nGenerating explanations for CSV format is not supported.  If this\nfield is set to true, either the Model.explanation_spec or\nexplanation_metadata and explanation_parameters must be populated.","isOptional":true,"parameterType":"BOOLEAN"},"included_fields":{"defaultValue":[],"description":"Fields that will be included in the prediction instance that is\nsent to the Model.\nIf ``instance_type`` is ``array``, the order of field names in\n``included_fields`` also determines the order of the values in the array.\nWhen ``included_fields`` is populated, ``excluded_fields`` must be empty.\nThe input must be JSONL with objects at each line, CSV, BigQuery\nor TfRecord.","isOptional":true,"parameterType":"LIST"},"instance_type":{"defaultValue":"","description":"The format of the instance that the Model\naccepts. Vertex AI will convert compatible\n`InstancesFormat <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#InputConfig>`_\nto the specified format. Supported values are:\n``object``: Each input is converted to JSON object format.\n  * For ``bigquery``, each row is converted to an object.\n  * For ``jsonl``, each line of the JSONL input must be an object.\n  * Does not apply to ``csv``, ``file-list``, ``tf-record``, or ``tf-record-gzip``.\n``array``: Each input is converted to JSON array format.\n  * For ``bigquery``, each row is converted to an array. The order\n    of columns is determined by the BigQuery column order, unless\n    `included_fields <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#InputConfig>`_ is populated.\n    ``included_fields`` must be populated for specifying field orders.\n  * For ``jsonl``, if each line of the JSONL input is an object,\n    ``included_fields`` must be populated for specifying field orders.\n  * Does not apply to `csv`, ``file-list``, ``tf-record``, or\n    ``tf-record-gzip``.\nIf not specified, Vertex AI converts the batch prediction input as\nfollows:\n * For ``bigquery`` and ``csv``, the behavior is the same as ``array`. The\n   order of columns is the same as defined in the file or table, unless\n   included_fields is populated.\n * For ``jsonl``, the prediction instance format is determined by\n   each line of the input.\n * For ``tf-record``/``tf-record-gzip``, each record will be converted to\n   an object in the format of ``{\"b64\": <value>}``, where ``<value>`` is\n   the Base64-encoded string of the content of the record.\n * For ``file-list``, each file in the list will be converted to an\n   object in the format of ``{\"b64\": <value>}``, where ``<value>`` is\n   the Base64-encoded string of the content of the file.","isOptional":true,"parameterType":"STRING"},"instances_format":{"defaultValue":"jsonl","description":"The format in which instances are\ngiven, must be one of the `Model <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models>`_'s supportedInputStorageFormats.\nFor more details about this input config, see\n`InputConfig <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#InputConfig.>`_","isOptional":true,"parameterType":"STRING"},"job_display_name":{"description":"The user-defined name of this BatchPredictionJob.","parameterType":"STRING"},"key_field":{"defaultValue":"","description":"The name of the field that is considered as a key.\nThe values identified by the key field is not included in the\ntransformed instances that is sent to the Model. This is similar to\nspecifying this name of the field in `excluded_fields <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#InputConfig>`_. In addition,\nthe batch prediction output will not include the instances. Instead the\noutput will only include the value of the key field, in a field named\n``key`` in the output:\n * For ``jsonl`` output format, the output will have a ``key`` field\n   instead of the ``instance`` field.\n * For ``csv``/``bigquery`` output format, the output will have have a ``key``\n   column instead of the instance feature columns.\nThe input must be JSONL with objects at each line, CSV, BigQuery\nor TfRecord.","isOptional":true,"parameterType":"STRING"},"labels":{"defaultValue":{},"description":"The labels with user-defined metadata to\norganize your BatchPredictionJobs.  Label keys and values can be no\nlonger than 64 characters (Unicode codepoints), can only contain\nlowercase letters, numeric characters, underscores and dashes.\nInternational characters are allowed.  See https://goo.gl/xmQnxf for\nmore information and examples of labels.","isOptional":true,"parameterType":"STRUCT"},"location":{"defaultValue":"us-central1","description":"Location for creating the BatchPredictionJob.","isOptional":true,"parameterType":"STRING"},"machine_type":{"defaultValue":"","description":"The type of machine for running batch\nprediction on dedicated resources. If the Model supports\nDEDICATED_RESOURCES this config may be provided (and the job will use\nthese resources). If the Model doesn't support AUTOMATIC_RESOURCES,\nthis config must be provided.  For more details about the\nBatchDedicatedResources, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#BatchDedicatedResources.\nFor more details about the machine spec, see\nhttps://cloud.google.com/vertex-ai/docs/reference/rest/v1/MachineSpec","isOptional":true,"parameterType":"STRING"},"manual_batch_tuning_parameters_batch_size":{"defaultValue":0,"description":"The number of\nthe records (e.g. instances) of the operation given in each batch to a\nmachine replica. Machine type, and size of a single record should be\nconsidered when setting this parameter, higher value speeds up the\nbatch operation's execution, but too high value will result in a whole\nbatch not fitting in a machine's memory, and the whole operation will\nfail.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"max_replica_count":{"defaultValue":0,"description":"The maximum number of machine replicas the batch operation may be scaled\nto. Only used if ``machine_type`` is set.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"model_parameters":{"defaultValue":{},"description":"The parameters that govern the predictions. The schema of the parameters","isOptional":true,"parameterType":"STRUCT"},"predictions_format":{"defaultValue":"jsonl","description":"The format in which Vertex AI gives the predictions. Must be one of the\nModel's supportedOutputStorageFormats.\nFor more details about this output config, see `OutputConfig <https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#OutputConfig>`_.","isOptional":true,"parameterType":"STRING"},"project":{"description":"Project to create the BatchPredictionJob.","parameterType":"STRING"},"starting_replica_count":{"defaultValue":0,"description":"The number of machine replicas\nused at the start of the batch operation. If not set, Vertex AI\ndecides starting number, not greater than ``max_replica_count``. Only\nused if ``machine_type`` is set.","isOptional":true,"parameterType":"NUMBER_INTEGER"}}},"outputDefinitions":{"artifacts":{"batchpredictionjob":{"artifactType":{"schemaTitle":"google.VertexBatchPredictionJob","schemaVersion":"0.0.1"},"description":"[**Deprecated. Use gcs_output_directory and bigquery_output_table\ninstead.**] Artifact\nrepresentation of the created batch prediction job."},"bigquery_output_table":{"artifactType":{"schemaTitle":"google.BQTable","schemaVersion":"0.0.1"},"description":"Artifact tracking the batch prediction job output. This is only\navailable if\nbigquery_output_table is specified."},"gcs_output_directory":{"artifactType":{"schemaTitle":"system.Artifact","schemaVersion":"0.0.1"},"description":"Artifact tracking the batch prediction job output. This is only\navailable if\ngcs_destination_output_uri_prefix is specified."}},"parameters":{"gcp_resources":{"description":"Serialized gcp_resources proto tracking the batch prediction job.\nFor more details, see\nhttps://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md.","parameterType":"STRING"}}}},"comp-model-evaluation-classification":{"executorLabel":"exec-model-evaluation-classification","inputDefinitions":{"artifacts":{"model":{"artifactType":{"schemaTitle":"google.VertexModel","schemaVersion":"0.0.1"},"description":"The Vertex model used for evaluation. Must be located in the same\nregion as the location argument. It is used to set the default\nconfigurations for AutoML and custom-trained models.","isOptional":true},"predictions_bigquery_source":{"artifactType":{"schemaTitle":"google.BQTable","schemaVersion":"0.0.1"},"description":"BigQuery table\nwith prediction or explanation data to be used for this evaluation. For\nprediction results, the table column should be named \"predicted_*\".","isOptional":true},"predictions_gcs_source":{"artifactType":{"schemaTitle":"system.Artifact","schemaVersion":"0.0.1"},"description":"An artifact with its\nURI pointing toward a GCS directory with prediction or explanation files\nto be used for this evaluation. For prediction results, the files should\nbe named \"prediction.results-*\" or \"predictions_\". For explanation\nresults, the files should be named \"explanation.results-*\".","isOptional":true}},"parameters":{"class_labels":{"defaultValue":[],"description":"The list of class names for the\ntarget_field_name, in the same order they appear in the batch\npredictions jobs predictions output file. For instance, if the values of\ntarget_field_name could be either ``1`` or ``0``, and the predictions output\ncontains [\"1\", \"0\"] for the prediction_label_column, then the\nclass_labels input will be [\"1\", \"0\"]. If not set, defaults to the\nclasses found in the prediction_label_column in the batch prediction\njobs predictions file.","isOptional":true,"parameterType":"LIST"},"classification_type":{"defaultValue":"multiclass","description":"The type of classification problem,\neither ``multiclass`` or ``multilabel``.","isOptional":true,"parameterType":"STRING"},"dataflow_disk_size_gb":{"defaultValue":50,"description":"The disk size (in GB) of the machine\nexecuting the evaluation run.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"dataflow_machine_type":{"defaultValue":"n1-standard-4","description":"The machine type executing the\nevaluation run.","isOptional":true,"parameterType":"STRING"},"dataflow_max_workers_num":{"defaultValue":5,"description":"The max number of workers\nexecuting the evaluation run.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"dataflow_service_account":{"defaultValue":"","description":"Service account to run\nthe Dataflow job. If not set, Dataflow will use the default worker\nservice account. For more details, see\nhttps://cloud.google.com/dataflow/docs/concepts/security-and-permissions#default_worker_service_account","isOptional":true,"parameterType":"STRING"},"dataflow_subnetwork":{"defaultValue":"","description":"Dataflow's fully qualified subnetwork\nname, when empty the default subnetwork will be used. More\ndetails:\nhttps://cloud.google.com/dataflow/docs/guides/specifying-networks#example_network_and_subnetwork_specifications","isOptional":true,"parameterType":"STRING"},"dataflow_use_public_ips":{"defaultValue":true,"description":"Specifies whether Dataflow\nworkers use public IP addresses.","isOptional":true,"parameterType":"BOOLEAN"},"dataflow_workers_num":{"defaultValue":1,"description":"The number of workers executing the\nevaluation run.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"encryption_spec_key_name":{"defaultValue":"","description":" Customer-managed encryption key options.\nIf set, resources created by this pipeline will be encrypted with the\nprovided encryption key. Has the form:\n``projects/my-project/locations/my-location/keyRings/my-kr/cryptoKeys/my-key``.\nThe key needs to be in the same region as where the compute resource is\ncreated.","isOptional":true,"parameterType":"STRING"},"force_runner_mode":{"defaultValue":"","description":"Flag to choose Beam runner. Valid options are ``DirectRunner``\nand ``Dataflow``.","isOptional":true,"parameterType":"STRING"},"ground_truth_bigquery_source":{"defaultValue":"","description":"Required for custom tabular.\nThe BigQuery table URI representing where the ground truth is located.\nUsed to provide ground truth for each prediction instance when they are\nnot part of the batch prediction jobs prediction instance.","isOptional":true,"parameterType":"STRING"},"ground_truth_format":{"defaultValue":"jsonl","description":"Required for custom tabular and non\ntabular data. The file format for the ground truth files. ``jsonl``,\n``csv``, and ``bigquery`` are the allowed formats.","isOptional":true,"parameterType":"STRING"},"ground_truth_gcs_source":{"defaultValue":[],"description":"Required for custom\ntabular and non tabular data. The GCS URIs representing where the ground\ntruth is located. Used to provide ground truth for each prediction\ninstance when they are not part of the batch prediction jobs prediction\ninstance.","isOptional":true,"parameterType":"LIST"},"location":{"defaultValue":"us-central1","description":"Location for running the evaluation.","isOptional":true,"parameterType":"STRING"},"positive_classes":{"defaultValue":[],"description":"The list of class\nnames to create binary classification metrics based on one-vs-rest for\neach value of positive_classes provided.","isOptional":true,"parameterType":"LIST"},"prediction_label_column":{"defaultValue":"prediction.classes","description":"The column name of the field\ncontaining classes the model is scoring. Formatted to be able to find\nnested columns, delimited by ``.``.","isOptional":true,"parameterType":"STRING"},"prediction_score_column":{"defaultValue":"prediction.scores","description":"The column name of the field\ncontaining batch prediction scores. Formatted to be able to find nested\ncolumns, delimited by ``.``.","isOptional":true,"parameterType":"STRING"},"predictions_format":{"defaultValue":"jsonl","description":"The file format for the batch\nprediction results. ``jsonl``, ``csv``, and ``bigquery`` are the allowed\nformats, from Vertex Batch Prediction.","isOptional":true,"parameterType":"STRING"},"project":{"description":"Project to run evaluation container.","parameterType":"STRING"},"slicing_specs":{"defaultValue":[],"description":"List of\n``google.cloud.aiplatform_v1.types.ModelEvaluationSlice.SlicingSpec``. When\nprovided, compute metrics for each defined slice. See sample code in\nhttps://cloud.google.com/vertex-ai/docs/pipelines/model-evaluation-component\nBelow is an example of how to format this input.\n\n1: First, create a SlicingSpec.\n  ``from google.cloud.aiplatform_v1.types.ModelEvaluationSlice.Slice import SliceSpec``\n\n  ``from google.cloud.aiplatform_v1.types.ModelEvaluationSlice.Slice.SliceSpec import SliceConfig``\n\n  ``slicing_spec = SliceSpec(configs={ 'feature_a': SliceConfig(SliceSpec.Value(string_value='label_a'))})``\n2: Create a list to store the slicing specs into.\n  ``slicing_specs = []``\n3: Format each SlicingSpec into a JSON or Dict.\n  ``slicing_spec_json = json_format.MessageToJson(slicing_spec)``\n  or\n  ``slicing_spec_dict = json_format.MessageToDict(slicing_spec)``\n4: Combine each slicing_spec JSON into a list.\n  ``slicing_specs.append(slicing_spec_json)``\n5: Finally, pass slicing_specs as an parameter for this component.\n  ``ModelEvaluationClassificationOp(slicing_specs=slicing_specs)``\nFor more details on configuring slices, see\nhttps://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.ModelEvaluationSlice","isOptional":true,"parameterType":"LIST"},"target_field_name":{"description":"The full name path of the features target field\nin the predictions file. Formatted to be able to find nested columns,\ndelimited by ``.``. Alternatively referred to as the ground truth (or\nground_truth_column) field.","parameterType":"STRING"}}},"outputDefinitions":{"artifacts":{"evaluation_metrics":{"artifactType":{"schemaTitle":"google.ClassificationMetrics","schemaVersion":"0.0.1"},"description":"``google.ClassificationMetrics`` representing the classification\nevaluation metrics in GCS."}},"parameters":{"gcp_resources":{"description":"Serialized gcp_resources proto tracking the Dataflow\njob. For more details, see\nhttps://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md.","parameterType":"STRING"}}}},"comp-target-field-data-remover":{"executorLabel":"exec-target-field-data-remover","inputDefinitions":{"parameters":{"bigquery_source_uri":{"defaultValue":"","description":"Google BigQuery Table URI to your\ninstances to run target field data remover on.","isOptional":true,"parameterType":"STRING"},"dataflow_service_account":{"defaultValue":"","description":"Service account to run the\ndataflow job. If not set, dataflow will use the default worker service\naccount. For more details, see\nhttps://cloud.google.com/dataflow/docs/concepts/security-and-permissions#default_worker_service_account","isOptional":true,"parameterType":"STRING"},"dataflow_subnetwork":{"defaultValue":"","description":"Dataflow's fully qualified subnetwork\nname, when empty the default subnetwork will be used. More details:\nhttps://cloud.google.com/dataflow/docs/guides/specifying-networks#example_network_and_subnetwork_specifications","isOptional":true,"parameterType":"STRING"},"dataflow_use_public_ips":{"defaultValue":true,"description":"Specifies whether Dataflow\nworkers use public IP addresses.","isOptional":true,"parameterType":"BOOLEAN"},"encryption_spec_key_name":{"defaultValue":"","description":"Customer-managed encryption key\nfor the Dataflow job. If this is set, then all resources created by the\nDataflow job will be encrypted with the provided encryption key.","isOptional":true,"parameterType":"STRING"},"force_runner_mode":{"defaultValue":"","description":"Flag to choose Beam runner. Valid options are `DirectRunner`\nand `Dataflow`.","isOptional":true,"parameterType":"STRING"},"gcs_source_uris":{"defaultValue":[],"description":"Google Cloud Storage URI(-s) to your\ninstances to run the target field data remover on. They must match\n`instances_format`. May contain wildcards. For more information on\nwildcards, see\n    https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.","isOptional":true,"parameterType":"LIST"},"instances_format":{"defaultValue":"jsonl","description":"The format in which instances are given,\nmust be one of the model's supported input storage formats. If not set,\ndefault to \"jsonl\".","isOptional":true,"parameterType":"STRING"},"location":{"defaultValue":"us-central1","description":"Location to retrieve dataset from. If not set,\ndefaulted to `us-central1`.","isOptional":true,"parameterType":"STRING"},"project":{"description":"Project to retrieve dataset from.","parameterType":"STRING"},"target_field_name":{"defaultValue":"ground_truth","description":"The name of the features target field in the\npredictions file. Formatted to be able to find nested columns for\n\"jsonl\", delimited by `.`. Alternatively referred to as the\nground_truth_column field. If not set, defaulted to `ground_truth`.","isOptional":true,"parameterType":"STRING"}}},"outputDefinitions":{"parameters":{"bigquery_output_table":{"description":"String of the downsampled dataset BigQuery\noutput.","parameterType":"STRING"},"gcp_resources":{"description":"Serialized gcp_resources proto tracking the dataflow\njob. For more details, see\nhttps://github.com/kubeflow/pipelines/blob/master/components/google-cloud/google_cloud_pipeline_components/proto/README.md.","parameterType":"STRING"},"gcs_output_directory":{"description":"JsonArray of the downsampled dataset GCS\noutput.","parameterType":"LIST"}}}},"comp-upload-tensorflow-model-to-google-cloud-vertex-ai":{"executorLabel":"exec-upload-tensorflow-model-to-google-cloud-vertex-ai","inputDefinitions":{"artifacts":{"model":{"artifactType":{"schemaTitle":"system.Artifact","schemaVersion":"0.0.1"}}},"parameters":{"description":{"isOptional":true,"parameterType":"STRING"},"display_name":{"isOptional":true,"parameterType":"STRING"},"encryption_spec_key_name":{"isOptional":true,"parameterType":"STRING"},"labels":{"isOptional":true,"parameterType":"STRUCT"},"location":{"isOptional":true,"parameterType":"STRING"},"project":{"isOptional":true,"parameterType":"STRING"},"serving_container_args":{"defaultValue":[],"isOptional":true,"parameterType":"LIST"},"staging_bucket":{"isOptional":true,"parameterType":"STRING"},"tensorflow_version":{"isOptional":true,"parameterType":"STRING"},"use_gpu":{"defaultValue":false,"isOptional":true,"parameterType":"BOOLEAN"},"use_optimized_runtime":{"defaultValue":false,"isOptional":true,"parameterType":"BOOLEAN"}}},"outputDefinitions":{"parameters":{"model_dict":{"parameterType":"STRUCT"},"model_name":{"parameterType":"STRING"}}}}},"deploymentSpec":{"executors":{"exec-bert-fine-tuning":{"container":{"args":["--type","CustomJob","--project","{{$.inputs.parameters['project']}}","--location","{{$.inputs.parameters['location']}}","--gcp_resources","{{$.outputs.parameters['gcp_resources'].output_file}}","--payload","{\"Concat\": [\"{\\\"display_name\\\": \\\"train-tfhub-model-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}\\\",\", {\"IfPresent\": {\"InputName\": \"encryption_spec_key_name\", \"Then\": {\"Concat\": [\"\\\"encryption_spec\\\": {\", \"\\\"kms_key_name\\\": \\\"\", \"{{$.inputs.parameters['encryption_spec_key_name']}}\", \"\\\"\", \"},\"]}}}, \"\\\"job_spec\\\": {\\\"worker_pool_specs\\\": [{\\\"replica_count\\\":\\\"\", \"1\", \"\\\", \\\"machine_spec\\\": {\", \"\\\"machine_type\\\": \\\"\", \"{{$.inputs.parameters['machine_type']}}\", \"\\\"\", \", \\\"accelerator_type\\\": \\\"\", \"{{$.inputs.parameters['accelerator_type']}}\", \"\\\"\", \", \\\"accelerator_count\\\": \", \"{{$.inputs.parameters['accelerator_count']}}\", \"}\", \", \\\"container_spec\\\": {\\\"image_uri\\\":\\\"\", \"us-docker.pkg.dev/cloud-aiplatform-private/automl-language/tfhub_model_trainer_image_gpu:latest\", \"\\\", \\\"args\\\": [ \\\"--input_data_path=\", \"{{$.inputs.parameters['input_data_path']}}\", \"\\\", \\\"--input_format=\", \"{{$.inputs.parameters['input_format']}}\", \"\\\", \\\"--natural_language_task_type=\", \"{{$.inputs.parameters['natural_language_task_type']}}\", \"\\\", \\\"--model_architecture=\", \"{{$.inputs.parameters['model_architecture']}}\", \"\\\", \\\"--train_batch_size=\", \"{{$.inputs.parameters['train_batch_size']}}\", \"\\\", \\\"--eval_batch_size=\", \"{{$.inputs.parameters['eval_batch_size']}}\", \"\\\", \\\"--num_epochs=\", \"{{$.inputs.parameters['num_epochs']}}\", \"\\\", \\\"--dropout=\", \"{{$.inputs.parameters['dropout']}}\", \"\\\", \\\"--initial_learning_rate=\", \"{{$.inputs.parameters['initial_learning_rate']}}\", \"\\\", \\\"--warmup=\", \"{{$.inputs.parameters['warmup']}}\", \"\\\", \\\"--optimizer_type=\", \"{{$.inputs.parameters['optimizer_type']}}\", \"\\\", \\\"--random_seed=\", \"{{$.inputs.parameters['random_seed']}}\", \"\\\", \\\"--train_steps_per_epoch=\", \"{{$.inputs.parameters['train_steps_per_epoch']}}\", \"\\\", \\\"--validation_steps_per_epoch=\", \"{{$.inputs.parameters['validation_steps_per_epoch']}}\", \"\\\", \\\"--test_steps_per_epoch=\", \"{{$.inputs.parameters['test_steps_per_epoch']}}\", \"\\\", \\\"--model_output_path=\", \"{{$.outputs.artifacts['model_output_path'].path}}\", \"\\\" ]}}]}}\"]}"],"command":["python3","-u","-m","google_cloud_pipeline_components.container.v1.custom_job.launcher"],"image":"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3"}},"exec-convert-classification-export-for-batch-predict":{"container":{"args":["--file-paths","{{$.inputs.parameters['file_paths']}}","--classification-type","{{$.inputs.parameters['classification_type']}}","--output-dir","{{$.outputs.parameters['output_dir'].output_file}}","----output-paths","{{$.outputs.parameters['output_files'].output_file}}"],"command":["sh","-ec","program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n","def _make_parent_dirs_and_return_path(file_path: str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return file_path\n\ndef convert_classification_export_for_batch_predict(\n    file_paths,\n    classification_type,\n    output_dir  # pytype: disable=invalid-annotation\n):\n  \"\"\"Converts classification dataset export for batch prediction input.\n\n  For each processed data item, there will be a JSON object with two fields: a\n  text field containing the raw text (either passed in directly or read from\n  GCS), and either a single string label or list of string labels, depending on\n  the classification type.\n\n  Args:\n    file_paths: List of URIs of the files storing the batch prediction input.\n    classification_type: String representing the problem type: either\n      'multiclass' (single-label) or 'multilabel'.\n    output_dir: GCS directory where the output files will be stored. Should be\n      generated by the pipeline.\n\n  Returns:\n    Namedtuple of one list under 'output_files' key, containing the URIs of the\n    JSONL files ready to be consumed by Vertex batch prediction.\n  \"\"\"\n  # KFP component dependencies must be imported in function body.\n  # pylint: disable=g-import-not-at-top\n  import collections\n  import json\n  import os\n  import tensorflow as tf\n  # pylint: enable=g-import-not-at-top\n\n  # All code, including these constants, must be defined within the function in\n  # order to be included in the resulting component.\n  # pylint: disable=invalid-name\n  MULTILABEL_TYPE = 'multilabel'\n\n  TEXT_KEY = 'text'\n  LABELS_KEY = 'labels'\n  CLASSIFICATION_ANNOTATION_KEY = 'classificationAnnotation'\n  CLASSIFICATION_ANNOTATIONS_KEY = 'classificationAnnotations'\n  DISPLAY_NAME_KEY = 'displayName'\n  CONTENT_KEY = 'textContent'\n  GCS_URI_KEY = 'textGcsUri'\n  # pylint: enable=invalid-name\n\n  output_file_paths = []\n  for file_path in file_paths:\n    with tf.io.gfile.GFile(file_path) as json_file:\n      output_file_path = os.path.join(output_dir, os.path.basename(file_path))\n      # Extra makedirs call to ensure all dirs are present.\n      # Without this the leaf dir may not be created.\n      os.makedirs(output_dir, exist_ok=True)\n\n      with tf.io.gfile.GFile(output_file_path, 'w') as results_file:\n        for dataset_line in json_file:\n          json_obj = json.loads(dataset_line)\n          result_list = []\n          if json_obj.get(CONTENT_KEY):\n            result_list.append(json_obj.get(CONTENT_KEY))\n          elif json_obj.get(GCS_URI_KEY):\n            with tf.io.gfile.GFile(json_obj.get(GCS_URI_KEY), 'r') as gcs_file:\n              result_list.append(gcs_file.read())\n          else:\n            raise ValueError('Text content or GCS URI must be specified.')\n          result_obj = {TEXT_KEY: result_list}\n\n          if classification_type == MULTILABEL_TYPE:\n            result_obj[LABELS_KEY] = [\n                annotation[DISPLAY_NAME_KEY]\n                for annotation in json_obj[CLASSIFICATION_ANNOTATIONS_KEY]\n            ]\n          else:\n            result_obj[LABELS_KEY] = json_obj[CLASSIFICATION_ANNOTATION_KEY][\n                DISPLAY_NAME_KEY]\n          results_file.write(json.dumps(result_obj) + '\\n')\n      # Subsequent components will not understand \"/gcs/\" path (which is\n      # apparently generated from KFP when specifying output directory). Convert\n      # to using standard \"gs://\" prefix for compatibility.\n      if output_file_path.startswith('/gcs/'):\n        output_file_path = 'gs://' + output_file_path[5:]\n      output_file_paths.append(output_file_path)\n  output_tuple = collections.namedtuple('Outputs', ['output_files'])\n  return output_tuple(output_file_paths)\n\ndef _serialize_json(obj) -> str:\n    if isinstance(obj, str):\n        return obj\n    import json\n\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n            return obj.to_struct()\n        else:\n            raise TypeError(\n                \"Object of type '%s' is not JSON serializable and does not have .to_struct() method.\"\n                % obj.__class__.__name__)\n\n    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\nimport json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Convert classification export for batch predict', description='Converts classification dataset export for batch prediction input.')\n_parser.add_argument(\"--file-paths\", dest=\"file_paths\", type=json.loads, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--classification-type\", dest=\"classification_type\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--output-dir\", dest=\"output_dir\", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = convert_classification_export_for_batch_predict(**_parsed_args)\n\n_output_serializers = [\n    _serialize_json,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],"image":"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest"}},"exec-get-task-type":{"container":{"args":["--executor_input","{{$}}","--function_to_execute","get_task_type"],"command":["sh","-ec","program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n","\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef get_task_type(classification_type: str) -> str:\n  if classification_type == 'multilabel':\n    return 'MULTICLASS_CLASSIFICATION'\n  elif classification_type == 'multiclass':\n    return 'CLASSIFICATION'\n\n  return 'UNDEFINED'\n\n"],"image":"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3"}},"exec-get-vertex-model":{"container":{"args":["--model_name","{{$.inputs.parameters['model_name']}}","--model_version","{{$.inputs.parameters['model_version']}}","--gcp_resources","{{$.outputs.parameters['gcp_resources'].output_file}}","--executor_input","{{$}}"],"command":["python3","-u","-m","google_cloud_pipeline_components.container._implementation.model.get_model.get_model"],"image":"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.1.0"}},"exec-model-batch-predict":{"container":{"args":["--type","BatchPredictionJob","--payload","{\"Concat\": [\"{\", \"\\\"display_name\\\": \\\"\", \"{{$.inputs.parameters['job_display_name']}}\", \"\\\", \", {\"IfPresent\": {\"InputName\": \"model\", \"Then\": {\"Concat\": [\"\\\"model\\\": \\\"\", \"{{$.inputs.artifacts['model'].metadata['resourceName']}}\", \"\\\",\"]}}}, \" \\\"input_config\\\": {\", \"\\\"instances_format\\\": \\\"\", \"{{$.inputs.parameters['instances_format']}}\", \"\\\"\", \", \\\"gcs_source\\\": {\", \"\\\"uris\\\":\", \"{{$.inputs.parameters['gcs_source_uris']}}\", \"}\", \", \\\"bigquery_source\\\": {\", \"\\\"input_uri\\\": \\\"\", \"{{$.inputs.parameters['bigquery_source_input_uri']}}\", \"\\\"\", \"}\", \"}\", \", \\\"instance_config\\\": {\", \"\\\"instance_type\\\": \\\"\", \"{{$.inputs.parameters['instance_type']}}\", \"\\\"\", \", \\\"key_field\\\": \\\"\", \"{{$.inputs.parameters['key_field']}}\", \"\\\" \", {\"IfPresent\": {\"InputName\": \"included_fields\", \"Then\": {\"Concat\": [\", \\\"included_fields\\\": \", \"{{$.inputs.parameters['included_fields']}}\"]}}}, {\"IfPresent\": {\"InputName\": \"excluded_fields\", \"Then\": {\"Concat\": [\", \\\"excluded_fields\\\": \", \"{{$.inputs.parameters['excluded_fields']}}\"]}}}, \"}\", \", \\\"model_parameters\\\": \", \"{{$.inputs.parameters['model_parameters']}}\", \", \\\"output_config\\\": {\", \"\\\"predictions_format\\\": \\\"\", \"{{$.inputs.parameters['predictions_format']}}\", \"\\\"\", \", \\\"gcs_destination\\\": {\", \"\\\"output_uri_prefix\\\": \\\"\", \"{{$.inputs.parameters['gcs_destination_output_uri_prefix']}}\", \"\\\"\", \"}\", \", \\\"bigquery_destination\\\": {\", \"\\\"output_uri\\\": \\\"\", \"{{$.inputs.parameters['bigquery_destination_output_uri']}}\", \"\\\"\", \"}\", \"}\", \", \\\"dedicated_resources\\\": {\", \"\\\"machine_spec\\\": {\", \"\\\"machine_type\\\": \\\"\", \"{{$.inputs.parameters['machine_type']}}\", \"\\\"\", \", \\\"accelerator_type\\\": \\\"\", \"{{$.inputs.parameters['accelerator_type']}}\", \"\\\"\", \", \\\"accelerator_count\\\": \", \"{{$.inputs.parameters['accelerator_count']}}\", \"}\", \", \\\"starting_replica_count\\\": \", \"{{$.inputs.parameters['starting_replica_count']}}\", \", \\\"max_replica_count\\\": \", \"{{$.inputs.parameters['max_replica_count']}}\", \"}\", \", \\\"manual_batch_tuning_parameters\\\": {\", \"\\\"batch_size\\\": \", \"{{$.inputs.parameters['manual_batch_tuning_parameters_batch_size']}}\", \"}\", \", \\\"generate_explanation\\\": \", \"{{$.inputs.parameters['generate_explanation']}}\", \", \\\"explanation_spec\\\": {\", \"\\\"parameters\\\": \", \"{{$.inputs.parameters['explanation_parameters']}}\", \", \\\"metadata\\\": \", \"{{$.inputs.parameters['explanation_metadata']}}\", \"}\", \", \\\"labels\\\": \", \"{{$.inputs.parameters['labels']}}\", \", \\\"encryption_spec\\\": {\\\"kms_key_name\\\":\\\"\", \"{{$.inputs.parameters['encryption_spec_key_name']}}\", \"\\\"}\", \"}\"]}","--project","{{$.inputs.parameters['project']}}","--location","{{$.inputs.parameters['location']}}","--gcp_resources","{{$.outputs.parameters['gcp_resources'].output_file}}","--executor_input","{{$}}"],"command":["python3","-u","-m","google_cloud_pipeline_components.container.v1.batch_prediction_job.launcher"],"image":"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.1.0"}},"exec-model-evaluation-classification":{"container":{"args":["--setup_file","/setup.py","--json_mode","true","--project_id","{{$.inputs.parameters['project']}}","--location","{{$.inputs.parameters['location']}}","--problem_type","classification","--target_field_name","{\"Concat\": [\"instance.\", \"{{$.inputs.parameters['target_field_name']}}\"]}","--batch_prediction_format","{{$.inputs.parameters['predictions_format']}}","{\"IfPresent\": {\"InputName\": \"predictions_gcs_source\", \"Then\": [\"--batch_prediction_gcs_source\", \"{{$.inputs.artifacts['predictions_gcs_source'].uri}}\"]}}","{\"IfPresent\": {\"InputName\": \"predictions_bigquery_source\", \"Then\": [\"--batch_prediction_bigquery_source\", {\"Concat\": [\"bq://\", \"{{$.inputs.artifacts['predictions_bigquery_source'].metadata['projectId']}}\", \".\", \"{{$.inputs.artifacts['predictions_bigquery_source'].metadata['datasetId']}}\", \".\", \"{{$.inputs.artifacts['predictions_bigquery_source'].metadata['tableId']}}\"]}]}}","{\"IfPresent\": {\"InputName\": \"model\", \"Then\": [\"--model_name\", \"{{$.inputs.artifacts['model'].metadata['resourceName']}}\"]}}","--ground_truth_format","{{$.inputs.parameters['ground_truth_format']}}","--ground_truth_gcs_source","{{$.inputs.parameters['ground_truth_gcs_source']}}","--ground_truth_bigquery_source","{{$.inputs.parameters['ground_truth_bigquery_source']}}","--root_dir","{{$.pipeline_root}}/{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}","--classification_type","{{$.inputs.parameters['classification_type']}}","--class_labels","{{$.inputs.parameters['class_labels']}}","--prediction_score_column","{{$.inputs.parameters['prediction_score_column']}}","--prediction_label_column","{{$.inputs.parameters['prediction_label_column']}}","{\"IfPresent\": {\"InputName\": \"slicing_specs\", \"Then\": [\"--slicing_specs\", \"{{$.inputs.parameters['slicing_specs']}}\"]}}","--positive_classes","{{$.inputs.parameters['positive_classes']}}","--dataflow_job_prefix","evaluation-classification-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}","--dataflow_service_account","{{$.inputs.parameters['dataflow_service_account']}}","--dataflow_disk_size","{{$.inputs.parameters['dataflow_disk_size_gb']}}","--dataflow_machine_type","{{$.inputs.parameters['dataflow_machine_type']}}","--dataflow_workers_num","{{$.inputs.parameters['dataflow_workers_num']}}","--dataflow_max_workers_num","{{$.inputs.parameters['dataflow_max_workers_num']}}","--dataflow_subnetwork","{{$.inputs.parameters['dataflow_subnetwork']}}","--dataflow_use_public_ips","{{$.inputs.parameters['dataflow_use_public_ips']}}","--kms_key_name","{{$.inputs.parameters['encryption_spec_key_name']}}","--force_runner_mode","{{$.inputs.parameters['force_runner_mode']}}","--output_metrics_gcs_path","{{$.outputs.artifacts['evaluation_metrics'].path}}","--gcp_resources","{{$.outputs.parameters['gcp_resources'].output_file}}","--executor_input","{{$}}"],"command":["python3","/main.py"],"image":"gcr.io/ml-pipeline/model-evaluation:v0.9.2"}},"exec-target-field-data-remover":{"container":{"args":["--task","data_splitter","--display_name","target-field-data-remover","--project_id","{{$.inputs.parameters['project']}}","--location","{{$.inputs.parameters['location']}}","--root_dir","{{$.pipeline_root}}/{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}","--gcs_source_uris","{{$.inputs.parameters['gcs_source_uris']}}","--bigquery_source_uri","{{$.inputs.parameters['bigquery_source_uri']}}","--instances_format","{{$.inputs.parameters['instances_format']}}","--target_field_name","{{$.inputs.parameters['target_field_name']}}","--dataflow_job_prefix","evaluation-target-field-remover-{{$.pipeline_job_uuid}}-{{$.pipeline_task_uuid}}","--dataflow_service_account","{{$.inputs.parameters['dataflow_service_account']}}","--dataflow_subnetwork","{{$.inputs.parameters['dataflow_subnetwork']}}","--dataflow_use_public_ips","{{$.inputs.parameters['dataflow_use_public_ips']}}","--kms_key_name","{{$.inputs.parameters['encryption_spec_key_name']}}","--force_runner_mode","{{$.inputs.parameters['force_runner_mode']}}","--gcs_directory_for_gcs_output_uris","{{$.outputs.parameters['gcs_output_directory'].output_file}}","--gcs_directory_for_bigquery_output_table_uri","{{$.outputs.parameters['bigquery_output_table'].output_file}}","--gcp_resources","{{$.outputs.parameters['gcp_resources'].output_file}}","--executor_input","{{$}}"],"command":["python3","/main.py"],"image":"gcr.io/ml-pipeline/model-evaluation:v0.9.2"}},"exec-upload-tensorflow-model-to-google-cloud-vertex-ai":{"container":{"args":["--model","{{$.inputs.artifacts['model'].path}}","{\"IfPresent\": {\"InputName\": \"tensorflow_version\", \"Then\": [\"--tensorflow-version\", \"{{$.inputs.parameters['tensorflow_version']}}\"]}}","{\"IfPresent\": {\"InputName\": \"use_gpu\", \"Then\": [\"--use-gpu\", \"{{$.inputs.parameters['use_gpu']}}\"]}}","{\"IfPresent\": {\"InputName\": \"use_optimized_runtime\", \"Then\": [\"--use-optimized-runtime\", \"{{$.inputs.parameters['use_optimized_runtime']}}\"]}}","{\"IfPresent\": {\"InputName\": \"serving_container_args\", \"Then\": [\"--serving-container-args\", \"{{$.inputs.parameters['serving_container_args']}}\"]}}","{\"IfPresent\": {\"InputName\": \"display_name\", \"Then\": [\"--display-name\", \"{{$.inputs.parameters['display_name']}}\"]}}","{\"IfPresent\": {\"InputName\": \"description\", \"Then\": [\"--description\", \"{{$.inputs.parameters['description']}}\"]}}","{\"IfPresent\": {\"InputName\": \"project\", \"Then\": [\"--project\", \"{{$.inputs.parameters['project']}}\"]}}","{\"IfPresent\": {\"InputName\": \"location\", \"Then\": [\"--location\", \"{{$.inputs.parameters['location']}}\"]}}","{\"IfPresent\": {\"InputName\": \"labels\", \"Then\": [\"--labels\", \"{{$.inputs.parameters['labels']}}\"]}}","{\"IfPresent\": {\"InputName\": \"staging_bucket\", \"Then\": [\"--staging-bucket\", \"{{$.inputs.parameters['staging_bucket']}}\"]}}","{\"IfPresent\": {\"InputName\": \"encryption_spec_key_name\", \"Then\": [\"--encryption-spec-key-name\", \"{{$.inputs.parameters['encryption_spec_key_name']}}\"]}}","----output-paths","{{$.outputs.parameters['model_name'].output_file}}","{{$.outputs.parameters['model_dict'].output_file}}"],"command":["sh","-ec","program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n","def upload_Tensorflow_model_to_Google_Cloud_Vertex_AI(\n    model_path,\n    tensorflow_version = None,\n    use_gpu = False,\n    use_optimized_runtime = False,\n    serving_container_args = None,\n\n    display_name = None,\n    description = None,\n\n    # Uncomment when anyone requests these:\n    # instance_schema_uri: str = None,\n    # parameters_schema_uri: str = None,\n    # prediction_schema_uri: str = None,\n    # explanation_metadata: \"google.cloud.aiplatform_v1.types.explanation_metadata.ExplanationMetadata\" = None,\n    # explanation_parameters: \"google.cloud.aiplatform_v1.types.explanation.ExplanationParameters\" = None,\n\n    project = None,\n    location = None,\n    labels = None,\n    encryption_spec_key_name: str = None,\n    staging_bucket = None,\n):\n    import json\n    import os\n    from google.cloud import aiplatform\n\n    if not location:\n        location = os.environ.get(\"CLOUD_ML_REGION\")\n\n    if not labels:\n        labels = {}\n    labels[\"component-source\"] = \"github-com-ark-kun-pipeline-components\"\n\n    if use_optimized_runtime:\n        device_type = \"gpu\" if use_gpu else \"cpu\"\n        if not tensorflow_version:\n            tensorflow_version = \"2-11\"\n        serving_container_image_uri = f\"us-docker.pkg.dev/vertex-ai-restricted/prediction/tf_opt-{device_type}.{tensorflow_version}:latest\"\n        model = aiplatform.Model.upload(\n            serving_container_image_uri=serving_container_image_uri,\n            serving_container_args=serving_container_args,\n            artifact_uri=model_path,\n            display_name=display_name,\n            description=description,\n            # instance_schema_uri=instance_schema_uri,\n            # parameters_schema_uri=parameters_schema_uri,\n            # prediction_schema_uri=prediction_schema_uri,\n            # explanation_metadata=explanation_metadata,\n            # explanation_parameters=explanation_parameters,\n            project=project,\n            location=location,\n            labels=labels,\n            encryption_spec_key_name=encryption_spec_key_name,\n            staging_bucket=staging_bucket,\n        )\n    else:\n        model = aiplatform.Model.upload_tensorflow_saved_model(\n            saved_model_dir=model_path,\n            tensorflow_version=tensorflow_version,\n            use_gpu=use_gpu,\n            display_name=display_name,\n            description=description,\n            # instance_schema_uri=instance_schema_uri,\n            # parameters_schema_uri=parameters_schema_uri,\n            # prediction_schema_uri=prediction_schema_uri,\n            # explanation_metadata=explanation_metadata,\n            # explanation_parameters=explanation_parameters,\n            project=project,\n            location=location,\n            labels=labels,\n            encryption_spec_key_name=encryption_spec_key_name,\n            staging_bucket=staging_bucket,\n        )\n\n    model_json = json.dumps(model.to_dict(), indent=2)\n    print(model_json)\n    return (model.resource_name, model_json)\n\ndef _deserialize_bool(s) -> bool:\n    from distutils.util import strtobool\n    return strtobool(s) == 1\n\ndef _serialize_json(obj) -> str:\n    if isinstance(obj, str):\n        return obj\n    import json\n    def default_serializer(obj):\n        if hasattr(obj, 'to_struct'):\n            return obj.to_struct()\n        else:\n            raise TypeError(\"Object of type '%s' is not JSON serializable and does not have .to_struct() method.\" % obj.__class__.__name__)\n    return json.dumps(obj, default=default_serializer, sort_keys=True)\n\ndef _serialize_str(str_value: str) -> str:\n    if not isinstance(str_value, str):\n        raise TypeError('Value \"{}\" has type \"{}\" instead of str.'.format(str(str_value), str(type(str_value))))\n    return str_value\n\nimport json\nimport argparse\n_parser = argparse.ArgumentParser(prog='Upload Tensorflow model to Google Cloud Vertex AI', description='')\n_parser.add_argument(\"--model\", dest=\"model_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--tensorflow-version\", dest=\"tensorflow_version\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--use-gpu\", dest=\"use_gpu\", type=_deserialize_bool, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--use-optimized-runtime\", dest=\"use_optimized_runtime\", type=_deserialize_bool, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--serving-container-args\", dest=\"serving_container_args\", type=json.loads, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--display-name\", dest=\"display_name\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--description\", dest=\"description\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--project\", dest=\"project\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--location\", dest=\"location\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--labels\", dest=\"labels\", type=json.loads, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--staging-bucket\", dest=\"staging_bucket\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"--encryption-spec-key-name\", dest=\"encryption_spec_key_name\", type=str, required=False, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=2)\n_parsed_args = vars(_parser.parse_args())\n_output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = upload_Tensorflow_model_to_Google_Cloud_Vertex_AI(**_parsed_args)\n\n_output_serializers = [\n    _serialize_str,\n    _serialize_json,\n\n]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n        pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],"image":"gcr.io/ml-pipeline/google-cloud-pipeline-components:2.0.0b3"}}}},"pipelineInfo":{"description":"Runs BERT fine-tuning pipeline.\nNote: These parameters default to those used by AutoML text models, and may\nneed to be changed for custom models. See this link for batch prediction\noutput formats:\nhttps://cloud.google.com/vertex-ai/docs/predictions/batch-predictions#example_batch_prediction_results","name":"bert-finetuning"},"root":{"dag":{"tasks":{"bert-fine-tuning":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-bert-fine-tuning"},"dependentTasks":["get-task-type"],"inputs":{"parameters":{"accelerator_count":{"componentInputParameter":"accelerator_count"},"accelerator_type":{"componentInputParameter":"accelerator_type"},"dropout":{"componentInputParameter":"dropout"},"encryption_spec_key_name":{"componentInputParameter":"encryption_spec_key_name"},"eval_batch_size":{"componentInputParameter":"eval_batch_size"},"initial_learning_rate":{"componentInputParameter":"initial_learning_rate"},"input_data_path":{"componentInputParameter":"training_data_path"},"input_format":{"componentInputParameter":"ground_truth_format"},"location":{"componentInputParameter":"location"},"machine_type":{"componentInputParameter":"compute_machine_type"},"model_architecture":{"componentInputParameter":"model_architecture"},"natural_language_task_type":{"taskOutputParameter":{"outputParameterKey":"Output","producerTask":"get-task-type"}},"num_epochs":{"componentInputParameter":"num_epochs"},"optimizer_type":{"componentInputParameter":"optimizer_type"},"project":{"componentInputParameter":"project"},"random_seed":{"componentInputParameter":"random_seed"},"test_steps_per_epoch":{"componentInputParameter":"test_steps_per_epoch"},"train_batch_size":{"componentInputParameter":"train_batch_size"},"train_steps_per_epoch":{"componentInputParameter":"train_steps_per_epoch"},"validation_steps_per_epoch":{"componentInputParameter":"validation_steps_per_epoch"},"warmup":{"componentInputParameter":"warmup"}}},"taskInfo":{"name":"bert-fine-tuning"}},"convert-classification-export-for-batch-predict":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-convert-classification-export-for-batch-predict"},"inputs":{"parameters":{"classification_type":{"componentInputParameter":"classification_type"},"file_paths":{"componentInputParameter":"ground_truth_gcs_source_uris"}}},"taskInfo":{"name":"convert-classification-export-for-batch-predict"}},"get-task-type":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-get-task-type"},"inputs":{"parameters":{"classification_type":{"componentInputParameter":"classification_type"}}},"taskInfo":{"name":"get-task-type"}},"get-vertex-model":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-get-vertex-model"},"dependentTasks":["upload-tensorflow-model-to-google-cloud-vertex-ai"],"inputs":{"parameters":{"model_name":{"taskOutputParameter":{"outputParameterKey":"model_name","producerTask":"upload-tensorflow-model-to-google-cloud-vertex-ai"}}}},"taskInfo":{"name":"get-vertex-model"}},"model-batch-predict":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-model-batch-predict"},"dependentTasks":["get-vertex-model","target-field-data-remover"],"inputs":{"artifacts":{"model":{"taskOutputArtifact":{"outputArtifactKey":"model","producerTask":"get-vertex-model"}}},"parameters":{"accelerator_count":{"runtimeValue":{"constant":1}},"accelerator_type":{"componentInputParameter":"accelerator_type"},"encryption_spec_key_name":{"componentInputParameter":"model_encryption_spec_key_name"},"gcs_destination_output_uri_prefix":{"componentInputParameter":"root_dir"},"gcs_source_uris":{"taskOutputParameter":{"outputParameterKey":"gcs_output_directory","producerTask":"target-field-data-remover"}},"instances_format":{"componentInputParameter":"ground_truth_format"},"job_display_name":{"runtimeValue":{"constant":"nl-batch-predict-evaluation"}},"location":{"componentInputParameter":"upload_model_location"},"machine_type":{"componentInputParameter":"compute_machine_type"},"predictions_format":{"runtimeValue":{"constant":"jsonl"}},"project":{"componentInputParameter":"project"}}},"taskInfo":{"name":"model-batch-predict"}},"model-evaluation-classification":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-model-evaluation-classification"},"dependentTasks":["convert-classification-export-for-batch-predict","model-batch-predict"],"inputs":{"artifacts":{"predictions_gcs_source":{"taskOutputArtifact":{"outputArtifactKey":"gcs_output_directory","producerTask":"model-batch-predict"}}},"parameters":{"class_labels":{"componentInputParameter":"class_labels"},"classification_type":{"componentInputParameter":"classification_type"},"encryption_spec_key_name":{"componentInputParameter":"model_encryption_spec_key_name"},"ground_truth_format":{"componentInputParameter":"ground_truth_format"},"ground_truth_gcs_source":{"taskOutputParameter":{"outputParameterKey":"output_files","producerTask":"convert-classification-export-for-batch-predict"}},"location":{"componentInputParameter":"upload_model_location"},"prediction_label_column":{"runtimeValue":{"constant":"prediction.displayNames"}},"prediction_score_column":{"runtimeValue":{"constant":"prediction.confidences"}},"predictions_format":{"runtimeValue":{"constant":"jsonl"}},"project":{"componentInputParameter":"project"},"target_field_name":{"componentInputParameter":"target_field_name"}}},"taskInfo":{"name":"model-evaluation-classification"}},"target-field-data-remover":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-target-field-data-remover"},"dependentTasks":["convert-classification-export-for-batch-predict"],"inputs":{"parameters":{"encryption_spec_key_name":{"componentInputParameter":"model_encryption_spec_key_name"},"gcs_source_uris":{"taskOutputParameter":{"outputParameterKey":"output_files","producerTask":"convert-classification-export-for-batch-predict"}},"instances_format":{"componentInputParameter":"ground_truth_format"},"location":{"componentInputParameter":"upload_model_location"},"project":{"componentInputParameter":"project"},"target_field_name":{"componentInputParameter":"target_field_name"}}},"taskInfo":{"name":"target-field-data-remover"}},"upload-tensorflow-model-to-google-cloud-vertex-ai":{"cachingOptions":{"enableCache":true},"componentRef":{"name":"comp-upload-tensorflow-model-to-google-cloud-vertex-ai"},"dependentTasks":["bert-fine-tuning"],"inputs":{"artifacts":{"model":{"taskOutputArtifact":{"outputArtifactKey":"model_output_path","producerTask":"bert-fine-tuning"}}},"parameters":{"display_name":{"componentInputParameter":"model_display_name"},"encryption_spec_key_name":{"componentInputParameter":"model_encryption_spec_key_name"},"location":{"componentInputParameter":"upload_model_location"},"project":{"componentInputParameter":"project"},"serving_container_args":{"runtimeValue":{"constant":["--allow_precompilation","--allow_compression"]}},"use_gpu":{"runtimeValue":{"constant":true}},"use_optimized_runtime":{"runtimeValue":{"constant":true}}}},"taskInfo":{"name":"upload-tensorflow-model-to-google-cloud-vertex-ai"}}}},"inputDefinitions":{"parameters":{"accelerator_count":{"defaultValue":1,"description":"Number of accelerators to use.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"accelerator_type":{"defaultValue":"NVIDIA_TESLA_T4","description":"Type of accelerator to use. See\nhttps://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus\nfor full list.","isOptional":true,"parameterType":"STRING"},"class_labels":{"description":"List of class labels.","parameterType":"LIST"},"classification_type":{"defaultValue":"multiclass","description":"Type of classification problem. Should either be\n`multiclass` or `multilabel` (defaults to `multiclass`).","isOptional":true,"parameterType":"STRING"},"compute_machine_type":{"defaultValue":"n1-highmem-8","description":"Type of machine for running batch prediction. See\nhttps://cloud.google.com/vertex-ai/docs/predictions/configure-compute#machine-types\nfor full list.","isOptional":true,"parameterType":"STRING"},"dropout":{"defaultValue":0.35,"description":"Dropout rate for model.","isOptional":true,"parameterType":"NUMBER_DOUBLE"},"encryption_spec_key_name":{"description":"Customer-managed encryption key.\nIf this is set, then all resources created by the PipelineJob will be\nencrypted with the provided encryption key.","parameterType":"STRING"},"eval_batch_size":{"defaultValue":32,"description":"Number of samples per validation/test batch.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"ground_truth_format":{"defaultValue":"jsonl","description":"Format of the ground truth file(s). Should be either\n`jsonl` or `csv` (defaults to `jsonl`).","isOptional":true,"parameterType":"STRING"},"ground_truth_gcs_source_uris":{"description":"List of URIs of the files containing the\nground truth. May contain wildcards.","parameterType":"LIST"},"initial_learning_rate":{"defaultValue":0.0001,"description":"Initial learning rate for model (or initial rate\nafter warmup steps).","isOptional":true,"parameterType":"NUMBER_DOUBLE"},"location":{"defaultValue":"us-central1","description":"Location for running the pipeline (defaults to `us-central1`).","isOptional":true,"parameterType":"STRING"},"model_architecture":{"defaultValue":"MULTILINGUAL_BERT_BASE_CASED","isOptional":true,"parameterType":"STRING"},"model_display_name":{"defaultValue":"bert-finetuned-model","description":"Display name to be used for uploading model. (defaults\nto `bert-finetuned-model`).","isOptional":true,"parameterType":"STRING"},"model_encryption_spec_key_name":{"description":"Customer-managed encryption key.\nIf this is set, then all Model related resources created will be\nencrypted with the provided encryption key.","parameterType":"STRING"},"num_epochs":{"defaultValue":30,"description":"Max number of epochs to train on (may end early due to\nearly-stopping policy).","isOptional":true,"parameterType":"NUMBER_INTEGER"},"optimizer_type":{"defaultValue":"lamb","description":"Type of optimizer to use during training. Options are\n['lamb', 'adamw'].","isOptional":true,"parameterType":"STRING"},"project":{"description":"Name of the GCP project.","parameterType":"STRING"},"random_seed":{"defaultValue":0,"description":"Random seed, set for reproducibility.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"root_dir":{"description":"GCS directory for staging files.","parameterType":"STRING"},"target_field_name":{"defaultValue":"labels","description":"Column name of the field containing the ground truth\nlabel.","isOptional":true,"parameterType":"STRING"},"test_steps_per_epoch":{"defaultValue":-1,"description":"Number of test steps per epoch, should only be used\nfor distributed training (multi-worker/multi-gpu).","isOptional":true,"parameterType":"NUMBER_INTEGER"},"train_batch_size":{"defaultValue":32,"description":"Number of samples per training batch.","isOptional":true,"parameterType":"NUMBER_INTEGER"},"train_steps_per_epoch":{"defaultValue":-1,"description":"Number of training steps per epoch, should only be\nused for distributed training (multi-worker/multi-gpu).","isOptional":true,"parameterType":"NUMBER_INTEGER"},"training_data_path":{"description":"GCS path to the file where data is stored. Should\ncontain all data splits (train, test, validation).","parameterType":"STRING"},"upload_model_location":{"defaultValue":"us-central1","description":"Location for uploading fine-tuned Vertex Model\n(defaults to `us-central1`).","isOptional":true,"parameterType":"STRING"},"validation_steps_per_epoch":{"defaultValue":-1,"description":"Number of validation steps per epoch, should\nonly be used for distributed training (multi-worker/multi-gpu).","isOptional":true,"parameterType":"NUMBER_INTEGER"},"warmup":{"defaultValue":0.1,"description":"Fraction of training steps to slowly increase learning rate up to\ninitial_learning_rate. Note that the 'lamb' optimizer will ignore this as\nit has built-in warmup.","isOptional":true,"parameterType":"NUMBER_DOUBLE"}}}},"schemaVersion":"2.1.0","sdkVersion":"kfp-2.0.0"}