{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Gemini: An Overview of Multimodal Use Cases\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fintro_multimodal_use_cases.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/3DUssjz\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HKLOuOlJutv"
   },
   "source": [
    "| Authors |\n",
    "| --- |\n",
    "| [Katie Nguyen](https://github.com/katiemn) |\n",
    "| [Saeed Aghabozorgi](https://github.com/saeedaghabozorgi) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Multimodal AI in action**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=pEmCgIGpIoo&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/pEmCgIGpIoo/maxresdefault.jpg\" alt=\"Multimodal AI in action\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "In this notebook, you will explore a variety of different use cases enabled by multimodality with Gemini.\n",
    "\n",
    "Gemini is a family of generative AI models developed by [Google DeepMind](https://deepmind.google/) that is designed for multimodal use cases. [Gemini 2.0](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2) is the latest model version.\n",
    "\n",
    "### Gemini 2.0 Flash\n",
    "\n",
    "This smaller Gemini model is optimized for high-frequency tasks to prioritize the model's response time. This model has superior speed and efficiency with a context window of up to 1 million tokens for all modalities.\n",
    "\n",
    "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "This notebook demonstrates a variety of multimodal use cases with Gemini.\n",
    "\n",
    "In this tutorial, you will learn how to use Gemini with the Gen AI SDK for Python to:\n",
    "\n",
    "  - Process and generate text\n",
    "  - Parse and summarize PDF documents\n",
    "  - Reason across multiple images\n",
    "  - Generating a video description\n",
    "  - Combining video data with external knowledge\n",
    "  - Understand Audio\n",
    "  - Analyze a code base\n",
    "  - Combine modalities\n",
    "  - Recommendation based on user preferences for e-commerce\n",
    "  - Understanding charts and diagrams\n",
    "  - Comparing images for similarities, anomalies, or differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhsUe0fyc-ER"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Install Google Gen AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kc4WxYmLSBW5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai gitingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. The restart might take a minute or longer. After it's restarted, continue to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LCaCx6PLSBW6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGB8Txa_e4V0"
   },
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JGOJHtgDe5-r"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-03-9d4e440cc380\" # \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"europe-west4\" # \"[your-region]\"  # @param {type:\"string\"}\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JTk488WDPBtQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-09 02:13:10.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:16.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:16.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:28.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:39.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:40.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:45.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:45.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:51.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:51.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:56.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:57.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:14:02.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:14:02.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:14:32.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:14:32.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m89\u001b[0m | Starting ingestion process | {\"source\":\"https://github.com/GoogleCloudPlatform/microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:32.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m98\u001b[0m | Parsing remote repository | {\"source\":\"https://github.com/GoogleCloudPlatform/microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:32.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m56\u001b[0m | Starting git clone operation | {\"url\":\"https://github.com/googlecloudplatform/microservices-demo\",\"local_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\",\"partial_clone\":false,\"subpath\":\"/\",\"branch\":null,\"tag\":null,\"commit\":\"895c9f20cd0cc31146122b49ab251756069e97be\",\"include_submodules\":false}\n",
      "\u001b[32m2025-10-09 02:14:33.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1740\u001b[0m | HTTP Request: HEAD https://github.com/googlecloudplatform/microservices-demo \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:14:33.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m97\u001b[0m | Executing git clone command | {\"command\":\"git clone --single-branch --no-checkout --depth=1 https://github.com/googlecloudplatform/microservices-demo <url> /var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:34.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m99\u001b[0m | Git clone completed successfully\n",
      "\u001b[32m2025-10-09 02:14:34.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m114\u001b[0m | Checking out commit | {\"commit\":\"895c9f20cd0cc31146122b49ab251756069e97be\"}\n",
      "\u001b[32m2025-10-09 02:14:34.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m123\u001b[0m | Git clone operation completed successfully | {\"local_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:34.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m132\u001b[0m | Repository cloned, starting file processing\n",
      "\u001b[32m2025-10-09 02:14:34.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m140\u001b[0m | Processing files and generating output\n",
      "\u001b[32m2025-10-09 02:14:34.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.ingestion\u001b[0m:\u001b[36mingest_query\u001b[0m:\u001b[36m44\u001b[0m | Starting file ingestion | {\"slug\":\"googlecloudplatform-microservices-demo\",\"subpath\":\"/\",\"local_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\",\"max_file_size\":10485760}\n",
      "\u001b[32m2025-10-09 02:14:34.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.ingestion\u001b[0m:\u001b[36mingest_query\u001b[0m:\u001b[36m96\u001b[0m | Processing directory | {\"directory_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:35.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.ingestion\u001b[0m:\u001b[36mingest_query\u001b[0m:\u001b[36m109\u001b[0m | Directory processing completed | {\"total_files\":309,\"total_directories\":90,\"total_size_bytes\":1498427,\"stats_total_files\":309,\"stats_total_size\":1498427}\n",
      "\u001b[32m2025-10-09 02:14:39.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m147\u001b[0m | Ingestion completed successfully\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio, Image, Markdown, Video, display\n",
    "from gitingest import ingest\n",
    "from google.genai.types import CreateCachedContentConfig, GenerateContentConfig, Part\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTNnM-lqfQRo"
   },
   "source": [
    "### Load Gemini 2.0 Flash model\n",
    "\n",
    "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2998506fe6d1"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06354c53e1a8"
   },
   "source": [
    "## Combining multiple modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3c00e534189b"
   },
   "source": [
    "### Video and audio understanding\n",
    "\n",
    "Try out Gemini's native multimodal and long-context capabilities on video interleaving with audio inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "41b5bb1b04c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/pixel8.mp4\" controls  width=\"350\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_url = (\n",
    "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/pixel8.mp4\"\n",
    ")\n",
    "display(Video(video_url, width=350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "a29e43974ca9"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here's a detailed description of the video:\n",
       "\n",
       "The video begins with an aerial shot of a dimly lit, urban area at night, featuring a train track, parked cars, and buildings.  The camera then transitions to a woman, Saeka Shimada, standing on a street in Tokyo. She introduces herself as a photographer in Tokyo and states that Tokyo has many faces, and its nighttime appearance is totally different from during the day.\n",
       "\n",
       "Next, the text on screen reads, “The new Pixel has a feature called ‘Video Boost.’ Coming soon. Pixel 8 Pro only. Requires Google Photos app.” Saeka shares that the new Pixel has a \"Video Boost\" feature, and in low light, \"Night Sight\" activates to improve the quality even more. Saeka takes a few photos as she walks down the narrow alleyway, taking in the different signs, storefronts, and lanterns, as well as reflections on the wet ground. \n",
       "\n",
       "She is now at a new destination, and shares that, “San-cha is where I used to live when I first moved to Tokyo.” \n",
       "\n",
       "Saeka expresses her appreciation for the location and takes more pictures and videos with her new Pixel.\n",
       "\n",
       "Saeka states, “Next, I came to Shibuya,” as the camera shows several lines of taxis, which are commonplace in Tokyo. Next, there is a bridge shown, with several figures walking across the walkway, waving down to someone they recognize.\n",
       "\n",
       "Regarding the new Pixel, the video indicates that the phone includes a new feature called “Video Boost” with the “Night Sight” function being activated in dimly lit areas. It also indicates that the “Video Boost” feature will be available on the Pixel 8 Pro and is required for Google Photos app users.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "  Provide a detailed description of the video.\n",
    "  The description should also contain any important dialogue from the video and key features of the phone.\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(\n",
    "    file_uri=video_url,\n",
    "    mime_type=\"video/mp4\",\n",
    ")\n",
    "contents = [prompt, video]\n",
    "\n",
    "response = client.models.generate_content(model=MODEL_ID, contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_multimodal_use_cases.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
