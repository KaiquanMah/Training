{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Gemini: An Overview of Multimodal Use Cases\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fuse-cases%2Fintro_multimodal_use_cases.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/3DUssjz\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/use-cases/intro_multimodal_use_cases.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HKLOuOlJutv"
   },
   "source": [
    "| Authors |\n",
    "| --- |\n",
    "| [Katie Nguyen](https://github.com/katiemn) |\n",
    "| [Saeed Aghabozorgi](https://github.com/saeedaghabozorgi) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Multimodal AI in action**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=pEmCgIGpIoo&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/pEmCgIGpIoo/maxresdefault.jpg\" alt=\"Multimodal AI in action\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "In this notebook, you will explore a variety of different use cases enabled by multimodality with Gemini.\n",
    "\n",
    "Gemini is a family of generative AI models developed by [Google DeepMind](https://deepmind.google/) that is designed for multimodal use cases. [Gemini 2.0](https://cloud.google.com/vertex-ai/generative-ai/docs/gemini-v2) is the latest model version.\n",
    "\n",
    "### Gemini 2.0 Flash\n",
    "\n",
    "This smaller Gemini model is optimized for high-frequency tasks to prioritize the model's response time. This model has superior speed and efficiency with a context window of up to 1 million tokens for all modalities.\n",
    "\n",
    "For more information, see the [Generative AI on Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) documentation.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "This notebook demonstrates a variety of multimodal use cases with Gemini.\n",
    "\n",
    "In this tutorial, you will learn how to use Gemini with the Gen AI SDK for Python to:\n",
    "\n",
    "  - Process and generate text\n",
    "  - Parse and summarize PDF documents\n",
    "  - Reason across multiple images\n",
    "  - Generating a video description\n",
    "  - Combining video data with external knowledge\n",
    "  - Understand Audio\n",
    "  - Analyze a code base\n",
    "  - Combine modalities\n",
    "  - Recommendation based on user preferences for e-commerce\n",
    "  - Understanding charts and diagrams\n",
    "  - Comparing images for similarities, anomalies, or differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhsUe0fyc-ER"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5afkyDMSBW5"
   },
   "source": [
    "### Install Google Gen AI SDK for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kc4WxYmLSBW5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai gitingest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. The restart might take a minute or longer. After it's restarted, continue to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LCaCx6PLSBW6"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGB8Txa_e4V0"
   },
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JGOJHtgDe5-r"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-03-9d4e440cc380\" # \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"europe-west4\" # \"[your-region]\"  # @param {type:\"string\"}\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BuQwwRiniVFG"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JTk488WDPBtQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-09 02:13:10.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:16.508\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:16.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:28.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:28.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:39.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:40.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:45.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:45.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:51.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:51.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:13:56.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:13:57.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:14:02.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:14:02.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgoogle.genai.models\u001b[0m:\u001b[36mgenerate_content\u001b[0m:\u001b[36m4975\u001b[0m | AFC is enabled with max remote calls: 10.\n",
      "\u001b[32m2025-10-09 02:14:32.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1025\u001b[0m | HTTP Request: POST https://europe-west4-aiplatform.googleapis.com/v1beta1/projects/qwiklabs-gcp-03-9d4e440cc380/locations/europe-west4/publishers/google/models/gemini-2.0-flash-001:generateContent \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:14:32.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m89\u001b[0m | Starting ingestion process | {\"source\":\"https://github.com/GoogleCloudPlatform/microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:32.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m98\u001b[0m | Parsing remote repository | {\"source\":\"https://github.com/GoogleCloudPlatform/microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:32.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m56\u001b[0m | Starting git clone operation | {\"url\":\"https://github.com/googlecloudplatform/microservices-demo\",\"local_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\",\"partial_clone\":false,\"subpath\":\"/\",\"branch\":null,\"tag\":null,\"commit\":\"895c9f20cd0cc31146122b49ab251756069e97be\",\"include_submodules\":false}\n",
      "\u001b[32m2025-10-09 02:14:33.178\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhttpx._client\u001b[0m:\u001b[36m_send_single_request\u001b[0m:\u001b[36m1740\u001b[0m | HTTP Request: HEAD https://github.com/googlecloudplatform/microservices-demo \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-10-09 02:14:33.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m97\u001b[0m | Executing git clone command | {\"command\":\"git clone --single-branch --no-checkout --depth=1 https://github.com/googlecloudplatform/microservices-demo <url> /var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:34.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m99\u001b[0m | Git clone completed successfully\n",
      "\u001b[32m2025-10-09 02:14:34.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m114\u001b[0m | Checking out commit | {\"commit\":\"895c9f20cd0cc31146122b49ab251756069e97be\"}\n",
      "\u001b[32m2025-10-09 02:14:34.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.clone\u001b[0m:\u001b[36mclone_repo\u001b[0m:\u001b[36m123\u001b[0m | Git clone operation completed successfully | {\"local_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:34.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m132\u001b[0m | Repository cloned, starting file processing\n",
      "\u001b[32m2025-10-09 02:14:34.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m140\u001b[0m | Processing files and generating output\n",
      "\u001b[32m2025-10-09 02:14:34.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.ingestion\u001b[0m:\u001b[36mingest_query\u001b[0m:\u001b[36m44\u001b[0m | Starting file ingestion | {\"slug\":\"googlecloudplatform-microservices-demo\",\"subpath\":\"/\",\"local_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\",\"max_file_size\":10485760}\n",
      "\u001b[32m2025-10-09 02:14:34.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.ingestion\u001b[0m:\u001b[36mingest_query\u001b[0m:\u001b[36m96\u001b[0m | Processing directory | {\"directory_path\":\"/var/tmp/gitingest/d1ca3385-3e35-41dc-a7da-fd3c983db345/googlecloudplatform-microservices-demo\"}\n",
      "\u001b[32m2025-10-09 02:14:35.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.ingestion\u001b[0m:\u001b[36mingest_query\u001b[0m:\u001b[36m109\u001b[0m | Directory processing completed | {\"total_files\":309,\"total_directories\":90,\"total_size_bytes\":1498427,\"stats_total_files\":309,\"stats_total_size\":1498427}\n",
      "\u001b[32m2025-10-09 02:14:39.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mgitingest.entrypoint\u001b[0m:\u001b[36mingest_async\u001b[0m:\u001b[36m147\u001b[0m | Ingestion completed successfully\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Audio, Image, Markdown, Video, display\n",
    "from gitingest import ingest\n",
    "from google.genai.types import CreateCachedContentConfig, GenerateContentConfig, Part\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTNnM-lqfQRo"
   },
   "source": [
    "### Load Gemini 2.0 Flash model\n",
    "\n",
    "Learn more about all [Gemini models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2998506fe6d1"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash-001\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22c7363baeb0"
   },
   "source": [
    "## Individual Modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a052fcef47ea"
   },
   "source": [
    "### Textual understanding\n",
    "\n",
    "Gemini can parse textual questions and retain that context across following prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "577574234d7e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here's a breakdown of the average weather in Mountain View, CA, in mid-May and some outfit suggestions:\n",
       "\n",
       "**Average Weather in Mountain View, CA in Mid-May**\n",
       "\n",
       "*   **Temperature:** The average high is around 70°F (21°C) and the average low is around 50°F (10°C).\n",
       "*   **Sunshine:** It's generally sunny and clear.\n",
       "*   **Rainfall:** Rainfall is relatively low.\n",
       "*   **Humidity:** Humidity is generally low.\n",
       "*   **Wind:** There can be a light breeze, especially in the afternoon.\n",
       "*   **Fog:** Morning fog is possible.\n",
       "\n",
       "**Key Characteristics:**\n",
       "\n",
       "*   Pleasant, mild days.\n",
       "*   Cool evenings.\n",
       "*   Lots of sunshine.\n",
       "*   Dry conditions.\n",
       "\n",
       "**Outfit Suggestions:**\n",
       "\n",
       "The key to dressing in Mountain View in May is **layers**. The temperature can fluctuate quite a bit between day and night.\n",
       "\n",
       "**Daytime Outfit Ideas:**\n",
       "\n",
       "*   **Option 1: Casual & Comfortable**\n",
       "    *   **Top:** A short-sleeved t-shirt or a lightweight blouse made of cotton or linen.\n",
       "    *   **Bottom:** Jeans, chinos, or a casual skirt (knee-length or midi).\n",
       "    *   **Shoes:** Comfortable sneakers, sandals, or flats.\n",
       "    *   **Outerwear:** A light denim jacket or a cardigan to throw on if it gets a little breezy.\n",
       "    *   **Accessories:** Sunglasses, a hat (optional), and sunscreen.\n",
       "*   **Option 2: Slightly Dressier**\n",
       "    *   **Top:** A nice blouse (silk, rayon, or a dressier cotton).\n",
       "    *   **Bottom:** Dress pants or a pencil skirt.\n",
       "    *   **Shoes:** Loafers, ballet flats, or low heels.\n",
       "    *   **Outerwear:** A light blazer or a trench coat.\n",
       "    *   **Accessories:** A scarf, simple jewelry, and a tote bag.\n",
       "*   **Option 3: For an active day**\n",
       "    *   **Top:** Moisture-wicking activewear shirt.\n",
       "    *   **Bottom:** Leggings, athletic shorts, or hiking pants.\n",
       "    *   **Shoes:** Sneakers or hiking shoes.\n",
       "    *   **Outerwear:** A light windbreaker.\n",
       "    *   **Accessories:** Sunglasses, hat, and a water bottle.\n",
       "\n",
       "**Evening Outfit Ideas:**\n",
       "\n",
       "The evenings will be considerably cooler, so you'll need to add layers or choose warmer clothes.\n",
       "\n",
       "*   **Option 1: Relaxed Evening**\n",
       "    *   **Top:** A long-sleeved shirt, sweater or a thermal top.\n",
       "    *   **Bottom:** Jeans, cords, or a comfortable skirt with tights.\n",
       "    *   **Outerwear:** A sweater, fleece jacket, or a light puffer jacket.\n",
       "    *   **Shoes:** Closed-toe shoes like boots or sneakers.\n",
       "    *   **Accessories:** A scarf.\n",
       "*   **Option 2: Dinner Out**\n",
       "    *   **Dress:** A long-sleeved dress (knit or a heavier fabric) or a dress with a cardigan or jacket.\n",
       "    *   **Top and Bottom:** Dress pants or a skirt with a sweater or a dressy top.\n",
       "    *   **Outerwear:** A stylish jacket, a wrap, or a dress coat.\n",
       "    *   **Shoes:** Boots, heels, or dressy flats.\n",
       "    *   **Accessories:** Jewelry, a clutch, and a scarf.\n",
       "*   **Option 3: A more casual evening event**\n",
       "    *   **Top:** A nice sweater, cardigan, or long-sleeved blouse.\n",
       "    *   **Bottom:** Dark-wash jeans or chinos.\n",
       "    *   **Outerwear:** A denim jacket, a leather jacket, or a light bomber jacket.\n",
       "    *   **Shoes:** Boots, loafers, or stylish sneakers.\n",
       "    *   **Accessories:** A fashionable scarf, a belt, or a simple necklace.\n",
       "\n",
       "**General Tips:**\n",
       "\n",
       "*   **Always bring a jacket or sweater:** Even if it's warm during the day, you'll be glad to have an extra layer at night.\n",
       "*   **Consider the occasion:** Dress appropriately for what you'll be doing.\n",
       "*   **Comfort is key:** Mountain View is a relaxed place, so you don't need to overdress.\n",
       "*   **Sunscreen is essential:** Even on cloudy days, the sun can be strong.\n",
       "*   **Check the forecast:** Weather patterns can change, so it's always a good idea to check the forecast before you leave.\n",
       "\n",
       "Enjoy your trip to Mountain View!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What is the average weather in Mountain View, CA in the middle of May?\"\n",
    "prompt = \"\"\"\n",
    "Considering the weather, please provide some outfit suggestions.\n",
    "\n",
    "Give examples for the daytime and the evening.\n",
    "\"\"\"\n",
    "\n",
    "contents = [question, prompt]\n",
    "response = client.models.generate_content(model=MODEL_ID, contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-0.3520269259600572,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"Okay, here's a breakdown of the average weather in Mountain View, CA, in mid-May and some outfit suggestions:\n",
       "\n",
       "**Average Weather in Mountain View, CA in Mid-May**\n",
       "\n",
       "*   **Temperature:** The average high is around 70°F (21°C) and the average low is around 50°F (10°C).\n",
       "*   **Sunshine:** It's generally sunny and clear.\n",
       "*   **Rainfall:** Rainfall is relatively low.\n",
       "*   **Humidity:** Humidity is generally low.\n",
       "*   **Wind:** There can be a light breeze, especially in the afternoon.\n",
       "*   **Fog:** Morning fog is possible.\n",
       "\n",
       "**Key Characteristics:**\n",
       "\n",
       "*   Pleasant, mild days.\n",
       "*   Cool evenings.\n",
       "*   Lots of sunshine.\n",
       "*   Dry conditions.\n",
       "\n",
       "**Outfit Suggestions:**\n",
       "\n",
       "The key to dressing in Mountain View in May is **layers**. The temperature can fluctuate quite a bit between day and night.\n",
       "\n",
       "**Daytime Outfit Ideas:**\n",
       "\n",
       "*   **Option 1: Casual & Comfortable**\n",
       "    *   **Top:** A short-sleeved t-shirt or a lightweight blouse made of cotton or linen.\n",
       "    *   **Bottom:** Jeans, chinos, or a casual skirt (knee-length or midi).\n",
       "    *   **Shoes:** Comfortable sneakers, sandals, or flats.\n",
       "    *   **Outerwear:** A light denim jacket or a cardigan to throw on if it gets a little breezy.\n",
       "    *   **Accessories:** Sunglasses, a hat (optional), and sunscreen.\n",
       "*   **Option 2: Slightly Dressier**\n",
       "    *   **Top:** A nice blouse (silk, rayon, or a dressier cotton).\n",
       "    *   **Bottom:** Dress pants or a pencil skirt.\n",
       "    *   **Shoes:** Loafers, ballet flats, or low heels.\n",
       "    *   **Outerwear:** A light blazer or a trench coat.\n",
       "    *   **Accessories:** A scarf, simple jewelry, and a tote bag.\n",
       "*   **Option 3: For an active day**\n",
       "    *   **Top:** Moisture-wicking activewear shirt.\n",
       "    *   **Bottom:** Leggings, athletic shorts, or hiking pants.\n",
       "    *   **Shoes:** Sneakers or hiking shoes.\n",
       "    *   **Outerwear:** A light windbreaker.\n",
       "    *   **Accessories:** Sunglasses, hat, and a water bottle.\n",
       "\n",
       "**Evening Outfit Ideas:**\n",
       "\n",
       "The evenings will be considerably cooler, so you'll need to add layers or choose warmer clothes.\n",
       "\n",
       "*   **Option 1: Relaxed Evening**\n",
       "    *   **Top:** A long-sleeved shirt, sweater or a thermal top.\n",
       "    *   **Bottom:** Jeans, cords, or a comfortable skirt with tights.\n",
       "    *   **Outerwear:** A sweater, fleece jacket, or a light puffer jacket.\n",
       "    *   **Shoes:** Closed-toe shoes like boots or sneakers.\n",
       "    *   **Accessories:** A scarf.\n",
       "*   **Option 2: Dinner Out**\n",
       "    *   **Dress:** A long-sleeved dress (knit or a heavier fabric) or a dress with a cardigan or jacket.\n",
       "    *   **Top and Bottom:** Dress pants or a skirt with a sweater or a dressy top.\n",
       "    *   **Outerwear:** A stylish jacket, a wrap, or a dress coat.\n",
       "    *   **Shoes:** Boots, heels, or dressy flats.\n",
       "    *   **Accessories:** Jewelry, a clutch, and a scarf.\n",
       "*   **Option 3: A more casual evening event**\n",
       "    *   **Top:** A nice sweater, cardigan, or long-sleeved blouse.\n",
       "    *   **Bottom:** Dark-wash jeans or chinos.\n",
       "    *   **Outerwear:** A denim jacket, a leather jacket, or a light bomber jacket.\n",
       "    *   **Shoes:** Boots, loafers, or stylish sneakers.\n",
       "    *   **Accessories:** A fashionable scarf, a belt, or a simple necklace.\n",
       "\n",
       "**General Tips:**\n",
       "\n",
       "*   **Always bring a jacket or sweater:** Even if it's warm during the day, you'll be glad to have an extra layer at night.\n",
       "*   **Consider the occasion:** Dress appropriately for what you'll be doing.\n",
       "*   **Comfort is key:** Mountain View is a relaxed place, so you don't need to overdress.\n",
       "*   **Sunscreen is essential:** Even on cloudy days, the sun can be strong.\n",
       "*   **Check the forecast:** Weather patterns can change, so it's always a good idea to check the forecast before you leave.\n",
       "\n",
       "Enjoy your trip to Mountain View!\n",
       "\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 10, 9, 2, 32, 14, 574039, tzinfo=TzInfo(UTC)),\n",
       "  model_version='gemini-2.0-flash-001',\n",
       "  response_id='rh7naNeEI-CO7dcPrdHEGQ',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=994,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=994\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=38,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=38\n",
       "      ),\n",
       "    ],\n",
       "    total_token_count=1032,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d5586dd92ed"
   },
   "source": [
    "### Document Summarization\n",
    "\n",
    "You can use Gemini to process PDF documents, and analyze content, retain information, and provide answers to queries regarding the documents.\n",
    "\n",
    "The PDF document example used here is the Gemini 2.0 paper (https://arxiv.org/pdf/2403.05530.pdf).\n",
    "\n",
    "![image.png](https://storage.googleapis.com/cloud-samples-data/generative-ai/image/gemini1.5-paper-2403.05530.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "d5af46d4da0c"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Gemini 1.5 Pro model can process inputs of up to 10 million tokens.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_file_uri = \"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\"\n",
    "pdf_file = Part.from_uri(file_uri=pdf_file_uri, mime_type=\"application/pdf\")\n",
    "\n",
    "prompt = \"How many tokens can the model process?\"\n",
    "\n",
    "contents = [pdf_file, prompt]\n",
    "\n",
    "response = client.models.generate_content(model=MODEL_ID, contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-0.27829599380493164,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"The Gemini 1.5 Pro model can process inputs of up to 10 million tokens.\n",
       "\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 10, 9, 2, 32, 26, 198488, tzinfo=TzInfo(UTC)),\n",
       "  model_version='gemini-2.0-flash-001',\n",
       "  response_id='uh7naNiODNHg7dcPtZuM4Aw',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=21,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=21\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=19874,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=8\n",
       "      ),\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.DOCUMENT: 'DOCUMENT'>,\n",
       "        token_count=19866\n",
       "      ),\n",
       "    ],\n",
       "    total_token_count=19895,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "25658ef8dcec"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemini 1.5 Pro is a highly compute-efficient multimodal mixture-of-experts model capable of recalling and reasoning over fine-grained information from millions of tokens of context. It achieves near-perfect recall on long-context retrieval tasks across modalities, improves the state-of-the-art in long-document QA, long-video QA and long-context ASR, and matches or surpasses Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Gemini 1.5 Pro also demonstrates surprising new capabilities such as in-context learning from entire long documents and the ability to translate English to Kalamang at a similar level to a person who learned from the same content.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "  You are a professional document summarization specialist.\n",
    "  Please summarize the given document.\n",
    "\"\"\"\n",
    "\n",
    "contents = [pdf_file, prompt]\n",
    "\n",
    "response = client.models.generate_content(model=MODEL_ID, contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_multimodal_use_cases.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
