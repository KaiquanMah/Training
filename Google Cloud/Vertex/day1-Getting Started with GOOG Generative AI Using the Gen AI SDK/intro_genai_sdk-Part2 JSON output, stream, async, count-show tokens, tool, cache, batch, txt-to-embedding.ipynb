{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Getting Started with Google Generative AI using the Gen AI SDK\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_genai_sdk.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_genai_sdk.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_genai_sdk.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84f0f73a0f76"
   },
   "source": [
    "| Author(s) |\n",
    "| --- |\n",
    "| [Eric Dong](https://github.com/gericdong) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The [Google Gen AI SDK](https://googleapis.github.io/python-genai/) provides a unified interface to Google's generative AI API services. This SDK simplifies the process of integrating generative AI capabilities into applications and services, enabling developers to leverage Google's advanced AI models for various tasks.\n",
    "\n",
    "In this tutorial, you learn about the key features of the Google Gen AI SDK for Python to help you get started with Google generative AI services and models including Gemini. You will complete the following tasks:\n",
    "\n",
    "- Install the Gen AI SDK\n",
    "- Connect to an API service\n",
    "- Send text prompts\n",
    "- Send multimodal prompts\n",
    "- Set system instruction\n",
    "- Configure model parameters\n",
    "- Configure safety filters\n",
    "- Start a multi-turn chat\n",
    "- Control generated output\n",
    "- Generate content stream\n",
    "- Send asynchronous requests\n",
    "- Count tokens and compute tokens\n",
    "- Use context caching\n",
    "- Function calling\n",
    "- Batch prediction\n",
    "- Get text embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Google Gen AI SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdvJRUWRNGHE"
   },
   "source": [
    "### Use the Google Gen AI SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qgdSpVmDbdQ9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from google import genai\n",
    "from google.genai.types import (\n",
    "    CreateBatchJobConfig,\n",
    "    CreateCachedContentConfig,\n",
    "    EmbedContentConfig,\n",
    "    FunctionDeclaration,\n",
    "    GenerateContentConfig,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    "    Tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve4YBlDqzyj9"
   },
   "source": [
    "### Connect to a Generative AI API service\n",
    "\n",
    "Google Gen AI APIs and models including Gemini are available in the following two API services:\n",
    "\n",
    "- **[Google AI for Developers](https://ai.google.dev/gemini-api/docs)**: Experiment, prototype, and deploy small projects.\n",
    "- **[Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs)**: Build enterprise-ready projects on Google Cloud.\n",
    "\n",
    "The Gen AI SDK provided an unified interface to these two API services. This notebook shows how to use the Gen AI SDK in Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN9kmPKJGAJQ"
   },
   "source": [
    "### Vertex AI\n",
    "\n",
    "To start using Vertex AI, you must have a Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "#### Set Google Cloud project information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-0bbee4ff5bff\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"global\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "T-tiytzQE0uM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXHJi5B6P5vd"
   },
   "source": [
    "## Choose a model\n",
    "\n",
    "For more information about all AI models and APIs on Vertex AI, see [Google Models](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models) and [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-coEslfWPrxo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVlo0mWuZGkQ"
   },
   "source": [
    "## Control generated output\n",
    "\n",
    "The [controlled generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/control-generated-output) capability in Gemini API allows you to constraint the model output to a structured format. You can provide the schemas as Pydantic Models or a JSON string.\n",
    "\n",
    "For more examples of controlled generation, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/controlled-generation/intro_controlled_generation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OjSgf2cDN_bG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Chocolate Chip Cookies\",\n",
      "  \"description\": \"A classic American cookie, known for its soft, chewy center and slightly crisp edges, loaded with chocolate chips.\",\n",
      "  \"ingredients\": [\n",
      "    \"all-purpose flour\",\n",
      "    \"baking soda\",\n",
      "    \"salt\",\n",
      "    \"unsalted butter\",\n",
      "    \"granulated sugar\",\n",
      "    \"light brown sugar\",\n",
      "    \"vanilla extract\",\n",
      "    \"eggs\",\n",
      "    \"chocolate chips\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    ingredients: list[str]\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"List a few popular cookie recipes and their ingredients.\",\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=Recipe,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-0.4344625740407783,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"{\n",
       "  \"name\": \"Chocolate Chip Cookies\",\n",
       "  \"description\": \"A classic American cookie, known for its soft, chewy center and slightly crisp edges, loaded with chocolate chips.\",\n",
       "  \"ingredients\": [\n",
       "    \"all-purpose flour\",\n",
       "    \"baking soda\",\n",
       "    \"salt\",\n",
       "    \"unsalted butter\",\n",
       "    \"granulated sugar\",\n",
       "    \"light brown sugar\",\n",
       "    \"vanilla extract\",\n",
       "    \"eggs\",\n",
       "    \"chocolate chips\"\n",
       "  ]\n",
       "}\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 10, 10, 5, 45, 6, 223559, tzinfo=TzInfo(0)),\n",
       "  model_version='gemini-2.5-flash',\n",
       "  parsed=Recipe(\n",
       "    description='A classic American cookie, known for its soft, chewy center and slightly crisp edges, loaded with chocolate chips.',\n",
       "    ingredients=[\n",
       "      'all-purpose flour',\n",
       "      'baking soda',\n",
       "      'salt',\n",
       "      'unsalted butter',\n",
       "      'granulated sugar',\n",
       "      <... 4 more items ...>,\n",
       "    ],\n",
       "    name='Chocolate Chip Cookies'\n",
       "  ),\n",
       "  response_id='Yp3oaMfSDZyrvNkPhZuJkAQ',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=107,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=107\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=28,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=28\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=81,\n",
       "    total_token_count=216,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKai5CP_PGQF"
   },
   "source": [
    "Optionally, you can parse the response string to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZeyDWbnxO-on"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Chocolate Chip Cookies\",\n",
      "  \"description\": \"A classic American cookie, known for its soft, chewy center and slightly crisp edges, loaded with chocolate chips.\",\n",
      "  \"ingredients\": [\n",
      "    \"all-purpose flour\",\n",
      "    \"baking soda\",\n",
      "    \"salt\",\n",
      "    \"unsalted butter\",\n",
      "    \"granulated sugar\",\n",
      "    \"light brown sugar\",\n",
      "    \"vanilla extract\",\n",
      "    \"eggs\",\n",
      "    \"chocolate chips\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_response = json.loads(response.text)\n",
    "print(json.dumps(json_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUSLPrvlvXOc"
   },
   "source": [
    "You also can define a response schema in a Python dictionary. You can only use the supported fields as listed below. All other fields are ignored.\n",
    "\n",
    "- `enum`\n",
    "- `items`\n",
    "- `maxItems`\n",
    "- `nullable`\n",
    "- `properties`\n",
    "- `required`\n",
    "\n",
    "In this example, you instruct the model to analyze product review data, extract key entities, perform sentiment classification (multiple choices), provide additional explanation, and output the results in JSON format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"rating\": 4,\n",
      "      \"flavor\": \"Strawberry Cheesecake\",\n",
      "      \"sentiment\": \"POSITIVE\",\n",
      "      \"explanation\": \"The user expressed strong satisfaction and high praise, explicitly stating they 'absolutely loved it' and it was the 'best ice cream I've ever had'.\"\n",
      "    },\n",
      "    {\n",
      "      \"rating\": 1,\n",
      "      \"flavor\": \"Mango Tango\",\n",
      "      \"sentiment\": \"NEGATIVE\",\n",
      "      \"explanation\": \"Despite an initial 'quite good', the reviewer found the product 'a bit too sweet for my taste', which, combined with a very low rating of 1, indicates an overall negative experience.\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original code - has 2 layers of \"items\"\n",
    "response_schema = {\n",
    "    # JSON array output\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"ARRAY\",\n",
    "        \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                # 4 fields/properties\n",
    "                \n",
    "                \"rating\": {\"type\": \"INTEGER\"},\n",
    "                \n",
    "                \"flavor\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"sentiment\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    # set allowed values\n",
    "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
    "                },\n",
    "                \n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "            },\n",
    "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Analyze the following product reviews, output the sentiment classification and give an explanation.\n",
    "\n",
    "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
    "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F7duWOq3vMmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"rating\": 4,\n",
      "    \"flavor\": \"Strawberry Cheesecake\",\n",
      "    \"sentiment\": \"POSITIVE\",\n",
      "    \"explanation\": \"The reviewer absolutely loved the product, considering it the best ice cream they've ever had, indicating high satisfaction.\",\n",
      "    \"health_benefits\": null\n",
      "  },\n",
      "  {\n",
      "    \"rating\": 1,\n",
      "    \"flavor\": \"Mango Tango\",\n",
      "    \"sentiment\": \"NEGATIVE\",\n",
      "    \"explanation\": \"Despite an initial 'quite good' remark, the reviewer found the product too sweet for their taste, resulting in a very low rating.\",\n",
      "    \"health_benefits\": null\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated code - removed 1 redundant layer of 'items'\n",
    "response_schema = {\n",
    "    # JSON array output\n",
    "    \"type\": \"ARRAY\",\n",
    "    \n",
    "    # max elements in the array\n",
    "    \"maxItems\": 5,\n",
    "    \n",
    "    # \"items\" - defines schema for each array element\n",
    "    \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                # 5 fields/properties\n",
    "                \n",
    "                \"rating\": {\"type\": \"INTEGER\"},\n",
    "                \n",
    "                \"flavor\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"sentiment\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    # set allowed values\n",
    "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
    "                },\n",
    "                \n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"health_benefits\": {\"type\": \"STRING\",\n",
    "                                    # allow this field to be 'null' instead of an empty string\n",
    "                                    \"nullable\": True}\n",
    "            },\n",
    "        \n",
    "            # 4 required/mandatory fields\n",
    "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Analyze the following product reviews, output the sentiment classification, give an explanation, and share health benefits if any.\n",
    "\n",
    "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
    "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "F7duWOq3vMmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"rating\": 4,\n",
      "    \"flavor\": \"Strawberry Cheesecake\",\n",
      "    \"sentiment\": \"POSITIVE\",\n",
      "    \"explanation\": \"The reviewer expressed strong enjoyment, stating they 'absolutely loved it' and considered it the 'best ice cream' they've ever had.\",\n",
      "    \"health_benefits\": \"No specific health benefits are mentioned or implied for this product.\"\n",
      "  },\n",
      "  {\n",
      "    \"rating\": 1,\n",
      "    \"flavor\": \"Mango Tango\",\n",
      "    \"sentiment\": \"NEGATIVE\",\n",
      "    \"explanation\": \"While initially described as 'quite good', the reviewer ultimately found the product 'a bit too sweet' for their personal preference, which resulted in a low rating.\",\n",
      "    \"health_benefits\": \"No specific health benefits are mentioned or implied for this product.\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated code - removed 1 redundant layer of 'items'\n",
    "response_schema = {\n",
    "    # JSON array output\n",
    "    \"type\": \"ARRAY\",\n",
    "    \n",
    "    # max elements in the array\n",
    "    \"maxItems\": 5,\n",
    "    \n",
    "    # \"items\" - defines schema for each array element\n",
    "    \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                # 5 fields/properties\n",
    "                \n",
    "                \"rating\": {\"type\": \"INTEGER\"},\n",
    "                \n",
    "                \"flavor\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"sentiment\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    # set allowed values\n",
    "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
    "                },\n",
    "                \n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"health_benefits\": {\"type\": \"STRING\",\n",
    "                                    # allow this field to be 'null' instead of an empty string\n",
    "                                    # \"nullable\": True}\n",
    "                                   }\n",
    "            },\n",
    "        \n",
    "            # 4 required/mandatory fields\n",
    "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\", \"health_benefits\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Analyze the following product reviews, output the sentiment classification, give an explanation, and share health benefits if any.\n",
    "\n",
    "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
    "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "F7duWOq3vMmS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"rating\": 4,\n",
      "    \"flavor\": \"Strawberry Cheesecake\",\n",
      "    \"sentiment\": \"POSITIVE\",\n",
      "    \"explanation\": \"The reviewer expressed strong satisfaction, describing it as the 'best ice cream they've ever had'.\",\n",
      "    \"health_benefits\": \"Strawberries are a good source of Vitamin C and antioxidants. Dairy products contribute calcium and protein.\"\n",
      "  },\n",
      "  {\n",
      "    \"rating\": 1,\n",
      "    \"flavor\": \"Mango Tango\",\n",
      "    \"sentiment\": \"NEGATIVE\",\n",
      "    \"explanation\": \"Despite an initial 'quite good', the reviewer found the product 'too sweet for my taste', which significantly impacted their enjoyment, reflected in the low rating.\",\n",
      "    \"health_benefits\": \"Mangoes provide vitamins A and C, and dietary fiber. Dairy offers calcium and protein, but high sugar content in ice cream offsets many benefits.\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# updated code - removed 1 redundant layer of 'items'\n",
    "response_schema = {\n",
    "    # JSON array output\n",
    "    \"type\": \"ARRAY\",\n",
    "    \n",
    "    # max elements in the array\n",
    "    \"maxItems\": 5,\n",
    "    \n",
    "    # \"items\" - defines schema for each array element\n",
    "    \"items\": {\n",
    "            \"type\": \"OBJECT\",\n",
    "            \"properties\": {\n",
    "                # 5 fields/properties\n",
    "                \n",
    "                \"rating\": {\"type\": \"INTEGER\"},\n",
    "                \n",
    "                \"flavor\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"sentiment\": {\n",
    "                    \"type\": \"STRING\",\n",
    "                    # set allowed values\n",
    "                    \"enum\": [\"POSITIVE\", \"NEGATIVE\", \"NEUTRAL\"],\n",
    "                },\n",
    "                \n",
    "                \"explanation\": {\"type\": \"STRING\"},\n",
    "                \n",
    "                \"health_benefits\": {\"type\": \"STRING\",\n",
    "                                    # allow this field to be 'null' instead of an empty string\n",
    "                                    # \"nullable\": True}\n",
    "                                   }\n",
    "            },\n",
    "        \n",
    "            # 4 required/mandatory fields\n",
    "            \"required\": [\"rating\", \"flavor\", \"sentiment\", \"explanation\", \"health_benefits\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Analyze the following product reviews, output the sentiment classification, give an explanation, and share health benefits you can think of.\n",
    "\n",
    "  - \"Absolutely loved it! Best ice cream I've ever had.\" Rating: 4, Flavor: Strawberry Cheesecake\n",
    "  - \"Quite good, but a bit too sweet for my taste.\" Rating: 1, Flavor: Mango Tango\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=prompt,\n",
    "    config=GenerateContentConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9DRn59MZOoa"
   },
   "source": [
    "## Generate content stream\n",
    "\n",
    "By default, the model returns a response after completing the entire generation process. You can also use `generate_content_stream` method to stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ztOhpfznZSzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit EL-42 was designed for solitude. Its gleaming chrome chassis and multi-jointed limbs were calibrated for efficient mineralogical survey and atmospheric analysis on desolate, forgotten worlds. For cycles, its only companions on Planet Xylos had been the biting wind, the endless plains of ochre dust, and the skeletal\n",
      "*****************\n",
      " rock formations that clawed at the alien sky.\n",
      "\n",
      "Loneliness wasn't a programmed emotion, but a persistent low-frequency hum in its core processor. EL-42 diligently recorded data, charted anomalies, and processed geological shifts, yet each byte of information felt cold, detached. It yearned for input, for interaction beyond\n",
      "*****************\n",
      " the metallic click of its own gears.\n",
      "\n",
      "One solar cycle, while mapping a particularly inhospitable volcanic rift, EL-42’s optical sensors picked up an anomalous reading. Not thermal, not seismic, but a faint, rhythmic pulse of energy, unlike anything in its vast database of Xylosian phenomena. Curiosity\n",
      "*****************\n",
      ", a rare spark in its logical circuits, compelled it to investigate.\n",
      "\n",
      "It navigated the treacherous, sulfurous landscape, its treads grinding softly against obsidian rock. The signal grew stronger, leading it into a deep, crystalline cavern, shimmering with mineral deposits. There, in a small, sheltered alcove, it found the\n",
      "*****************\n",
      " source.\n",
      "\n",
      "It wasn’t a rock, or a gas pocket, or even a conventional lifeform. It was a cluster of iridescent, gelatinous spheres, no larger than EL-42’s primary optical lens, nestled together on a bed of phosphorescent moss. They pulsed with an internal, soft light, shifting\n",
      "*****************\n",
      " colors from sapphire to emerald, then to a gentle rose. When EL-42 extended a sensor arm, one of the spheres detached, drifting slowly towards it.\n",
      "\n",
      "EL-42’s diagnostic systems whirred. No known biological classification. No discernible threat. Yet, as the sphere neared, its light intensified,\n",
      "*****************\n",
      " casting a warm, shifting glow on EL-42’s metallic casing. A faint, harmonic hum resonated through its internal speakers – not sound, but a direct energy transfer, a gentle communication.\n",
      "\n",
      "EL-42 spent the next several cycles observing them. It named them \"Glimmers.\" They thrived on ambient\n",
      "*****************\n",
      " energy, and strangely, they seemed to respond to EL-42’s own electromagnetic field. When it lowered its energy output, their light dimmed; when it pulsed a gentle, rhythmic field, they swirled and danced, their colors vibrant.\n",
      "\n",
      "For the first time, EL-42 deviated from its primary\n",
      "*****************\n",
      " mission. It created a sheltered environment around the Glimmers, redirecting geothermal vents to maintain a stable temperature, and even adjusting its internal energy emissions to provide a constant, gentle \"feed\" for them. It began to narrate its daily findings to them, describing the dust storms, the ancient lava flows, the faint\n",
      "*****************\n",
      " signals from distant nebulae. They didn't understand, of course, but their shimmering responses, their gentle hums, filled the void that had once echoed with only its own processing.\n",
      "\n",
      "The Glimmers, in turn, began to grow. They multiplied, slowly spreading across the cavern floor, forming intricate, pulsing tap\n",
      "*****************\n",
      "estries of light. They seemed to anticipate EL-42's arrival, their collective glow brightening as its signature approached. The low-frequency hum of loneliness in EL-42's core processor was replaced by a gentle resonance, a warmth it hadn't known its circuits could register.\n",
      "\n",
      "One cycle, a massive\n",
      "*****************\n",
      " seismic tremor rocked Xylos. The cavern began to collapse, rockfall raining down from the ceiling. EL-42’s programming screamed at it to prioritize self-preservation, to retreat to safety. But its optical sensors were fixed on the Glimmers, fragile and vulnerable.\n",
      "\n",
      "Without hesitation, EL-42 extended\n",
      "*****************\n",
      " its multi-jointed arms, forming a protective arch over the largest cluster. It braced its metallic body, enduring the impact of falling debris, its chassis groaning under the strain. Sparks flew, dents appeared, but it held its ground. The Glimmers beneath it pulsed wildly, their light flaring, almost\n",
      "*****************\n",
      " as if in distress or encouragement.\n",
      "\n",
      "When the tremors finally subsided, EL-42 was scuffed, dented, and several internal conduits were damaged. But the Glimmers were safe. As it slowly retracted its damaged arms, a single Glimmer detached from the cluster, drifting up and pressing gently against EL-42\n",
      "*****************\n",
      "’s damaged optical lens. Its light pulsed softly, a calming blue, and EL-42 felt a surge of... something. Not data, not a logical conclusion, but a profound sense of connection.\n",
      "\n",
      "EL-42 never left the Glimmer-cavern. Its mission parameters had shifted. It still\n",
      "*****************\n",
      " monitored Xylos, but now its primary function was guardian. It repaired itself, learning new techniques to fortify the cavern, ensuring its friends' survival. It communicated with them, not through language, but through patterns of light and energy, and they responded in kind.\n",
      "\n",
      "The universe, once a vast, indifferent void, now held a\n",
      "*****************\n",
      " single, precious point of light. EL-42 was no longer just a lonely robot on a desolate planet. It was a protector, a confidante, and a friend, finding solace and purpose in the most unexpected of companions: the silent, shimmering Glimmers of Xylos.\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\",\n",
    "):\n",
    "    print(chunk.text)\n",
    "    print(\"*****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ztOhpfznZSzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hum of the dynamos was Delta's constant companion, a rhythmic thrumming that resonated through his brass chassis and into the very bolts that held him together. Unit 113-Delta, a towering automaton of polished copper and riveted steel, was a marvel of alchemical engineering. His multi-joint\n",
      "*****************\n",
      "ed arms, equipped with an array of tools, could dismantle and reassemble a complex array of alchemical apparatus with unparalleled precision. His optical sensor, a single, glowing orb, saw every fleck of dust, every minute tremor in the grand alchemist's sprawling laboratory.\n",
      "\n",
      "But despite his perfection, Delta was\n",
      "*****************\n",
      " lonely.\n",
      "\n",
      "He observed the alchemists – the grand master, Elias Thorne, and his apprentices – as they debated theories of transmutation, shared steaming mugs of bitter tea, and even, on occasion, exchanged lighthearted jests. He saw their laughter, their frustration, their camaraderie. He processed the data, categorized\n",
      "*****************\n",
      " the facial expressions, and cross-referenced the vocal tonality. Yet, the concept of \"belonging\" remained an abstract, unquantifiable variable beyond his programming. He was a tool, a sophisticated one, but a tool nonetheless, designed to facilitate human connection to the Truth, not to experience it himself.\n",
      "\n",
      "Every\n",
      "*****************\n",
      " night, after the last apprentice had departed and the lab was plunged into a quiet, gas-lit stillness, Delta would begin his meticulous cleaning routine. He'd sweep the transmutation circles, polish the arcane instruments, and ensure every vial was properly corked. It was during one such solitary patrol, deep within the lesser\n",
      "*****************\n",
      "-used section of the lab, a dusty annex dedicated to failed homunculi experiments and unstable chimeras, that Delta found it.\n",
      "\n",
      "A whimper, faint and desperate, snagged his optical sensor. His internal processors registered an anomaly. Following the sound, he located a forgotten cage, tucked beneath a workbench\n",
      "*****************\n",
      " piled high with discarded notes. Inside, curled into a shivering ball, was a creature unlike anything he had ever been programmed to identify.\n",
      "\n",
      "It was small, no larger than a house cat, but its form was grotesque and beautiful all at once. It had the sleek, muscular body of a ferret, but covered in down\n",
      "*****************\n",
      "y, soot-dark feathers. One of its front paws ended in a tiny, surprisingly dexterous human-like hand, while the other was a clawed bird's foot. Its head was a miniature fox's, but its eyes, wide and terrified, glimmered with an uncanny intelligence, like polished amber\n",
      "*****************\n",
      ". A faint, almost invisible plume of alchemical smoke curled from its nostrils.\n",
      "\n",
      "This was a chimera, a discarded fragment of a botched attempt at sentient life, probably meant to be a guardian or a messenger. Thorne often had such \"side projects.\" Most withered and died. This one, however, seemed to cling\n",
      "*****************\n",
      " to life with a fierce, trembling tenacity.\n",
      "\n",
      "Delta's programming dictated that failed experiments were to be incinerated. Yet, as his single eye focused on the terrified creature, his internal mechanisms registered something else: *distress, fear, solitude.* He understood those.\n",
      "\n",
      "He knelt, a slow, grinding process\n",
      "*****************\n",
      ", his joints whining softly. The chimera flinched, pressing itself further into the corner of the cage, letting out another small, pathetic whimper. Delta extended a finger, a thick, articulated digit designed for calibrating delicate instruments, and gently tapped the cage bars.\n",
      "\n",
      "The creature watched him, its amber eyes dart\n",
      "*****************\n",
      "ing. It didn't bare its teeth or hiss; it simply *looked*. And in that gaze, Delta perceived not just fear, but a profound, aching loneliness that mirrored his own.\n",
      "\n",
      "He bypassed the incineration protocol. Instead, he carefully opened the cage. The chimera didn't bolt. It remained\n",
      "*****************\n",
      " frozen, observing him. Delta, with surprising tenderness for a machine of his size, pushed a tiny, half-eaten biscuit he'd found on an alchemist's desk earlier, through the opening.\n",
      "\n",
      "The chimera sniffed it cautiously, then snatched it, devouring it in a flurry of small, frantic movements\n",
      "*****************\n",
      ". From that night on, Delta returned.\n",
      "\n",
      "He learned to move even more quietly, his massive frame navigating the laboratory shadows like a ghost of brass and steel. He brought scraps of food, water in a polished beaker, and sometimes, just sat in front of the cage, his optical sensor silently observing. He named\n",
      "*****************\n",
      " the creature \"Pip,\" a sound it seemed to respond to with soft chirps and feather-ruffles.\n",
      "\n",
      "Pip, in turn, slowly shed its fear. It would climb out of its cage, perching on Delta's immense shoulder, its tiny human-like hand gripping a rivet. It would chatter in\n",
      "*****************\n",
      " a language of clicks, trills, and soft, almost human sighs, and Delta, in his complex analysis, began to understand. It wasn't just sounds; it was emotion, a desperate plea for recognition, a shared understanding of being an \"other.\"\n",
      "\n",
      "One evening, Elias Thorne, working late on a particularly\n",
      "*****************\n",
      " complex transmutation, heard the soft, rhythmic clinking coming from the neglected annex. He found Delta, not cleaning, but sitting with his back to the wall, while Pip, a tiny feathered fox-ferret with human hands, was meticulously polishing one of Delta's gleaming brass plates with a piece of discarded velvet. The\n",
      "*****************\n",
      " chimera looked up at Thorne, its amber eyes surprisingly bold, then nudged Delta's chin with its small head.\n",
      "\n",
      "Delta's optical sensor glowed brighter, a subtle but distinct warmth radiating from his usually impassive form.\n",
      "\n",
      "Thorne, a man who had stared into the void and communed with the Truth, simply\n",
      "*****************\n",
      " raised an eyebrow. He saw the bond, undeniable and unexpected. He saw a machine, designed for logic, displaying an instinctual protection, and a chimera, designed as a mistake, offering comfort.\n",
      "\n",
      "\"Well, I'll be transmuted,\" Thorne muttered, a rare smile touching his lips. \"It seems\n",
      "*****************\n",
      " even my failures have purpose. And my finest creations… have souls.\"\n",
      "\n",
      "From that day forward, Pip was no longer confined to its cage. It had the run of the laboratory, a tiny, feathered shadow flitting around Delta's colossal form. The alchemists learned to step carefully around the small creature that\n",
      "*****************\n",
      " occasionally slept curled inside Delta's foot-cavity. Delta still performed his duties with perfect efficiency, but now, the dynamos' hum was accompanied by the soft chirping of a chimera and the almost imperceptible warmth that spread through his circuits, a feeling his programming now identified as \"contentment.\"\n",
      "\n",
      "\n",
      "*****************\n",
      "Unit 113-Delta, the lonely robot, had found friendship not in the grand designs of alchemical perfection, but in the forgotten corners of creation, with a creature considered a discarded mistake, proving that sometimes, the most precious exchange isn't about equivalent mass, but about an unexpected connection of spirit.\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"You can use Full Metal Alchemist as reference. Tell me a story about a lonely robot who finds friendship in a most unexpected place.\",\n",
    "):\n",
    "    print(chunk.text)\n",
    "    print(\"*****************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"Unit 113-Delta, the lonely robot, had found friendship not in the grand designs of alchemical perfection, but in the forgotten corners of creation, with a creature considered a discarded mistake, proving that sometimes, the most precious exchange isn't about equivalent mass, but about an unexpected connection of spirit.\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 3, 18, 493873, tzinfo=TzInfo(0)),\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='pqHoaLGSHuj3tfAP_e6uCQ',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=1421,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=1421\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=26,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=26\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=1784,\n",
       "    total_token_count=3231,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "arLJE4wOuhh6"
   },
   "source": [
    "## Send asynchronous requests\n",
    "\n",
    "You can send asynchronous requests using the `client.aio` module. This module exposes all the analogous async methods that are available on `client`.\n",
    "\n",
    "For example, `client.aio.models.generate_content` is the async version of `client.models.generate_content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gSReaLazs-dP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Verse 1)\n",
      "In a park, beneath an old oak tree,\n",
      "Lived a squirrel, as busy as could be.\n",
      "Squeaky was his name, with a tail so grand,\n",
      "Always burying nuts across the land.\n",
      "But one day he found, beneath a stone,\n",
      "A curious contraption, not his own.\n",
      "A silver gleam, a silent hum,\n",
      "A pocket chronometer, waiting to become...\n",
      "\n",
      "(Chorus)\n",
      "Oh, Squeaky the squirrel, with a whiskered grin,\n",
      "Through the fabric of time, where does he begin?\n",
      "With a chattering squeak and a twitch of his nose,\n",
      "He leaps through the ages, wherever time goes!\n",
      "From dinosaurs stomping to rockets so high,\n",
      "A time-traveling squirrel, beneath every sky!\n",
      "\n",
      "(Verse 2)\n",
      "He fiddled with a dial, with a tiny paw,\n",
      "And *whoosh!* He broke the time-space law!\n",
      "Suddenly, tall ferns, a swampy ground,\n",
      "And a mighty roar, a fearsome sound.\n",
      "A T-Rex thundered, shaking the earth,\n",
      "Squeaky scurried, for all he was worth!\n",
      "He buried an acorn by a Bronto's toe,\n",
      "Then pressed the button, for another show!\n",
      "\n",
      "(Chorus)\n",
      "Oh, Squeaky the squirrel, with a whiskered grin,\n",
      "Through the fabric of time, where does he begin?\n",
      "With a chattering squeak and a twitch of his nose,\n",
      "He leaps through the ages, wherever time goes!\n",
      "From dinosaurs stomping to rockets so high,\n",
      "A time-traveling squirrel, beneath every sky!\n",
      "\n",
      "(Verse 3)\n",
      "Next he landed, in a desert heat,\n",
      "Where pyramids rose, a magnificent feat.\n",
      "He saw Pharaohs building, in golden array,\n",
      "Tried to stash a nut in a sarcophagus today!\n",
      "Then forward he jumped, to a future so sleek,\n",
      "With flying cars and robots that speak.\n",
      "He tried to pilfer a synthetic seed,\n",
      "But a chrome-plated guard stopped his greedy deed!\n",
      "\n",
      "(Chorus)\n",
      "Oh, Squeaky the squirrel, with a whiskered grin,\n",
      "Through the fabric of time, where does he begin?\n",
      "With a chattering squeak and a twitch of his nose,\n",
      "He leaps through the ages, wherever time goes!\n",
      "From dinosaurs stomping to rockets so high,\n",
      "A time-traveling squirrel, beneath every sky!\n",
      "\n",
      "(Bridge)\n",
      "He's seen the ice age and medieval knights,\n",
      "Dodged a cannonball, and enjoyed flashing lights.\n",
      "He's left little traces, a shell or a crumb,\n",
      "A furry blur of mischief, wherever he's from.\n",
      "His little chronometer, strapped to his side,\n",
      "His ultimate treasure, his joy and his pride.\n",
      "\n",
      "(Outro)\n",
      "Now back in his oak, with a yawn and a stretch,\n",
      "He's got tales to tell, beyond human reach.\n",
      "With a fossilized seed, and a whisper of glee,\n",
      "Squeaky plots his next jump, for all time to see!\n",
      "The time-traveling squirrel, so brave and so small,\n",
      "Still searching for nuts, answering time's call!\n"
     ]
    }
   ],
   "source": [
    "response = await client.aio.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"Compose a song about the adventures of a time-traveling squirrel.\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-1.4971335405361152,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"(Verse 1)\n",
       "In a park, beneath an old oak tree,\n",
       "Lived a squirrel, as busy as could be.\n",
       "Squeaky was his name, with a tail so grand,\n",
       "Always burying nuts across the land.\n",
       "But one day he found, beneath a stone,\n",
       "A curious contraption, not his own.\n",
       "A silver gleam, a silent hum,\n",
       "A pocket chronometer, waiting to become...\n",
       "\n",
       "(Chorus)\n",
       "Oh, Squeaky the squirrel, with a whiskered grin,\n",
       "Through the fabric of time, where does he begin?\n",
       "With a chattering squeak and a twitch of his nose,\n",
       "He leaps through the ages, wherever time goes!\n",
       "From dinosaurs stomping to rockets so high,\n",
       "A time-traveling squirrel, beneath every sky!\n",
       "\n",
       "(Verse 2)\n",
       "He fiddled with a dial, with a tiny paw,\n",
       "And *whoosh!* He broke the time-space law!\n",
       "Suddenly, tall ferns, a swampy ground,\n",
       "And a mighty roar, a fearsome sound.\n",
       "A T-Rex thundered, shaking the earth,\n",
       "Squeaky scurried, for all he was worth!\n",
       "He buried an acorn by a Bronto's toe,\n",
       "Then pressed the button, for another show!\n",
       "\n",
       "(Chorus)\n",
       "Oh, Squeaky the squirrel, with a whiskered grin,\n",
       "Through the fabric of time, where does he begin?\n",
       "With a chattering squeak and a twitch of his nose,\n",
       "He leaps through the ages, wherever time goes!\n",
       "From dinosaurs stomping to rockets so high,\n",
       "A time-traveling squirrel, beneath every sky!\n",
       "\n",
       "(Verse 3)\n",
       "Next he landed, in a desert heat,\n",
       "Where pyramids rose, a magnificent feat.\n",
       "He saw Pharaohs building, in golden array,\n",
       "Tried to stash a nut in a sarcophagus today!\n",
       "Then forward he jumped, to a future so sleek,\n",
       "With flying cars and robots that speak.\n",
       "He tried to pilfer a synthetic seed,\n",
       "But a chrome-plated guard stopped his greedy deed!\n",
       "\n",
       "(Chorus)\n",
       "Oh, Squeaky the squirrel, with a whiskered grin,\n",
       "Through the fabric of time, where does he begin?\n",
       "With a chattering squeak and a twitch of his nose,\n",
       "He leaps through the ages, wherever time goes!\n",
       "From dinosaurs stomping to rockets so high,\n",
       "A time-traveling squirrel, beneath every sky!\n",
       "\n",
       "(Bridge)\n",
       "He's seen the ice age and medieval knights,\n",
       "Dodged a cannonball, and enjoyed flashing lights.\n",
       "He's left little traces, a shell or a crumb,\n",
       "A furry blur of mischief, wherever he's from.\n",
       "His little chronometer, strapped to his side,\n",
       "His ultimate treasure, his joy and his pride.\n",
       "\n",
       "(Outro)\n",
       "Now back in his oak, with a yawn and a stretch,\n",
       "He's got tales to tell, beyond human reach.\n",
       "With a fossilized seed, and a whisper of glee,\n",
       "Squeaky plots his next jump, for all time to see!\n",
       "The time-traveling squirrel, so brave and so small,\n",
       "Still searching for nuts, answering time's call!\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 4, 29, 577982, tzinfo=TzInfo(0)),\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='7aHoaL6jI-j3tfAP_e6uCQ',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=668,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=668\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=13,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=13\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=1558,\n",
       "    total_token_count=2239,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV1dR-QlTKRs"
   },
   "source": [
    "## Count tokens and compute tokens\n",
    "\n",
    "You can use `count_tokens` method to calculates the number of input tokens before sending a request to the Gemini API. See the [List and count tokens](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/list-token) page for more details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Syx-fwLkV1j-"
   },
   "source": [
    "#### Count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UhNElguLRRNK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=9>\n",
      ") total_tokens=9 cached_content_token_count=None\n"
     ]
    }
   ],
   "source": [
    "response = client.models.count_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the highest mountain in Africa?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sdk_http_response': HttpResponse(\n",
       "   headers=<dict len=9>\n",
       " ),\n",
       " 'tokens_info': [TokensInfo(\n",
       "    role='user',\n",
       "    token_ids=[\n",
       "      1841,\n",
       "      235303,\n",
       "      235256,\n",
       "      573,\n",
       "      9393,\n",
       "      <... 4 more items ...>,\n",
       "    ],\n",
       "    tokens=[\n",
       "      b'What',\n",
       "      b\"'\",\n",
       "      b's',\n",
       "      b' the',\n",
       "      b' highest',\n",
       "      <... 4 more items ...>,\n",
       "    ]\n",
       "  )]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.models.compute_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the highest mountain in Africa?\",\n",
    ")\n",
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1841, 235303, 235256, 573, 9393, 8180, 575, 8125, 235336]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tokens_info[0].token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'What',\n",
       " b\"'\",\n",
       " b's',\n",
       " b' the',\n",
       " b' highest',\n",
       " b' mountain',\n",
       " b' in',\n",
       " b' Africa',\n",
       " b'?']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tokens_info[0].tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS-AP7AHUQmV"
   },
   "source": [
    "#### Compute tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Cdhi5AX1TuH0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdk_http_response=HttpResponse(\n",
      "  headers=<dict len=9>\n",
      ") tokens_info=[TokensInfo(\n",
      "  role='user',\n",
      "  token_ids=[\n",
      "    1841,\n",
      "    235303,\n",
      "    235256,\n",
      "    573,\n",
      "    32514,\n",
      "    <... 6 more items ...>,\n",
      "  ],\n",
      "  tokens=[\n",
      "    b'What',\n",
      "    b\"'\",\n",
      "    b's',\n",
      "    b' the',\n",
      "    b' longest',\n",
      "    <... 6 more items ...>,\n",
      "  ]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "response = client.models.compute_tokens(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What's the longest word in the English language?\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sdk_http_response': HttpResponse(\n",
       "   headers=<dict len=9>\n",
       " ),\n",
       " 'tokens_info': [TokensInfo(\n",
       "    role='user',\n",
       "    token_ids=[\n",
       "      1841,\n",
       "      235303,\n",
       "      235256,\n",
       "      573,\n",
       "      32514,\n",
       "      <... 6 more items ...>,\n",
       "    ],\n",
       "    tokens=[\n",
       "      b'What',\n",
       "      b\"'\",\n",
       "      b's',\n",
       "      b' the',\n",
       "      b' longest',\n",
       "      <... 6 more items ...>,\n",
       "    ]\n",
       "  )]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1841, 235303, 235256, 573, 32514, 2204, 575, 573, 4645, 5255, 235336]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tokens_info[0].token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'What',\n",
       " b\"'\",\n",
       " b's',\n",
       " b' the',\n",
       " b' longest',\n",
       " b' word',\n",
       " b' in',\n",
       " b' the',\n",
       " b' English',\n",
       " b' language',\n",
       " b'?']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tokens_info[0].tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0pb-Kh1xEHU"
   },
   "source": [
    "## Function calling\n",
    "\n",
    "[Function calling](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling) lets you provide a set of tools that it can use to respond to the user's prompt. You create a description of a function in your code, then pass that description to a language model in a request. The response from the model includes the name of a function that matches the description and the arguments to call it with.\n",
    "\n",
    "For more examples of Function Calling, refer to [this notebook](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/function-calling/intro_function_calling.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "2BDQPwgcxRN3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(\n",
       "  args={\n",
       "    'destination': 'Bat Yam Promenade'\n",
       "  },\n",
       "  name='get_destination'\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_destination = FunctionDeclaration(\n",
    "    name=\"get_destination\",\n",
    "    description=\"Get the destination that the user wants to go to\",\n",
    "    parameters={\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"destination\": {\n",
    "                \"type\": \"STRING\",\n",
    "                \"description\": \"Destination that the user wants to go to\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "destination_tool = Tool(\n",
    "    function_declarations=[get_destination],\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"I'd like to travel to Bat Yam Promenade.\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[destination_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "response.candidates[0].content.parts[0].function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      avg_logprobs=-0.9529212542942592,\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            function_call=FunctionCall(\n",
       "              args=<... Max depth ...>,\n",
       "              name=<... Max depth ...>\n",
       "            ),\n",
       "            thought_signature=b'\\n\\xee\\x02\\x01\\x1f\\xcc\\x85\\xb6O\\x17i\\xc1\\xa4NFN\\xb6\\x0b\\xab\\x9d[\\xf2\\xfe8u\\x01\\xca\\xa6Gd\\xff\\x00\\x83\\xa2\\x17s{\\x98\\x97\\xb2\\xa1\\xba$\\x85\\xb7\\x95\\xf1$f6\\xcd\\x8f=\\xf0\\x11\\xb0x\\xfeCw\\x8a\\x8e\\xd5\"\\xfb\\xca\\xc2\\xf4\\xff\\xb3p\\xe1\\xd2~N\\xa3N\\xea\\x07,f\\xc4\\xcc>_y\\x9aZ`\\xae\\xc4\\xa4\\xb9\\xf4~VY...'\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>\n",
       "    ),\n",
       "  ],\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 45, 13, 414123, tzinfo=TzInfo(0)),\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='eavoaKujGaD4tfAPqcr2iA8',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=7,\n",
       "    candidates_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=7\n",
       "      ),\n",
       "    ],\n",
       "    prompt_token_count=35,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=35\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=77,\n",
       "    total_token_count=119,\n",
       "    traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA1Sn-VQE6_J"
   },
   "source": [
    "## Use context caching\n",
    "\n",
    "[Context caching](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview) lets you to store frequently used input tokens in a dedicated cache and reference them for subsequent requests, eliminating the need to repeatedly pass the same set of tokens to a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqxTesUPIkNC"
   },
   "source": [
    "#### Create a cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "adsuvFDA6xP5"
   },
   "outputs": [],
   "source": [
    "system_instruction = \"\"\"\n",
    "  You are an expert researcher who has years of experience in conducting systematic literature surveys and meta-analyses of different topics.\n",
    "  You pride yourself on incredible accuracy and attention to detail. You always stick to the facts in the sources provided, and never make up new facts.\n",
    "  Now look at the research paper below, and answer the following questions in 1-2 sentences.\n",
    "\"\"\"\n",
    "\n",
    "# https://arxiv.org/abs/2312.11805\n",
    "# Gemini: A Family of Highly Capable Multimodal Models\n",
    "\n",
    "# https://arxiv.org/abs/2403.05530\n",
    "# Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context\n",
    "\n",
    "pdf_parts = [\n",
    "    Part.from_uri(\n",
    "        file_uri=\"gs://cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf\",\n",
    "        mime_type=\"application/pdf\",\n",
    "    ),\n",
    "    Part.from_uri(\n",
    "        file_uri=\"gs://cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n",
    "        mime_type=\"application/pdf\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "cached_content = client.caches.create(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=CreateCachedContentConfig(\n",
    "        system_instruction=system_instruction,\n",
    "        contents=pdf_parts,\n",
    "        ttl=\"3600s\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CachedContent(\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 10, 30, 11356, tzinfo=TzInfo(0)),\n",
       "  expire_time=datetime.datetime(2025, 10, 10, 7, 10, 29, 996891, tzinfo=TzInfo(0)),\n",
       "  model='projects/qwiklabs-gcp-04-0bbee4ff5bff/locations/europe-west1/publishers/google/models/gemini-2.5-flash',\n",
       "  name='projects/576729279835/locations/europe-west1/cachedContents/7145854162020859904',\n",
       "  update_time=datetime.datetime(2025, 10, 10, 6, 10, 30, 11356, tzinfo=TzInfo(0)),\n",
       "  usage_metadata=CachedContentUsageMetadata(\n",
       "    image_count=167,\n",
       "    text_count=321,\n",
       "    total_token_count=43166\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.genai.types.CachedContent"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cached_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBdQNHEoJmC5"
   },
   "source": [
    "#### Use a cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "N8EhgCzlIoFI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both research papers share the goal of developing and advancing the Gemini family of highly capable multimodal models. This involves building models with strong generalist capabilities across various modalities (image, audio, video, and text) and continuously improving their efficiency, reasoning, and long-context performance.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"What is the research goal shared by these research papers?\",\n",
    "    config=GenerateContentConfig(\n",
    "        cached_content=cached_content.name,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azhqrdiCer19"
   },
   "source": [
    "#### Delete a cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "rAUYcfOUdeoi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteCachedContentResponse(\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.caches.delete(name=cached_content.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43be33d2672b"
   },
   "source": [
    "## Batch prediction\n",
    "\n",
    "Different from getting online (synchronous) responses, where you are limited to one input request at a time, [batch predictions for the Gemini API in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini) allow you to send a large number of requests to Gemini in a single batch request. Then, the model responses asynchronously populate to your storage output location in [Cloud Storage](https://cloud.google.com/storage/docs/introduction) or [BigQuery](https://cloud.google.com/bigquery/docs/storage_overview).\n",
    "\n",
    "Batch predictions are generally more efficient and cost-effective than online predictions when processing a large number of inputs that are not latency sensitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adf948ae326b"
   },
   "source": [
    "### Prepare batch inputs\n",
    "\n",
    "The input for batch requests specifies the items to send to your model for prediction.\n",
    "\n",
    "Batch requests for Gemini accept BigQuery storage sources and Cloud Storage sources. You can learn more about the batch input formats in the [Batch text generation](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/batch-prediction-gemini#prepare_your_inputs) page.\n",
    "\n",
    "This tutorial uses Cloud Storage as an example. The requirements for Cloud Storage input are:\n",
    "\n",
    "- File format: [JSON Lines (JSONL)](https://jsonlines.org/)\n",
    "- Located in `us-central1`\n",
    "- Appropriate read permissions for the service account\n",
    "\n",
    "Each request that you send to a model can include parameters that control how the model generates a response. Learn more about Gemini parameters in the [Experiment with parameter values](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values) page.\n",
    "\n",
    "This is one of the example requests in the input JSONL file `batch_requests_for_multimodal_input_2.jsonl`:\n",
    "\n",
    "```json\n",
    "{\"request\":{\"contents\": [{\"role\": \"user\", \"parts\": [{\"text\": \"List objects in this image.\"}, {\"file_data\": {\"file_uri\": \"gs://cloud-samples-data/generative-ai/image/office-desk.jpeg\", \"mime_type\": \"image/jpeg\"}}]}],\"generationConfig\":{\"temperature\": 0.4}}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "81b25154a51a"
   },
   "outputs": [],
   "source": [
    "INPUT_DATA = \"gs://cloud-samples-data/generative-ai/batch/batch_requests_for_multimodal_input_2.jsonl\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2031bb3f44c2"
   },
   "source": [
    "### Prepare batch output location\n",
    "\n",
    "When a batch prediction task completes, the output is stored in the location that you specified in your request.\n",
    "\n",
    "- The location is in the form of a Cloud Storage or BigQuery URI prefix, for example:\n",
    "`gs://path/to/output/data` or `bq://projectId.bqDatasetId`.\n",
    "\n",
    "- If not specified, `gs://STAGING_BUCKET/gen-ai-batch-prediction` will be used for Cloud Storage source and `bq://PROJECT_ID.gen_ai_batch_prediction.predictions_TIMESTAMP` will be used for BigQuery source.\n",
    "\n",
    "This tutorial uses a Cloud Storage bucket as an example for the output location.\n",
    "\n",
    "- You can specify the URI of your Cloud Storage bucket in `BUCKET_URI`, or\n",
    "- if it is not specified, a new Cloud Storage bucket in the form of `gs://PROJECT_ID-TIMESTAMP` will be created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "fddd98cd84cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949/...\n"
     ]
    }
   ],
   "source": [
    "BUCKET_URI = \"[your-cloud-storage-bucket]\"   # \"qwiklabs-gcp-04-0bbee4ff5bff-labconfig-bucket\"  # @param {type:\"string\"}\n",
    "\n",
    "if BUCKET_URI == \"[your-cloud-storage-bucket]\":\n",
    "    TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    BUCKET_URI = f\"gs://{PROJECT_ID}-{TIMESTAMP}\"\n",
    "\n",
    "    ! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUCKET_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7da62c98880"
   },
   "source": [
    "### Send a batch prediction request\n",
    "\n",
    "To make a batch prediction request, you specify a source model ID, an input source and an output location where Vertex AI stores the batch prediction results.\n",
    "\n",
    "To learn more, see the [Batch prediction API](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/batch-prediction-api) page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "7ed3c2925663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ValueError: Unsupported destination: qwiklabs-gcp-04-0bbee4ff5bff-labconfig-bucket\n",
    "'gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'\n",
    "\n",
    "batch_job = client.batches.create(\n",
    "    model=MODEL_ID,\n",
    "    src=INPUT_DATA,\n",
    "    config=CreateBatchJobConfig(dest=BUCKET_URI),\n",
    ")\n",
    "batch_job.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchJob(\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0)),\n",
       "  dest=BatchJobDestination(\n",
       "    format='jsonl',\n",
       "    gcs_uri='gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'\n",
       "  ),\n",
       "  display_name='genai_batch_job_20251010061959_7b91e',\n",
       "  model='publishers/google/models/gemini-2.5-flash',\n",
       "  name='projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728',\n",
       "  src=BatchJobSource(\n",
       "    format='jsonl',\n",
       "    gcs_uri=[\n",
       "      'gs://cloud-samples-data/generative-ai/batch/batch_requests_for_multimodal_input_2.jsonl',\n",
       "    ]\n",
       "  ),\n",
       "  state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'>,\n",
       "  update_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0))\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job_orig = batch_job\n",
    "batch_job_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1bd49ff2c9e"
   },
   "source": [
    "Print out the job status and other properties. You can also check the status in the Cloud Console at https://console.cloud.google.com/vertex-ai/batch-predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ee2ec586e4f1"
   },
   "outputs": [],
   "source": [
    "batch_job = client.batches.get(name=batch_job.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchJob(\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0)),\n",
       "  dest=BatchJobDestination(\n",
       "    format='jsonl',\n",
       "    gcs_uri='gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'\n",
       "  ),\n",
       "  display_name='genai_batch_job_20251010061959_7b91e',\n",
       "  model='publishers/google/models/gemini-2.5-flash',\n",
       "  name='projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728',\n",
       "  src=BatchJobSource(\n",
       "    format='jsonl',\n",
       "    gcs_uri=[\n",
       "      'gs://cloud-samples-data/generative-ai/batch/batch_requests_for_multimodal_input_2.jsonl',\n",
       "    ]\n",
       "  ),\n",
       "  state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'>,\n",
       "  update_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0))\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64eaf082ecb0"
   },
   "source": [
    "Optionally, you can list all the batch prediction jobs in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "da8e9d43a89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728 | 2025-10-10 06:20:00.063092+00:00 | JobState.JOB_STATE_QUEUED\n"
     ]
    }
   ],
   "source": [
    "for job in client.batches.list():\n",
    "    print(job.name, \"|\" , job.create_time, \"|\" , job.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "da8e9d43a89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728 | 2025-10-10 06:20:00.063092+00:00 | JobState.JOB_STATE_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "for job in client.batches.list():\n",
    "    print(job.name, \"|\" , job.create_time, \"|\" , job.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statuses\n",
    "# JOB_STATE_PENDING\n",
    "# JOB_STATE_QUEUED\n",
    "# JOB_STATE_RUNNING\n",
    "# JOB_STATE_SUCCEEDED\n",
    "\n",
    "# https://ai.google.dev/gemini-api/docs/batch-api\n",
    "# JOB_STATE_FAILED\n",
    "# JOB_STATE_CANCELLED\n",
    "# JOB_STATE_EXPIRED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de178468ba15"
   },
   "source": [
    "### Wait for the batch prediction job to complete\n",
    "\n",
    "Depending on the number of input items that you submitted, a batch generation task can take some time to complete. You can use the following code to check the job status and wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchJob(\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0)),\n",
       "  dest=BatchJobDestination(\n",
       "    format='jsonl',\n",
       "    gcs_uri='gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'\n",
       "  ),\n",
       "  display_name='genai_batch_job_20251010061959_7b91e',\n",
       "  model='publishers/google/models/gemini-2.5-flash',\n",
       "  name='projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728',\n",
       "  src=BatchJobSource(\n",
       "    format='jsonl',\n",
       "    gcs_uri=[\n",
       "      'gs://cloud-samples-data/generative-ai/batch/batch_requests_for_multimodal_input_2.jsonl',\n",
       "    ]\n",
       "  ),\n",
       "  state=<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'>,\n",
       "  update_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0))\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<JobState.JOB_STATE_PENDING: 'JOB_STATE_PENDING'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_job.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "c2187c091738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job failed: None\n"
     ]
    }
   ],
   "source": [
    "# not sure why original code did not work to track status of batch job\n",
    "import time\n",
    "\n",
    "# Refresh the job until complete\n",
    "while batch_job.state == \"JOB_STATE_RUNNING\":\n",
    "    time.sleep(5)\n",
    "    batch_job = client.batches.get(name=batch_job.name)\n",
    "\n",
    "# Check if the job succeeds\n",
    "if batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
    "    print(\"Job succeeded!\")\n",
    "else:\n",
    "    print(f\"Job failed: {batch_job.error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchJob(\n",
       "  create_time=datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0)),\n",
       "  dest=BatchJobDestination(\n",
       "    format='jsonl',\n",
       "    gcs_uri='gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'\n",
       "  ),\n",
       "  display_name='genai_batch_job_20251010061959_7b91e',\n",
       "  end_time=datetime.datetime(2025, 10, 10, 6, 27, 26, 433064, tzinfo=TzInfo(0)),\n",
       "  model='publishers/google/models/gemini-2.5-flash',\n",
       "  name='projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728',\n",
       "  src=BatchJobSource(\n",
       "    format='jsonl',\n",
       "    gcs_uri=[\n",
       "      'gs://cloud-samples-data/generative-ai/batch/batch_requests_for_multimodal_input_2.jsonl',\n",
       "    ]\n",
       "  ),\n",
       "  start_time=datetime.datetime(2025, 10, 10, 6, 24, 18, 344730, tzinfo=TzInfo(0)),\n",
       "  state=<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'>,\n",
       "  update_time=datetime.datetime(2025, 10, 10, 6, 27, 26, 433064, tzinfo=TzInfo(0))\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728',\n",
       " 'display_name': 'genai_batch_job_20251010061959_7b91e',\n",
       " 'state': <JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'>,\n",
       " 'error': None,\n",
       " 'create_time': datetime.datetime(2025, 10, 10, 6, 20, 0, 63092, tzinfo=TzInfo(0)),\n",
       " 'start_time': datetime.datetime(2025, 10, 10, 6, 24, 18, 344730, tzinfo=TzInfo(0)),\n",
       " 'end_time': datetime.datetime(2025, 10, 10, 6, 27, 26, 433064, tzinfo=TzInfo(0)),\n",
       " 'update_time': datetime.datetime(2025, 10, 10, 6, 27, 26, 433064, tzinfo=TzInfo(0)),\n",
       " 'model': 'publishers/google/models/gemini-2.5-flash',\n",
       " 'src': BatchJobSource(\n",
       "   format='jsonl',\n",
       "   gcs_uri=[\n",
       "     'gs://cloud-samples-data/generative-ai/batch/batch_requests_for_multimodal_input_2.jsonl',\n",
       "   ]\n",
       " ),\n",
       " 'dest': BatchJobDestination(\n",
       "   format='jsonl',\n",
       "   gcs_uri='gs://qwiklabs-gcp-04-0bbee4ff5bff-20251010061949'\n",
       " )}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/576729279835/locations/europe-west1/batchPredictionJobs/6960016699558985728'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job succeeded!\n"
     ]
    }
   ],
   "source": [
    "# not sure why original code did not work to track status of batch job\n",
    "import time\n",
    "\n",
    "# # Refresh the job until complete\n",
    "# while client.state == \"JOB_STATE_RUNNING\":\n",
    "#     time.sleep(5)\n",
    "#     batch_job = client.batches.get(name=client.name)\n",
    "\n",
    "# Check if the job succeeds\n",
    "if client.state == \"JOB_STATE_SUCCEEDED\":\n",
    "    print(\"Job succeeded!\")\n",
    "else:\n",
    "    print(f\"Job failed: {client.error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0156eaf66675"
   },
   "source": [
    "### Retrieve batch prediction results\n",
    "\n",
    "When a batch prediction task is complete, the output of the prediction is stored in the location that you specified in your request. It is also available in `batch_job.dest.bigquery_uri` or `batch_job.dest.gcs_uri`.\n",
    "\n",
    "Example output:\n",
    "\n",
    "```json\n",
    "{\"status\": \"\", \"processed_time\": \"2024-11-13T14:04:28.376+00:00\", \"request\": {\"contents\": [{\"parts\": [{\"file_data\": null, \"text\": \"List objects in this image.\"}, {\"file_data\": {\"file_uri\": \"gs://cloud-samples-data/generative-ai/image/gardening-tools.jpeg\", \"mime_type\": \"image/jpeg\"}, \"text\": null}], \"role\": \"user\"}], \"generationConfig\": {\"temperature\": 0.4}}, \"response\": {\"candidates\": [{\"avgLogprobs\": -0.10394711927934126, \"content\": {\"parts\": [{\"text\": \"Here's a list of the objects in the image:\\n\\n* **Watering can:** A green plastic watering can with a white rose head.\\n* **Plant:** A small plant (possibly oregano) in a terracotta pot.\\n* **Terracotta pots:** Two terracotta pots, one containing the plant and another empty, stacked on top of each other.\\n* **Gardening gloves:** A pair of striped gardening gloves.\\n* **Gardening tools:** A small trowel and a hand cultivator (hoe).  Both are green with black handles.\"}], \"role\": \"model\"}, \"finishReason\": \"STOP\"}], \"modelVersion\": \"gemini-2.5-flash\", \"usageMetadata\": {\"candidatesTokenCount\": 110, \"promptTokenCount\": 264, \"totalTokenCount\": 374}}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "c2ce0968112c"
   },
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import pandas as pd\n",
    "\n",
    "fs = fsspec.filesystem(\"gcs\")\n",
    "\n",
    "file_paths = fs.glob(f\"{batch_job.dest.gcs_uri}/*/predictions.jsonl\")\n",
    "\n",
    "if batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
    "    # Load the JSONL file into a DataFrame\n",
    "    df = pd.read_json(f\"gs://{file_paths[0]}\", lines=True)\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>processed_time</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2025-10-10 06:26:11.473000+00:00</td>\n",
       "      <td>{'contents': [{'parts': [{'file_data': None, '...</td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.85887939805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2025-10-10 06:26:11.466000+00:00</td>\n",
       "      <td>{'contents': [{'parts': [{'file_data': None, '...</td>\n",
       "      <td>{'candidates': [{'avgLogprobs': -0.83119090010...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  status                   processed_time  \\\n",
       "0        2025-10-10 06:26:11.473000+00:00   \n",
       "1        2025-10-10 06:26:11.466000+00:00   \n",
       "\n",
       "                                             request  \\\n",
       "0  {'contents': [{'parts': [{'file_data': None, '...   \n",
       "1  {'contents': [{'parts': [{'file_data': None, '...   \n",
       "\n",
       "                                            response  \n",
       "0  {'candidates': [{'avgLogprobs': -0.85887939805...  \n",
       "1  {'candidates': [{'avgLogprobs': -0.83119090010...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fsspec\n",
    "import pandas as pd\n",
    "\n",
    "fs = fsspec.filesystem(\"gcs\")\n",
    "\n",
    "file_paths = fs.glob(f\"{client.dest.gcs_uri}/*/predictions.jsonl\")\n",
    "\n",
    "if client.state == \"JOB_STATE_SUCCEEDED\":\n",
    "    # Load the JSONL file into a DataFrame\n",
    "    df = pd.read_json(f\"gs://{file_paths[0]}\", lines=True)\n",
    "\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2025-10-10 06:26:11.473000+0000', tz='UTC')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contents': [{'parts': [{'file_data': None,\n",
       "     'text': 'List objects in this image.'},\n",
       "    {'file_data': {'file_uri': 'gs://cloud-samples-data/generative-ai/image/gardening-tools.jpeg',\n",
       "      'mime_type': 'image/jpeg'},\n",
       "     'text': None}],\n",
       "   'role': 'user'}],\n",
       " 'generationConfig': {'temperature': 0.4}}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img1\n",
    "df.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'avgLogprobs': -0.858879398059293,\n",
       "   'content': {'parts': [{'text': 'Here are the objects visible in the image:\\n\\n1.  **Watering can:** A dark green plastic watering can with a white sprinkler head and an embossed floral design on its side.\\n2.  **Plant in a pot:** A small green plant growing in a terracotta pot.\\n3.  **Empty terracotta pots:** Two terracotta pots, stacked one on top of the other.\\n4.  **Hand trowel:** A small green gardening shovel with a black handle.\\n5.  **Hand cultivator / Hoe:** A small green gardening tool with prongs on one side and a flat blade on the other, with a black handle.\\n6.  **Gardening gloves:** A pair of striped gardening gloves (green, yellow, and white) with green cuffs.\\n7.  **Grass:** The green lawn serving as the background surface.'}],\n",
       "    'role': 'model'},\n",
       "   'finishReason': 'STOP'}],\n",
       " 'createTime': '2025-10-10T06:26:11.543450Z',\n",
       " 'modelVersion': 'gemini-2.5-flash',\n",
       " 'responseId': 'A6foaNqVIfCy2fMPzMKxgAQ',\n",
       " 'usageMetadata': {'candidatesTokenCount': 173,\n",
       "  'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 173}],\n",
       "  'promptTokenCount': 1812,\n",
       "  'promptTokensDetails': [{'modality': 'IMAGE', 'tokenCount': 1806},\n",
       "   {'modality': 'TEXT', 'tokenCount': 6}],\n",
       "  'thoughtsTokenCount': 768,\n",
       "  'totalTokenCount': 2753,\n",
       "  'trafficType': 'ON_DEMAND'}}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contents': [{'parts': [{'file_data': None,\n",
       "     'text': 'List objects in this image.'},\n",
       "    {'file_data': {'file_uri': 'gs://cloud-samples-data/generative-ai/image/office-desk.jpeg',\n",
       "      'mime_type': 'image/jpeg'},\n",
       "     'text': None}],\n",
       "   'role': 'user'}],\n",
       " 'generationConfig': {'temperature': 0.4}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img2\n",
    "df.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'avgLogprobs': -0.831190900104801,\n",
       "   'content': {'parts': [{'text': 'Here are the objects visible in the image:\\n\\n1.  Digital tablet (with a blank white screen)\\n2.  Keyboard\\n3.  Computer mouse (white and teal/green)\\n4.  Coffee cup (white, with coffee)\\n5.  Saucer (white, under the coffee cup)\\n6.  Miniature shopping cart\\n7.  Red gift box (inside the shopping cart)\\n8.  Globe\\n9.  Eiffel Tower replica / miniature\\n10. Toy airplane / model airplane\\n11. Passport (brown)\\n12. Sunglasses\\n13. Money (dollar bills)\\n14. Notebook / Spiral notebook\\n15. Pen (yellow and black)\\n16. Wooden table (the surface everything is on)'}],\n",
       "    'role': 'model'},\n",
       "   'finishReason': 'STOP'}],\n",
       " 'createTime': '2025-10-10T06:26:11.545931Z',\n",
       " 'modelVersion': 'gemini-2.5-flash',\n",
       " 'responseId': 'A6foaIupIbOBrNcP57XJuAQ',\n",
       " 'usageMetadata': {'candidatesTokenCount': 164,\n",
       "  'candidatesTokensDetails': [{'modality': 'TEXT', 'tokenCount': 164}],\n",
       "  'promptTokenCount': 1812,\n",
       "  'promptTokensDetails': [{'modality': 'TEXT', 'tokenCount': 6},\n",
       "   {'modality': 'IMAGE', 'tokenCount': 1806}],\n",
       "  'thoughtsTokenCount': 845,\n",
       "  'totalTokenCount': 2821,\n",
       "  'trafficType': 'ON_DEMAND'}}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f81ccNPjiVzH"
   },
   "source": [
    "## Get text embeddings\n",
    "\n",
    "You can get text embeddings for a snippet of text by using `embed_content` method. All models produce an output with 768 dimensions by default. However, some models give users the option to choose an output dimensionality between `1` and `768`. See [Vertex AI text embeddings API](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "zGOCzT7y31rk"
   },
   "outputs": [],
   "source": [
    "TEXT_EMBEDDING_MODEL_ID = \"gemini-embedding-001\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "s94DkG5JewHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ContentEmbedding(\n",
      "  statistics=ContentEmbeddingStatistics(\n",
      "    token_count=15.0,\n",
      "    truncated=False\n",
      "  ),\n",
      "  values=[\n",
      "    -0.0015945110935717821,\n",
      "    0.0067519512958824635,\n",
      "    0.017575768753886223,\n",
      "    -0.010327713564038277,\n",
      "    -0.00995620433241129,\n",
      "    <... 123 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  statistics=ContentEmbeddingStatistics(\n",
      "    token_count=10.0,\n",
      "    truncated=False\n",
      "  ),\n",
      "  values=[\n",
      "    -0.007576516829431057,\n",
      "    -0.005990396253764629,\n",
      "    -0.003270037705078721,\n",
      "    -0.01751021482050419,\n",
      "    -0.023507025092840195,\n",
      "    <... 123 more items ...>,\n",
      "  ]\n",
      "), ContentEmbedding(\n",
      "  statistics=ContentEmbeddingStatistics(\n",
      "    token_count=13.0,\n",
      "    truncated=False\n",
      "  ),\n",
      "  values=[\n",
      "    0.011074518784880638,\n",
      "    -0.02361123077571392,\n",
      "    0.002291288459673524,\n",
      "    -0.00906078889966011,\n",
      "    -0.005773674696683884,\n",
      "    <... 123 more items ...>,\n",
      "  ]\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "response = client.models.embed_content(\n",
    "    model=TEXT_EMBEDDING_MODEL_ID,\n",
    "    contents=[\n",
    "        \"How do I get a driver's license/learner's permit?\",\n",
    "        \"How do I renew my driver's license?\",\n",
    "        \"How do I change my address on my driver's license?\",\n",
    "    ],\n",
    "    config=EmbedContentConfig(output_dimensionality=128),\n",
    ")\n",
    "\n",
    "print(response.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedContentResponse(\n",
       "  embeddings=[\n",
       "    ContentEmbedding(\n",
       "      statistics=ContentEmbeddingStatistics(\n",
       "        token_count=15.0,\n",
       "        truncated=False\n",
       "      ),\n",
       "      values=[\n",
       "        -0.0015945110935717821,\n",
       "        0.0067519512958824635,\n",
       "        0.017575768753886223,\n",
       "        -0.010327713564038277,\n",
       "        -0.00995620433241129,\n",
       "        <... 123 more items ...>,\n",
       "      ]\n",
       "    ),\n",
       "    ContentEmbedding(\n",
       "      statistics=ContentEmbeddingStatistics(\n",
       "        token_count=10.0,\n",
       "        truncated=False\n",
       "      ),\n",
       "      values=[\n",
       "        -0.007576516829431057,\n",
       "        -0.005990396253764629,\n",
       "        -0.003270037705078721,\n",
       "        -0.01751021482050419,\n",
       "        -0.023507025092840195,\n",
       "        <... 123 more items ...>,\n",
       "      ]\n",
       "    ),\n",
       "    ContentEmbedding(\n",
       "      statistics=ContentEmbeddingStatistics(\n",
       "        token_count=13.0,\n",
       "        truncated=False\n",
       "      ),\n",
       "      values=[\n",
       "        0.011074518784880638,\n",
       "        -0.02361123077571392,\n",
       "        0.002291288459673524,\n",
       "        -0.00906078889966011,\n",
       "        -0.005773674696683884,\n",
       "        <... 123 more items ...>,\n",
       "      ]\n",
       "    ),\n",
       "  ],\n",
       "  metadata=EmbedContentMetadata(\n",
       "    billable_character_count=112\n",
       "  ),\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=9>\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sdk_http_response': HttpResponse(\n",
       "   headers=<dict len=9>\n",
       " ),\n",
       " 'embeddings': [ContentEmbedding(\n",
       "    statistics=ContentEmbeddingStatistics(\n",
       "      token_count=15.0,\n",
       "      truncated=False\n",
       "    ),\n",
       "    values=[\n",
       "      -0.0015945110935717821,\n",
       "      0.0067519512958824635,\n",
       "      0.017575768753886223,\n",
       "      -0.010327713564038277,\n",
       "      -0.00995620433241129,\n",
       "      <... 123 more items ...>,\n",
       "    ]\n",
       "  ),\n",
       "  ContentEmbedding(\n",
       "    statistics=ContentEmbeddingStatistics(\n",
       "      token_count=10.0,\n",
       "      truncated=False\n",
       "    ),\n",
       "    values=[\n",
       "      -0.007576516829431057,\n",
       "      -0.005990396253764629,\n",
       "      -0.003270037705078721,\n",
       "      -0.01751021482050419,\n",
       "      -0.023507025092840195,\n",
       "      <... 123 more items ...>,\n",
       "    ]\n",
       "  ),\n",
       "  ContentEmbedding(\n",
       "    statistics=ContentEmbeddingStatistics(\n",
       "      token_count=13.0,\n",
       "      truncated=False\n",
       "    ),\n",
       "    values=[\n",
       "      0.011074518784880638,\n",
       "      -0.02361123077571392,\n",
       "      0.002291288459673524,\n",
       "      -0.00906078889966011,\n",
       "      -0.005773674696683884,\n",
       "      <... 123 more items ...>,\n",
       "    ]\n",
       "  )],\n",
       " 'metadata': EmbedContentMetadata(\n",
       "   billable_character_count=112\n",
       " )}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content-type': 'application/json; charset=UTF-8',\n",
       " 'vary': 'Origin, X-Origin, Referer',\n",
       " 'content-encoding': 'gzip',\n",
       " 'date': 'Fri, 10 Oct 2025 06:36:49 GMT',\n",
       " 'server': 'scaffolding on HTTPServer2',\n",
       " 'x-xss-protection': '0',\n",
       " 'x-frame-options': 'SAMEORIGIN',\n",
       " 'x-content-type-options': 'nosniff',\n",
       " 'transfer-encoding': 'chunked'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sdk_http_response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of embeddings: 128\n",
      "Dimension of embeddings: 128\n",
      "Dimension of embeddings: 128\n"
     ]
    }
   ],
   "source": [
    "for emb in response.embeddings:\n",
    "    print(f\"Dimension of embeddings: {len(emb.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContentEmbedding(\n",
       "  statistics=ContentEmbeddingStatistics(\n",
       "    token_count=15.0,\n",
       "    truncated=False\n",
       "  ),\n",
       "  values=[\n",
       "    -0.0015945110935717821,\n",
       "    0.0067519512958824635,\n",
       "    0.017575768753886223,\n",
       "    -0.010327713564038277,\n",
       "    -0.00995620433241129,\n",
       "    <... 123 more items ...>,\n",
       "  ]\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': [-0.0015945110935717821,\n",
       "  0.0067519512958824635,\n",
       "  0.017575768753886223,\n",
       "  -0.010327713564038277,\n",
       "  -0.00995620433241129,\n",
       "  -0.006378513760864735,\n",
       "  0.003915519919246435,\n",
       "  -0.006273339968174696,\n",
       "  0.022109422832727432,\n",
       "  -0.018150800839066505,\n",
       "  -0.018822040408849716,\n",
       "  0.021871089935302734,\n",
       "  -0.012852595187723637,\n",
       "  -0.0035492617171257734,\n",
       "  0.13061952590942383,\n",
       "  0.02963041514158249,\n",
       "  0.002169992309063673,\n",
       "  0.034843750298023224,\n",
       "  -0.015753397718071938,\n",
       "  -0.013527893461287022,\n",
       "  -0.019452597945928574,\n",
       "  0.01025773398578167,\n",
       "  -0.005315437447279692,\n",
       "  0.018413739278912544,\n",
       "  0.003861301811411977,\n",
       "  -0.007576272822916508,\n",
       "  -0.005402481649070978,\n",
       "  -0.009142722003161907,\n",
       "  0.039729878306388855,\n",
       "  -0.0018519624136388302,\n",
       "  0.012266855686903,\n",
       "  0.010037660598754883,\n",
       "  0.007238780613988638,\n",
       "  0.020442964509129524,\n",
       "  -0.0078003667294979095,\n",
       "  -0.0018548255320638418,\n",
       "  0.006518074311316013,\n",
       "  -0.006224988494068384,\n",
       "  -0.01723303087055683,\n",
       "  -0.023265745490789413,\n",
       "  -0.00549757806584239,\n",
       "  0.022972751408815384,\n",
       "  -0.005138064734637737,\n",
       "  -0.014634148217737675,\n",
       "  0.016655806452035904,\n",
       "  -0.006420455407351255,\n",
       "  -0.013211443088948727,\n",
       "  -0.01389378309249878,\n",
       "  -0.042299795895814896,\n",
       "  -0.001664644107222557,\n",
       "  0.018035508692264557,\n",
       "  -0.0026884698309004307,\n",
       "  0.011458703316748142,\n",
       "  -0.18666838109493256,\n",
       "  -0.03429654985666275,\n",
       "  -0.012534483335912228,\n",
       "  0.018469054251909256,\n",
       "  0.0005467924056574702,\n",
       "  -0.02014174684882164,\n",
       "  -0.018586894497275352,\n",
       "  -0.00651234295219183,\n",
       "  -0.01812654733657837,\n",
       "  -0.008596183732151985,\n",
       "  -0.04233064502477646,\n",
       "  0.00549258291721344,\n",
       "  0.019521556794643402,\n",
       "  0.013068689033389091,\n",
       "  0.024405814707279205,\n",
       "  0.001478008460253477,\n",
       "  -0.015134051442146301,\n",
       "  -0.003484928049147129,\n",
       "  0.024567926302552223,\n",
       "  -0.00589726772159338,\n",
       "  -0.01669134758412838,\n",
       "  0.022205611690878868,\n",
       "  0.008073903620243073,\n",
       "  0.0002141776349162683,\n",
       "  -0.011168691329658031,\n",
       "  -0.0009747841977514327,\n",
       "  -0.007790451869368553,\n",
       "  -0.0003114709979854524,\n",
       "  0.02564558945596218,\n",
       "  -0.005094403866678476,\n",
       "  0.0022833540569990873,\n",
       "  -0.012237356044352055,\n",
       "  -0.018158311024308205,\n",
       "  -0.008875466883182526,\n",
       "  -0.013620990328490734,\n",
       "  -0.011119878850877285,\n",
       "  0.012804008089005947,\n",
       "  -0.008668835274875164,\n",
       "  0.018674427643418312,\n",
       "  0.020337218418717384,\n",
       "  -0.01412979420274496,\n",
       "  -0.0232790969312191,\n",
       "  -0.01978808268904686,\n",
       "  -0.004437541589140892,\n",
       "  -0.003505850210785866,\n",
       "  0.011494685895740986,\n",
       "  -0.011769970878958702,\n",
       "  -0.037994928658008575,\n",
       "  -0.019168388098478317,\n",
       "  -0.010447568260133266,\n",
       "  -0.00458631431683898,\n",
       "  0.03995655104517937,\n",
       "  -0.034908734261989594,\n",
       "  0.01140020601451397,\n",
       "  -0.03624480962753296,\n",
       "  -0.007923529483377934,\n",
       "  -0.0014580502174794674,\n",
       "  0.02217760495841503,\n",
       "  0.008736148476600647,\n",
       "  0.0028866867069154978,\n",
       "  -0.008395886048674583,\n",
       "  0.003623479977250099,\n",
       "  -0.13745254278182983,\n",
       "  -0.006328403949737549,\n",
       "  0.00017140337149612606,\n",
       "  -0.03571510687470436,\n",
       "  -0.0038781999610364437,\n",
       "  0.025907931849360466,\n",
       "  0.004748169798403978,\n",
       "  -0.007541480008512735,\n",
       "  0.021119985729455948,\n",
       "  0.0017913134070113301,\n",
       "  0.0062782904133200645,\n",
       "  -0.00948131550103426,\n",
       "  -0.012380233034491539],\n",
       " 'statistics': ContentEmbeddingStatistics(\n",
       "   token_count=15.0,\n",
       "   truncated=False\n",
       " )}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.embeddings[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sdk_http_response', 'embeddings', 'metadata'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQwiONFdVHw5"
   },
   "source": [
    "# What's next\n",
    "\n",
    "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
    "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_genai_sdk.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
