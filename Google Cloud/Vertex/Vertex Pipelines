GSP965 22030 Vertex Pipelines 

Overview
Pipelines help you automate and reproduce your ML workflow. Vertex AI integrates the ML offerings across Google Cloud into a seamless development experience. Previously, models trained with AutoML and custom models were accessible via separate services. Vertex AI combines both into a single API, along with other new products. Vertex AI also includes a variety of MLOps products, like Vertex Pipelines. In this lab, you will learn how to create and run ML pipelines with Vertex Pipelines.

Why are ML pipelines useful?
Before diving in, first understand why you would want to use a pipeline. Imagine you're building out a ML workflow that includes processing data, training a model, hyperparameter tuning, evaluation, and model deployment. Each of these steps may have different dependencies, which may become unwieldy if you treat the entire workflow as a monolith. As you begin to scale your ML process, you might want to share your ML workflow with others on your team so they can run it and contribute code. Without a reliable, reproducible process, this can become difficult. With pipelines, each step in your ML process is its own container. This lets you develop steps independently and track the input and output from each step in a reproducible way. You can also schedule or trigger runs of your pipeline based on other events in your Cloud environment, like when new training data is available.

What you'll learn
Use the Kubeflow Pipelines SDK to build scalable ML pipelines
Create and run a 3-step intro pipeline that takes text input
Create and run a pipeline that trains, evaluates, and deploys an AutoML classification model
Use pre-built components for interacting with Vertex AI services, provided through the google_cloud_pipeline_components library
Schedule a pipeline job with Cloud Scheduler






Create an Vertex Notebooks instance
Click on the Navigation Menu.
Navigate to Vertex AI, then to Workbench.
On the Notebook instances page, navigate to the User-Managed Notebooks tab and wait until ai-notebook is fully created.
It should take a few minutes for the notebook to be fully created.
Once the instance has been created, select Open JupyterLab









Vertex Pipelines setup
There are a few additional libraries you'll need to install in order to use Vertex Pipelines:
Kubeflow Pipelines: This is the SDK used to build the pipeline. Vertex Pipelines supports running pipelines built with both Kubeflow Pipelines or TFX.
Google Cloud Pipeline Components: This library provides pre-built components that make it easier to interact with Vertex AI services from your pipeline steps.


Step 1: Create Python notebook and install libraries
From the Launcher menu in your Notebook instance, create a notebook by selecting Python 3.
You can access the Launcher menu by clicking on the + sign in the top left of your notebook instance.

To install both services needed for this lab, first set the user flag in a notebook cell:
USER_FLAG = "--user"

Then run the following from your notebook:
!pip3 install {USER_FLAG} google-cloud-aiplatform==1.0.0 --upgrade
!pip3 install {USER_FLAG} kfp google-cloud-pipeline-components==0.1.1 --upgrade

After installing these packages you'll need to restart the kernel:
import os
if not os.getenv("IS_TESTING"):
    # Automatically restart kernel after installs
    import IPython
    app = IPython.Application.instance()
    app.kernel.do_shutdown(True)

Finally, check that you have correctly installed the packages. The KFP SDK version should be >=1.6:
!python3 -c "import kfp; print('KFP SDK version: {}'.format(kfp.__version__))"
!python3 -c "import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))"





