Overview
In this lab, you will identify Map and Reduce operations, execute the pipeline, use command line parameters.

Objective
Identify Map and Reduce operations
Execute the pipeline
Use command line parameters



Task 1. Lab Preparations
Specific steps must be completed to successfully execute this lab:

Open the SSH terminal and connect to the training VM
You will be running all code from a curated training VM.
In the Console, on the Navigation menu (Navigation menu icon), click Compute Engine > VM instances.
Locate the line with the instance called training-vm.
On the far right, under Connect, click on SSH to open a terminal window.
In this lab, you will enter CLI commands on the training-vm.

Clone the training github repository
In the training-vm SSH terminal enter the following command:
git clone https://github.com/GoogleCloudPlatform/training-data-analyst







Task 2. Identify Map and Reduce operations
Return to the training-vm SSH terminal and navigate to the directory /training-data-analyst/courses/data_analysis/lab2/python and view the file is_popular.py with Nano. Do not make any changes to the code. Press Ctrl+X to exit Nano.
cd ~/training-data-analyst/courses/data_analysis/lab2/python
nano is_popular.py



student-00-70fc419b46c0@training-vm:~$ git clone https://github.com/GoogleCloudPlatform/training-data-analyst
Cloning into 'training-data-analyst'...
remote: Enumerating objects: 59907, done.
remote: Counting objects: 100% (330/330), done.
remote: Compressing objects: 100% (175/175), done.
remote: Total 59907 (delta 174), reused 270 (delta 140), pack-reused 59577
Receiving objects: 100% (59907/59907), 680.30 MiB | 39.94 MiB/s, done.
Resolving deltas: 100% (38004/38004), done.

student-00-70fc419b46c0@training-vm:~$ cd ~/training-data-analyst/courses/data_analysis/lab2/python
student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ pwd
/home/student-00-70fc419b46c0/training-data-analyst/courses/data_analysis/lab2/python

student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ ls
grepc.py  grep.py  install_packages_OLD.sh  install_packages.sh  is_popular.py  JavaProjectsThatNeedHelp.py  JavaProjectsThatNeedHelp_PY2_Version.py  OLD_grepc.py


student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ nano is_popular.py 
#!/usr/bin/env python3

"""
Copyright Google Inc. 2016
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""

import apache_beam as beam
import argparse

def startsWith(line, term):
   if line.startswith(term):
      yield line

def splitPackageName(packageName):
   """e.g. given com.example.appname.library.widgetname
           returns com
                   com.example
                   com.example.appname
      etc.
   """
   result = []
   end = packageName.find('.')
   while end > 0:
      result.append(packageName[0:end])
      end = packageName.find('.', end+1)
   result.append(packageName)             #append the last packageName 'combo' found but yet to be appended
   return result

def getPackages(line, keyword):
   start = line.find(keyword) + len(keyword)            # index of the 'keyword' string found, otherwise -1 if not found
                                                        # adjusted to start after the keyword
   end = line.find(';', start)                          # find the next  semi-colon ';'
   if start < end:                                      # ';' found
      packageName = line[start:end].strip()             # extract string between the 'keyword' on the LHS and ';' on the RHS => not including those 2 items 
      return splitPackageName(packageName)              # call splitPackageName fn => return a list of package names found within that string
   return []                                            # if we cant find the next ';' => return an empty list 

def packageUse(line, keyword):
   packages = getPackages(line, keyword)
   for p in packages:                   
      yield (p, 1)                      # pkg name and count of 1 FOR EVERY PACKAGE

if __name__ == '__main__':
   parser = argparse.ArgumentParser(description='Find the most used Java packages')
   parser.add_argument('--output_prefix', default='/tmp/output', help='Output prefix')
   parser.add_argument('--input', default='../javahelp/src/main/java/com/google/cloud/training/dataanalyst/javahelp/', help='Input directory')

   options, pipeline_args = parser.parse_known_args()
   p = beam.Pipeline(argv=pipeline_args)

   input = '{0}*.java'.format(options.input)
   output_prefix = options.output_prefix
   keyword = 'import'

   # find most used packages
   (p
      | 'GetJava' >> beam.io.ReadFromText(input)                                    # read input file
      | 'GetImports' >> beam.FlatMap(lambda line: startsWith(line, keyword))        # keep lines starting with 'import'
      | 'PackageUse' >> beam.FlatMap(lambda line: packageUse(line, keyword))        # tuple of (pkg name and count of 1)
      | 'TotalUse' >> beam.CombinePerKey(sum)                                       # SUM across each pkg name
      | 'Top_5' >> beam.transforms.combiners.Top.Of(5, key=lambda kv: kv[1])
      | 'write' >> beam.io.WriteToText(output_prefix)                               # write to output file in the output dir
   )

   p.run().wait_until_finish()   
   
   


Can you answer these questions about the file is_popular.py?
What custom arguments are defined?                                # input, line, keyword, output_prefix
What is the default output prefix?                                # output dir '/tmp/output'
How is the variable output_prefix in main() set?                  # from the --output_prefix provided by the user; otherwise take the default output dir '/tmp/output'
How are the pipeline arguments such as --runner set?
What are the key steps in the pipeline?                           # see analysis in the code above
Which of these steps happen in parallel?                          # probably GetImports and PackageUse can happen in parallel, as GetImports finishes processing some lines, it can pass the outputs to PackageUse to process. Then GetImports can process the remaining lines in the queue in parallel.
Which of these steps are aggregations?                            # TotalUse



















Task 3. Execute the pipeline
In the training-vm SSH terminal, run the pipeline locally:
python3 ./is_popular.py



Identify the output file. It should be output<suffix> and could be a sharded file.        => output-00000-of-00001
ls -al /tmp

student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ python3 ./is_popular.py

student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ ls /tmp
hsperfdata_root  output-00000-of-00001  ssh-oo81we1HRt

student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ ls -al /tmp
total 40
drwxrwxrwt  9 root                    root           4096 Aug 29 00:23 .
drwxr-xr-x 23 root                    root           4096 Aug 28 21:11 ..
drwxrwxrwt  2 root                    root           4096 Aug 28 21:11 .font-unix
drwxr-xr-x  2 root                    root           4096 Aug 28 21:12 hsperfdata_root
drwxrwxrwt  2 root                    root           4096 Aug 28 21:11 .ICE-unix
-rw-r--r--  1 student-00-70fc419b46c0 google-sudoers  128 Aug 29 00:23 output-00000-of-00001
drwx------  2 student-00-70fc419b46c0 google-sudoers 4096 Aug 28 23:51 ssh-oo81we1HRt
drwxrwxrwt  2 root                    root           4096 Aug 28 21:11 .Test-unix
drwxrwxrwt  2 root                    root           4096 Aug 28 21:11 .X11-unix
drwxrwxrwt  2 root                    root           4096 Aug 28 21:11 .XIM-unix





Examine the output file, replacing '-*' with the appropriate suffix.
cat /tmp/output-*

student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ cat /tmp/output-*
[('org', 45), ('org.apache', 44), ('org.apache.beam', 44), ('org.apache.beam.sdk', 43), ('org.apache.beam.sdk.transforms', 16)]
























Task 4. Use command line parameters
In the training-vm SSH terminal, change the output prefix from the default value:
python3 ./is_popular.py --output_prefix=/tmp/myoutput


What will be the name of the new file that is written out?        => NO LONGER the same 'output-<someSuffix>'
                                                                  => new output file naming convention becomes 'myoutput-<someSuffix>'
Note that we now have a new file in the /tmp directory:
ls -lrt /tmp/myoutput*


student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ python3 ./is_popular.py --output_prefix=/tmp/myoutput
student-00-70fc419b46c0@training-vm:~/training-data-analyst/courses/data_analysis/lab2/python$ ls -lrt /tmp/myoutput*
-rw-r--r-- 1 student-00-70fc419b46c0 google-sudoers 128 Aug 29 00:27 /tmp/myoutput-00000-of-00001






