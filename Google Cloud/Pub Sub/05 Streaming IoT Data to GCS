https://googlecoursera.qwiklabs.com/focuses/11768437?parent=lti_session
In this lab, you configure Cloud IoT Core and Cloud Pub/Sub to create a Pub/Sub topic and registry on GCP. 
You use this topic to ingest data streaming from an Android Things board.

Create Cloud Pub/Sub topics and subscriptions
Use IoT Core to create a registry
Start the MQTT Application on a simulator
Stream data to Google Cloud Storage


project id  qwiklabs-gcp-01-15df2afcfbba
region      us-central1
zone        us-central1-a







Enable APIs
Cloud IoT API
Cloud Pub/Sub API
Container Registry API
Google Cloud Storage





Cloud Pub/Sub setup and topics
In this section you create a pub/sub topic for your streaming data.
On the Navigation menu, click Pub/Sub > Topics. If prompted, enable the API.
Click Create Topic.
For Topic ID, type iotlab, and then click Create Topic.

Setting topic permissions
You now have a pub/sub topic. To allow the project to publish this topic, add the project as a member/publisher.
To add members, check the topic name, and then click Show info panel.
Click Add member.
Add the project as a member to the topic.       cloud-iot@system.gserviceaccount.com      <project ID>@<project ID>.iam.gserviceaccount.com
Select the role of Pub/Sub > Pub/Sub Publisher, and then click Save to add the member.








Create a location for data storage
You need to create a storage folder to store the data streaming from the Android Things board. This is done in two steps.
Create a storage bucket.
Create a folder in the bucket.


Create a storage bucket
On the Navigation menu, click Storage > Browser.
Click Create bucket menu item.
Bucket names must be unique, use your project name for the bucket name or create a unique bucket name. Enter the <bucket-name> for the bucket, and then click Create.

Create a folder in your bucket
Return to the Storage Browser. Your new bucket should be in the list.
Click on the bucket you created.
Click Create folder.
For Name, type Sensor-Data, and then click Create.














Start a Dataflow job
You now have a device publishing data, and your Google Cloud Project is authorized to receive this data. 
Now you can start a Dataflow job to save the data to your bucket.

Create a Dataflow job from a template
On the Navigation menu, click Dataflow.
Click Create job from template.

Enter the following values in the template.
Property	                    Value (type or select)
Job name	                    sensor-data
Cloud Dataflow template	      Cloud Pub/Sub to Text Files on Cloud Storage

The template page will expand to display a series of textboxes. Some of the textboxes are optional and some are required. You will only modify the required textboxes.
Property	                        Value (type or select)
Regional endpoint	                Select the region closest to you
Input Cloud Pub/Sub topic	        projects/<project-name>/topics/iotlab                                           projects/qwiklabs-gcp-01-15df2afcfbba/topics/iotlab
Output Cloud.Storage directory	  gs://<bucket-name>/Sensor-Data/ (note the slash at the end of the input text)   gs://qwiklabs-gcp-01-15df2afcfbba/Sensor-Data/
Output file prefix	              output-
Temporary Location	              gs://<bucket-name>/tmp                                                          gs://qwiklabs-gcp-01-15df2afcfbba/tmp

Click Run job.


















Prepare Your Compute Engine VM
In your project, a pre-provisioned VM instance named iot-device-simulator will let you run instances of a Python script that emulate an MQTT-connected IoT device. 
Before you emulate the devices, you will also use this VM instance to populate your Cloud IoT Core device registry.

To connect to the iot-device-simulator VM instance:
In the GCP Console, go to Navigation menu > Compute Engine> VM Instances. You'll see your VM instance listed as iot-device-simulator.

To the right, click the SSH drop-down arrow and select Open in browser window.
You might need to click Hide Info Panel to reveal the SSH drop-down arrow.

In your SSH session on the iot-device-simulator VM instance, enter this command to remove the default Google Cloud Platform SDK installation. 
(In subsequent steps, you will install the latest version, including the beta component.)
sudo apt-get remove google-cloud-sdk -y

Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following packages will be REMOVED:
  google-cloud-sdk
0 upgraded, 0 newly installed, 1 to remove and 4 not upgraded.
After this operation, 400 MB disk space will be freed.
(Reading database ... 71419 files and directories currently installed.)
Removing google-cloud-sdk (309.0.0-0) ...
Processing triggers for man-db (2.7.6.1-2) ...




Now install the latest version of the Google Cloud Platform SDK and accept all defaults:
curl https://sdk.cloud.google.com | bash

Welcome to the Google Cloud SDK!

To help improve the quality of this product, we collect anonymized usage data
and anonymized stacktraces when crashes are encountered; additional information
is available at <https://cloud.google.com/sdk/usage-statistics>. This data is
handled in accordance with our privacy policy
<https://policies.google.com/privacy>. You may choose to opt in this
collection now (by choosing 'Y' at the below prompt), or at any time in the
future by running the following command:

    gcloud config set disable_usage_reporting false

Do you want to help improve the Google Cloud SDK (y/N)?  n         


This will install all the core command line tools necessary for working with
the Google Cloud Platform.



Your current Cloud SDK version is: 314.0.0
Installing components from version: 314.0.0

┌─────────────────────────────────────────────────────────────────────────────┐
│                     These components will be installed.                     │
├─────────────────────────────────────────────────────┬────────────┬──────────┤
│                         Name                        │  Version   │   Size   │
├─────────────────────────────────────────────────────┼────────────┼──────────┤
│ BigQuery Command Line Tool                          │     2.0.62 │  < 1 MiB │
│ BigQuery Command Line Tool (Platform Specific)      │     2.0.58 │  < 1 MiB │
│ Cloud SDK Core Libraries (Platform Specific)        │ 2020.07.10 │  < 1 MiB │
│ Cloud Storage Command Line Tool                     │       4.53 │  3.5 MiB │
│ Cloud Storage Command Line Tool (Platform Specific) │       4.51 │  < 1 MiB │
│ Default set of gcloud commands                      │            │          │
│ Kuberun                                             │      0.0.1 │ 22.3 MiB │
│ Kuberun                                             │      0.0.1 │          │
│ anthoscli                                           │      0.2.7 │          │
│ anthoscli                                           │      0.2.7 │ 51.7 MiB │
│ gcloud cli dependencies                             │ 2020.06.12 │  < 1 MiB │
└─────────────────────────────────────────────────────┴────────────┴──────────┘

For the latest full release notes, please visit:
  https://cloud.google.com/sdk/release_notes

╔════════════════════════════════════════════════════════════╗
╠═ Creating update staging area                             ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: BigQuery Command Line Tool                   ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: BigQuery Command Line Tool (Platform Spec... ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: Cloud SDK Core Libraries (Platform Specific) ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: Cloud Storage Command Line Tool              ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: Cloud Storage Command Line Tool (Platform... ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: Default set of gcloud commands               ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: Kuberun                                      ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: Kuberun                                      ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: anthoscli                                    ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: anthoscli                                    ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Installing: gcloud cli dependencies                      ═╣
╠════════════════════════════════════════════════════════════╣
╠═ Creating backup and activating new installation          ═╣
╚════════════════════════════════════════════════════════════╝

Performing post processing steps...done.                                                                                                                                                                                        

Update done!








End your ssh session on the iot-device-simulator VM instance:
exit

Start another SSH session on the iot-device-simulator VM instance.

Initialize the gcloud SDK.
gcloud init

Click on the URL shown to open a new browser window that displays a verification code.

Use your browser to copy the verification code.
4/5AHV6uCqtO-tMqLeakFHH_2ChPqhHbMl1TXkgmCtYjOpF6u_A5Wd7Ok

Paste the verification code in response to the "Enter verification code:" prompt and press Enter.

In response to "Pick cloud project to use", pick the GCP project that Qwiklabs created for you.

Enter this command to make sure that the components of the SDK are up to date.
gcloud components update

Enter the following command to install the beta components. Accept if prompted to continue.
gcloud components install beta

Enter this command to update the system's information about Debian Linux package repositories:
sudo apt-get update

Hit:1 http://security.debian.org stretch/updates InRelease
Ign:2 http://deb.debian.org/debian stretch InRelease
Hit:3 http://deb.debian.org/debian stretch-updates InRelease             
Hit:4 http://deb.debian.org/debian stretch-backports InRelease           
Hit:5 http://deb.debian.org/debian stretch Release                       
Hit:6 http://packages.cloud.google.com/apt cloud-sdk-stretch InRelease   
Hit:7 http://packages.cloud.google.com/apt google-compute-engine-stretch-stable InRelease
Hit:8 http://packages.cloud.google.com/apt google-cloud-packages-archive-keyring-stretch InRelease
Reading package lists... Done  



Enter this command to make sure that various required software packages are installed:
sudo apt-get install python-pip openssl git -y

Reading package lists... Done
Building dependency tree       
Reading state information... Done
git is already the newest version (1:2.11.0-3+deb9u7).
openssl is already the newest version (1.1.0l-1~deb9u1).
python-pip is already the newest version (9.0.1-2+deb9u2).
0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.



Use pip to add needed Python components:
sudo pip install pyjwt paho-mqtt cryptography

Collecting pyjwt
  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl
Collecting paho-mqtt
  Downloading https://files.pythonhosted.org/packages/32/d3/6dcb8fd14746fcde6a556f932b5de8bea8fedcb85b3a092e0e986372c0e7/paho-mqtt-1.5.1.tar.gz (101kB)
    100% |████████████████████████████████| 102kB 3.6MB/s 
Requirement already satisfied: cryptography in /usr/lib/python2.7/dist-packages
Building wheels for collected packages: paho-mqtt
  Running setup.py bdist_wheel for paho-mqtt ... done
  Stored in directory: /root/.cache/pip/wheels/75/e2/f5/78942b19b4d135605e58dfe85fba52253b14d636aabf76904b
Successfully built paho-mqtt
Installing collected packages: pyjwt, paho-mqtt
Successfully installed paho-mqtt-1.5.1 pyjwt-1.7.1



Enter this command to add data to analyze during this lab:
git clone http://github.com/GoogleCloudPlatform/training-data-analyst

Cloning into 'training-data-analyst'...
warning: redirecting to https://github.com/GoogleCloudPlatform/training-data-analyst/
remote: Enumerating objects: 42136, done.
remote: Total 42136 (delta 0), reused 0 (delta 0), pack-reused 42136
Receiving objects: 100% (42136/42136), 464.71 MiB | 43.41 MiB/s, done.
Resolving deltas: 100% (26355/26355), done.



In your SSH session on the iot-device-simulator VM instance, run the following, adding your project ID as the value for PROJECT_ID:
export PROJECT_ID=qwiklabs-gcp-01-15df2afcfbba

Your completed command will look like this: export PROJECT_ID=qwiklabs-gcp-d2e509fed105b3ed

You must choose a region for your IoT registry. At the present time, these regions are supported:
us-central1
europe-west1
Asia-east1
Choose the region that is closest to you. To set an environment variable containing your preferred region, enter the command:
export MY_REGION=
followed by the region name. Your completed command will look like this:
export MY_REGION=us-central1
















Open Core IoT
On the Navigation menu, click IoT Core menu. Enable it if prompted.
Click Create registry.

On the Create a registry page, specify the following, and leave the remaining settings as their defaults:
Property	                    Value (type or select)
Registry ID	                  iotlab-registry
Region	                      us-central1 (or select a region that is closest to you)
Select a Cloud Pub/Sub topic	projects/<project-name>/topics/iotlab             projects/qwiklabs-gcp-01-15df2afcfbba/topics/iotlab
Click Create.




Create a Cryptographic Keypair
To allow IoT devices to connect securely to Cloud IoT Core, you must create a cryptographic keypair.
In your SSH session on the iot-device-simulator VM instance, enter these commands to create the keypair in the appropriate directory:
cd $HOME/training-data-analyst/quests/iotlab/
openssl req -x509 -newkey rsa:2048 -keyout rsa_private.pem \
    -nodes -out rsa_cert.pem -subj "/CN=unused"

This openssl command creates an RSA cryptographic keypair and writes it to a file called rsa_private.pem.




Create the device and add it to the registry
In your SSH session on the iot-device-simulator VM instance, type
cat rsa_cert.pem
-----BEGIN CERTIFICATE-----
<rsacert>
-----END CERTIFICATE-----



Click on Devices in the left side panel under IoT Core menu.
Click Create a Device.
Property	          Value (type or select)
Device ID	          temp-sensor-buenos-aires
Authentication	    Enter manually
Public key format	  RS256_X509
Public key value	  Paste the certificate that you copied
Click Create.

Go back to the Devices page to create an another Device.
Click Create a Device.
Property	          Value (type or select)
Device ID	          temp-sensor-istanbul
Authentication	    Enter manually
Public key format	  RS256_X509
Public key value	  Paste the certificate that you copied
Click Create.

























Run Simulated Devices
In your SSH session on the iot-device-simulator VM instance, enter these commands to download the CA root certificates from pki.google.com to the appropriate directory:
cd $HOME/training-data-analyst/quests/iotlab/
wget https://pki.google.com/roots.pem

Enter this command to run the first simulated device:
python cloudiot_mqtt_example_json.py \
   --project_id=$PROJECT_ID \
   --cloud_region=$MY_REGION \
   --registry_id=iotlab-registry \
   --device_id=temp-sensor-buenos-aires \
   --private_key_file=rsa_private.pem \
   --message_type=event \
   --algorithm=RS256 --num_messages=200 > buenos-aires-log.txt 2>&1 &

It will continue to run in the background.



Enter this command to run the second simulated device:
python cloudiot_mqtt_example_json.py \
   --project_id=$PROJECT_ID \
   --cloud_region=$MY_REGION \
   --registry_id=iotlab-registry \
   --device_id=temp-sensor-istanbul \
   --private_key_file=rsa_private.pem \
   --message_type=event \
   --algorithm=RS256 \
   --num_messages=200

Telemetry data will flow from the simulated devices through Cloud IoT Core to your Cloud Pub/Sub topic. In turn, your Dataflow job will read messages from your Pub/Sub topic and write their contents to your GCS bucket.




Examine the stored data
Dataflow is collecting the data published by Pub/Sub and saving it in output files in the bucket and folder specified in the job template. The files are written every 5 minutes, and each begins with the prefix specified in the job template.
On the Navigation menu, click Storage.
Select the bucket used for this project: <bucket-name>
Select the folder Sensor-Data. Dataflow is writing the data from the device to this folder.
It writes a file every five minutes. If the folder is empty, wait about 5-10 minutes then check.

Open a file by clicking on its name.
Your file contents should be similar to what is shown below.
Output
Creating JWT using RS256 from private key file rsa_private.pem
Publishing message 1 of 200: '{'device': 'temp-sensor-istanbul', 'timestamp': 1602658015, 'temperature': 22.686660588654313}'
('on_connect', '0: No error.')
on_publish
Publishing message 2 of 200: '{'device': 'temp-sensor-istanbul', 'timestamp': 1602658016, 'temperature': 22.693921405973192}'
on_publish
...
Publishing message 199 of 200: '{'device': 'temp-sensor-istanbul', 'timestamp': 1602658213, 'temperature': 24.72849547413262}'
on_publish
Publishing message 200 of 200: '{'device': 'temp-sensor-istanbul', 'timestamp': 1602658214, 'temperature': 24.737661127767293}'
on_publish
Finished.
[1]+  Done                    python cloudiot_mqtt_example_json.py --project_id=$PROJECT_ID --cloud_region=$MY_REGION --registry_id=iotlab-registry --device_id=temp-sensor-buenos-aires --private_key_file=rsa_private.pem --message_type=event --algorithm=RS256 --num_messages=200 > buenos-aires-log.txt 2>&1



Stop the Dataflow job
In this section, you stop collecting data through Dataflow by stopping the job.
On the Navigation menu, click Dataflow and select the dataflow you created earlier.
Click the Stop button on the Job page.
In the dialog box, select Drain, then Stop Job.
It will take a few minutes for the job to stop.
Using the back arrow, return to the Dataflow page. Make sure the job status of the sensor-data job is Drained.

