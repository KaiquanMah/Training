Craft a prompt 
Send the prompt to the model 
Observe and analyze the output 
Identify potential issues with the prompt 
Refine the prompt



============


Iterative prompt engineering for standard prompts
You are a developer using prompt engineering techniques for your various tasks, and you want to carefully select the right language model. You wrote an initial prompt to know what are the top ten pre-trained language models out there. Now, your goal is to refine this prompt to generate a table presenting information on each model's name, release year and its owning company.
The OpenAI package and the get_response() function have been pre-loaded for you.


Iteratively refine the prompt to get the desired outcome: a table with three columns for the top ten pre-trained language models, listing the model name, release year, and owning company.



client = OpenAI(api_key="<OPENAI_API_TOKEN>")

# Refine the following prompt
prompt = "Give me the top 10 pre-trained language models in a table i can copy to excel with 3 columns: model name, release year, owning company"

response = get_response(prompt)
print(response)


    As of my last update in October 2023, here are ten of the most prominent pre-trained language models that have made significant impacts in the field of natural language processing (NLP):
    
    1. **GPT-3 (Generative Pre-trained Transformer 3)** - Developed by OpenAI, GPT-3 is known for its impressive ability to generate human-like text and perform a variety of language tasks.
    
    2. **BERT (Bidirectional Encoder Representations from Transformers)** - Created by Google, BERT revolutionized NLP by introducing bidirectional training of transformers, allowing the model to understand context better.
    
    3. **RoBERTa (A Robustly Optimized BERT Pretraining Approach)** - An improvement over BERT, RoBERTa was developed by Facebook AI and focuses on training with more data and longer sequences.
    
    4. **T5 (Text-to-Text Transfer Transformer)** - Developed by Google, T5 treats every NLP task as a text-to-text problem, allowing for a unified approach to various tasks.
    
    5. **XLNet** - A generalized autoregressive pretraining model that outperforms BERT on several benchmarks by capturing bidirectional context without masking.
    
    6. **ALBERT (A Lite BERT)** - A more efficient version of BERT, ALBERT reduces the model size while maintaining performance through parameter sharing and factorized embedding parameterization.
    
    7. **DistilBERT** - A smaller, faster, and lighter version of BERT, DistilBERT retains 97% of BERT's language understanding while being 60% faster.
    
    8. **ERNIE (Enhanced Representation through kNowledge Integration)** - Developed by Baidu, ERNIE incorporates knowledge graphs into the pre-training process to improve understanding.
    
    9. **BART (Bidirectional and Auto-Regressive Transformers)** - A model from Facebook AI that combines the strengths of BERT and GPT, BART is particularly effective for text generation and summarization tasks.
    
    10. **ChatGPT (based on GPT-4)** - The latest iteration of OpenAI's conversational AI, ChatGPT is designed for dialogue and interactive applications, building on the capabilities of its predecessors.
    
    These models have been widely adopted in various applications, including chatbots, translation, summarization, and more. The landscape of NLP is rapidly evolving, so new models and improvements may emerge beyond my last update.

<script.py> output:
    Hereâ€™s a table of the top 10 pre-trained language models that you can easily copy to Excel:
    
    | Model Name                | Release Year | Owning Company       |
    |---------------------------|--------------|----------------------|
    | BERT                      | 2018         | Google               |
    | GPT-2                     | 2019         | OpenAI               |
    | RoBERTa                   | 2019         | Facebook AI Research  |
    | T5                        | 2019         | Google               |
    | GPT-3                     | 2020         | OpenAI               |
    | BART                      | 2020         | Facebook AI Research  |
    | ELECTRA                   | 2020         | Google               |
    | DeBERTa                   | 2021         | Microsoft            |
    | GPT-3.5                   | 2022         | OpenAI               |
    | LLaMA                     | 2023         | Meta                 |
    
    Feel free to copy this table directly into Excel!
