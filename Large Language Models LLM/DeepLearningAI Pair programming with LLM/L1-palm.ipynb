{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e80b742-0c2e-46d2-99e5-61f2982571e4",
   "metadata": {},
   "source": [
    "# Lesson 1: Getting Started with PaLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b4dd3-3436-43f8-811c-262ed83d7767",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "Set the ~~MakerSuite~~ Gemini API key with the provided helper function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7b619",
   "metadata": {},
   "source": [
    "> Note: this course was launched in 2023, up to date (June 2025) [PaLM is being deprecated](https://ai.google.dev/palm_docs/deprecation). Therefore, we're migrating the content of this notebook [from PaLM to Gemini](https://ai.google.dev/docs/migration_guide) to be functional from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db7275e-7ba3-482c-90a5-8d470dcca05c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from utils import get_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be2f53-efa5-495f-808e-1e3189f0b73d",
   "metadata": {},
   "source": [
    "In this classroom, we've installed the relevant libraries for you.\n",
    "\n",
    "If you wanted to use the ~~PaLM API~~ Gemini API on your own machine, you would first install the library:\n",
    "```Python\n",
    "!pip install -q google.generativeai\n",
    "```\n",
    "The optional flag `-q` installs \"quietly\" without printing out details of the installation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71786bc2",
   "metadata": {},
   "source": [
    "> Note: if you want to run it locally, you can get the Gemini API from this [website](https://aistudio.google.com/app/apikey) by only using your gmail account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffb615",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Legacy PALM API code shown in the video\n",
    "import google.generativeai as palm\n",
    "palm.configure(api_key=get_api_key())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a9a4b3-b338-4ed8-ac7b-a08143da5b63",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "# From now own with Gemini API\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.api_core import client_options as client_options_lib\n",
    "\n",
    "genai.configure(\n",
    "    api_key=get_api_key(),\n",
    "    transport=\"rest\",\n",
    "    client_options=client_options_lib.ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648b897-5ad4-4caa-808d-97528c2fcf39",
   "metadata": {},
   "source": [
    "### Explore the available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77038a39-427c-4d1f-bc7e-e0692e8f6869",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: models/embedding-gecko-001\n",
      "description: Obtain a distributed representation of a text.\n",
      "generation methods:['embedText', 'countTextTokens']\n",
      "\n",
      "name: models/gemini-1.5-pro-latest\n",
      "description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-1.5-pro-002\n",
      "description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "name: models/gemini-1.5-pro\n",
      "description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-1.5-flash-latest\n",
      "description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-1.5-flash\n",
      "description: Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-1.5-flash-002\n",
      "description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "name: models/gemini-1.5-flash-8b\n",
      "description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "generation methods:['createCachedContent', 'generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-1.5-flash-8b-001\n",
      "description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "generation methods:['createCachedContent', 'generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-1.5-flash-8b-latest\n",
      "description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "generation methods:['createCachedContent', 'generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-2.5-pro-preview-03-25\n",
      "description: Gemini 2.5 Pro Preview 03-25\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-flash-preview-05-20\n",
      "description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-flash\n",
      "description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-flash-lite-preview-06-17\n",
      "description: Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-pro-preview-05-06\n",
      "description: Preview release (May 6th, 2025) of Gemini 2.5 Pro\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-pro-preview-06-05\n",
      "description: Preview release (June 5th, 2025) of Gemini 2.5 Pro\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-pro\n",
      "description: Stable release (June 17th, 2025) of Gemini 2.5 Pro\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-exp\n",
      "description: Gemini 2.0 Flash Experimental\n",
      "generation methods:['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash\n",
      "description: Gemini 2.0 Flash\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-001\n",
      "description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-exp-image-generation\n",
      "description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "generation methods:['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-lite-001\n",
      "description: Stable version of Gemini 2.0 Flash-Lite\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-lite\n",
      "description: Gemini 2.0 Flash-Lite\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-preview-image-generation\n",
      "description: Gemini 2.0 Flash Preview Image Generation\n",
      "generation methods:['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-lite-preview-02-05\n",
      "description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-lite-preview\n",
      "description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-pro-exp\n",
      "description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-pro-exp-02-05\n",
      "description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-exp-1206\n",
      "description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-thinking-exp-01-21\n",
      "description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-thinking-exp\n",
      "description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-thinking-exp-1219\n",
      "description: Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-flash-preview-tts\n",
      "description: Gemini 2.5 Flash Preview TTS\n",
      "generation methods:['countTokens', 'generateContent']\n",
      "\n",
      "name: models/gemini-2.5-pro-preview-tts\n",
      "description: Gemini 2.5 Pro Preview TTS\n",
      "generation methods:['countTokens', 'generateContent']\n",
      "\n",
      "name: models/learnlm-2.0-flash-experimental\n",
      "description: LearnLM 2.0 Flash Experimental\n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemma-3-1b-it\n",
      "description: \n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemma-3-4b-it\n",
      "description: \n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemma-3-12b-it\n",
      "description: \n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemma-3-27b-it\n",
      "description: \n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemma-3n-e4b-it\n",
      "description: \n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemma-3n-e2b-it\n",
      "description: \n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-2.5-flash-lite\n",
      "description: Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\n",
      "generation methods:['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-flash-image-preview\n",
      "description: Gemini 2.5 Flash Preview Image\n",
      "generation methods:['generateContent', 'countTokens']\n",
      "\n",
      "name: models/embedding-001\n",
      "description: Obtain a distributed representation of a text.\n",
      "generation methods:['embedContent']\n",
      "\n",
      "name: models/text-embedding-004\n",
      "description: Obtain a distributed representation of a text.\n",
      "generation methods:['embedContent']\n",
      "\n",
      "name: models/gemini-embedding-exp-03-07\n",
      "description: Obtain a distributed representation of a text.\n",
      "generation methods:['embedContent', 'countTextTokens', 'countTokens']\n",
      "\n",
      "name: models/gemini-embedding-exp\n",
      "description: Obtain a distributed representation of a text.\n",
      "generation methods:['embedContent', 'countTextTokens', 'countTokens']\n",
      "\n",
      "name: models/gemini-embedding-001\n",
      "description: Obtain a distributed representation of a text.\n",
      "generation methods:['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "\n",
      "name: models/aqa\n",
      "description: Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "generation methods:['generateAnswer']\n",
      "\n",
      "name: models/imagen-3.0-generate-002\n",
      "description: Vertex served Imagen 3.0 002 model\n",
      "generation methods:['predict']\n",
      "\n",
      "name: models/imagen-4.0-generate-preview-06-06\n",
      "description: Vertex served Imagen 4.0 model\n",
      "generation methods:['predict']\n",
      "\n",
      "name: models/imagen-4.0-ultra-generate-preview-06-06\n",
      "description: Vertex served Imagen 4.0 ultra model\n",
      "generation methods:['predict']\n",
      "\n",
      "name: models/imagen-4.0-generate-001\n",
      "description: Vertex served Imagen 4.0 model\n",
      "generation methods:['predict']\n",
      "\n",
      "name: models/imagen-4.0-ultra-generate-001\n",
      "description: Vertex served Imagen 4.0 ultra model\n",
      "generation methods:['predict']\n",
      "\n",
      "name: models/imagen-4.0-fast-generate-001\n",
      "description: Vertex served Imagen 4.0 Fast model\n",
      "generation methods:['predict']\n",
      "\n",
      "name: models/veo-2.0-generate-001\n",
      "description: Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.\n",
      "generation methods:['predictLongRunning']\n",
      "\n",
      "name: models/veo-3.0-generate-preview\n",
      "description: Veo 3 preview.\n",
      "generation methods:['predictLongRunning']\n",
      "\n",
      "name: models/veo-3.0-fast-generate-preview\n",
      "description: Veo 3 fast preview.\n",
      "generation methods:['predictLongRunning']\n",
      "\n",
      "name: models/veo-3.0-generate-001\n",
      "description: Veo 3 preview.\n",
      "generation methods:['predictLongRunning']\n",
      "\n",
      "name: models/veo-3.0-fast-generate-001\n",
      "description: Veo 3 fast preview.\n",
      "generation methods:['predictLongRunning']\n",
      "\n",
      "name: models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "description: Gemini 2.5 Flash Preview Native Audio Dialog\n",
      "generation methods:['countTokens', 'bidiGenerateContent']\n",
      "\n",
      "name: models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "description: Gemini 2.5 Flash Exp Native Audio Thinking Dialog\n",
      "generation methods:['countTokens', 'bidiGenerateContent']\n",
      "\n",
      "name: models/gemini-2.0-flash-live-001\n",
      "description: Gemini 2.0 Flash 001\n",
      "generation methods:['bidiGenerateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-live-2.5-flash-preview\n",
      "description: Gemini Live 2.5 Flash Preview\n",
      "generation methods:['bidiGenerateContent', 'countTokens']\n",
      "\n",
      "name: models/gemini-2.5-flash-live-preview\n",
      "description: Gemini 2.5 Flash Live Preview\n",
      "generation methods:['bidiGenerateContent', 'countTokens']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PaLM API legacy:\n",
    "# for m in palm.list_models():\n",
    "\n",
    "# Now, Gemini API, and you can see the different versions of this model\n",
    "for m in genai.list_models():\n",
    "    print(f\"name: {m.name}\")\n",
    "    print(f\"description: {m.description}\")\n",
    "    print(f\"generation methods:{m.supported_generation_methods}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3f595c7",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [m for m in genai.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcc7d8b",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [m for m in genai.list_models() if 'generateMessage' in m.supported_generation_methods]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc66f9bf",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/gemini-1.5-pro-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Pro Latest',\n",
       "       description=('Alias that points to the most recent production (non-experimental) release '\n",
       "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
       "                    'million tokens.'),\n",
       "       input_token_limit=2000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-pro-002',\n",
       "       base_model_id='',\n",
       "       version='002',\n",
       "       display_name='Gemini 1.5 Pro 002',\n",
       "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
       "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
       "       input_token_limit=2000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-pro',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Pro',\n",
       "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
       "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
       "       input_token_limit=2000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-flash-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash Latest',\n",
       "       description=('Alias that points to the most recent production (non-experimental) release '\n",
       "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
       "                    'across diverse tasks.'),\n",
       "       input_token_limit=1000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-flash',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash',\n",
       "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
       "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
       "       input_token_limit=1000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-flash-002',\n",
       "       base_model_id='',\n",
       "       version='002',\n",
       "       display_name='Gemini 1.5 Flash 002',\n",
       "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
       "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
       "       input_token_limit=1000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-flash-8b',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash-8B',\n",
       "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
       "                    'Flash model, released in October of 2024.'),\n",
       "       input_token_limit=1000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-flash-8b-001',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash-8B 001',\n",
       "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
       "                    'Flash model, released in October of 2024.'),\n",
       "       input_token_limit=1000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-1.5-flash-8b-latest',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 1.5 Flash-8B Latest',\n",
       "       description=('Alias that points to the most recent production (non-experimental) release '\n",
       "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
       "                    'released in October of 2024.'),\n",
       "       input_token_limit=1000000,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.5-pro-preview-03-25',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-03-25',\n",
       "       display_name='Gemini 2.5 Pro Preview 03-25',\n",
       "       description='Gemini 2.5 Pro Preview 03-25',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-preview-05-20',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-05-20',\n",
       "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
       "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 2.5 Flash',\n",
       "       description=('Stable version of Gemini 2.5 Flash, our mid-size multimodal model that '\n",
       "                    'supports up to 1 million tokens, released in June of 2025.'),\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-lite-preview-06-17',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-06-17',\n",
       "       display_name='Gemini 2.5 Flash-Lite Preview 06-17',\n",
       "       description='Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-pro-preview-05-06',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-05-06',\n",
       "       display_name='Gemini 2.5 Pro Preview 05-06',\n",
       "       description='Preview release (May 6th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-pro-preview-06-05',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-06-05',\n",
       "       display_name='Gemini 2.5 Pro Preview',\n",
       "       description='Preview release (June 5th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-pro',\n",
       "       base_model_id='',\n",
       "       version='2.5',\n",
       "       display_name='Gemini 2.5 Pro',\n",
       "       description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-flash-exp',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash Experimental',\n",
       "       description='Gemini 2.0 Flash Experimental',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash',\n",
       "       description='Gemini 2.0 Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-001',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash 001',\n",
       "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
       "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
       "       description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite-001',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash-Lite 001',\n",
       "       description='Stable version of Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash-Lite',\n",
       "       description='Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-preview-image-generation',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Gemini 2.0 Flash Preview Image Generation',\n",
       "       description='Gemini 2.0 Flash Preview Image Generation',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens', 'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
       "       base_model_id='',\n",
       "       version='preview-02-05',\n",
       "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
       "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-flash-lite-preview',\n",
       "       base_model_id='',\n",
       "       version='preview-02-05',\n",
       "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
       "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=40),\n",
       " Model(name='models/gemini-2.0-pro-exp',\n",
       "       base_model_id='',\n",
       "       version='2.5-exp-03-25',\n",
       "       display_name='Gemini 2.0 Pro Experimental',\n",
       "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
       "       base_model_id='',\n",
       "       version='2.5-exp-03-25',\n",
       "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
       "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-exp-1206',\n",
       "       base_model_id='',\n",
       "       version='2.5-exp-03-25',\n",
       "       display_name='Gemini Experimental 1206',\n",
       "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-05-20',\n",
       "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
       "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-05-20',\n",
       "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
       "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
       "       base_model_id='',\n",
       "       version='2.5-preview-05-20',\n",
       "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
       "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts',\n",
       "       base_model_id='',\n",
       "       version='gemini-2.5-flash-exp-tts-2025-05-19',\n",
       "       display_name='Gemini 2.5 Flash Preview TTS',\n",
       "       description='Gemini 2.5 Flash Preview TTS',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=16384,\n",
       "       supported_generation_methods=['countTokens', 'generateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts',\n",
       "       base_model_id='',\n",
       "       version='gemini-2.5-pro-preview-tts-2025-05-19',\n",
       "       display_name='Gemini 2.5 Pro Preview TTS',\n",
       "       description='Gemini 2.5 Pro Preview TTS',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=16384,\n",
       "       supported_generation_methods=['countTokens', 'generateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/learnlm-2.0-flash-experimental',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='LearnLM 2.0 Flash Experimental',\n",
       "       description='LearnLM 2.0 Flash Experimental',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=32768,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-1b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 1B',\n",
       "       description='',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-4b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 4B',\n",
       "       description='',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-12b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 12B',\n",
       "       description='',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3-27b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3 27B',\n",
       "       description='',\n",
       "       input_token_limit=131072,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3n-e4b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3n E4B',\n",
       "       description='',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemma-3n-e2b-it',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemma 3n E2B',\n",
       "       description='',\n",
       "       input_token_limit=8192,\n",
       "       output_token_limit=2048,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-lite',\n",
       "       base_model_id='',\n",
       "       version='001',\n",
       "       display_name='Gemini 2.5 Flash-Lite',\n",
       "       description='Stable version of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
       "       input_token_limit=1048576,\n",
       "       output_token_limit=65536,\n",
       "       supported_generation_methods=['generateContent',\n",
       "                                     'countTokens',\n",
       "                                     'createCachedContent',\n",
       "                                     'batchGenerateContent'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64),\n",
       " Model(name='models/gemini-2.5-flash-image-preview',\n",
       "       base_model_id='',\n",
       "       version='2.0',\n",
       "       display_name='Nano Banana',\n",
       "       description='Gemini 2.5 Flash Preview Image',\n",
       "       input_token_limit=32768,\n",
       "       output_token_limit=8192,\n",
       "       supported_generation_methods=['generateContent', 'countTokens'],\n",
       "       temperature=1.0,\n",
       "       top_p=0.95,\n",
       "       top_k=64)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [m for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8540099-fad0-4954-83a7-c2fba3f6d972",
   "metadata": {},
   "source": [
    "#### Filter models by their supported generation methods\n",
    "- `generateText` is currently recommended for coding-related prompts.\n",
    "- `generateMessage` is optimized for multi-turn chats (dialogues) with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e8e83",
   "metadata": {},
   "source": [
    "> Update (October 2024):\n",
    "- `generateContent`, best model for scaling across a wide range of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb02ae",
   "metadata": {},
   "source": [
    "```Python\n",
    "# Legacy PALM API code shown in the video\n",
    "models = [m for m in genai.list_models() \n",
    "          if 'generateText' \n",
    "          in m.supported_generation_methods]\n",
    "# Today 2025, this code is now deprecated\n",
    "models\n",
    "\n",
    "# Model Bison set as legacy model in 2024\n",
    "model_bison = models[0]\n",
    "model_bison\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a24bff-ebe0-4fd3-93f6-c2aeef4d44f7",
   "metadata": {},
   "source": [
    "#### helper function to generate text\n",
    "\n",
    "- The `@retry` decorator helps you to retry the API call if it fails.\n",
    "- We set the temperature to 0.0 so that the model returns the same output (completion) if given the same input (the prompt).\n",
    "\n",
    "```Python\n",
    "# Code legacy for PALM API\n",
    "from google.api_core import retry\n",
    "@retry.Retry()\n",
    "def generate_text(prompt,\n",
    "                  model=model_bison,\n",
    "                  temperature=0.0):\n",
    "    return palm.generate_text(prompt=prompt,\n",
    "                              model=model,\n",
    "                              temperature=temperature)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2fd6e9",
   "metadata": {
    "height": 71
   },
   "outputs": [],
   "source": [
    "# Set the model to connect to the Gemini API\n",
    "model_flash = genai.GenerativeModel(model_name='gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a73e1ce1",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Helper with Gemini API\n",
    "def generate_text(prompt,\n",
    "                  model=model_flash,\n",
    "                  temperature=0.0):\n",
    "    return model_flash.generate_content(prompt,\n",
    "                                  generation_config={'temperature':temperature})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa756beb-7e70-4575-a27e-82b733b3d3b0",
   "metadata": {},
   "source": [
    "#### Ask the LLM how to write some code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04080420-acd1-43a8-92bc-7d4c407a0154",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt = \"Show me how to iterate across a list in Python.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32a354db-cb9b-4353-b777-4980256f4686",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Gemini API updates to generate the text\n",
    "completion = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef2b1688-2eb7-465c-81cd-555d5b0a5a70",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here are several ways to iterate across a list in Python, along with explanations and examples:\n",
      "\n",
      "**1.  The Basic `for` Loop (Iterating Directly Over Elements)**\n",
      "\n",
      "   This is the most common and straightforward way to iterate through a list.  It directly accesses each element in the list one by one.\n",
      "\n",
      "   ```python\n",
      "   my_list = [\"apple\", \"banana\", \"cherry\"]\n",
      "\n",
      "   for item in my_list:\n",
      "       print(item)  # Process each item\n",
      "   ```\n",
      "\n",
      "   **Explanation:**\n",
      "\n",
      "   *   `for item in my_list:`:  This loop assigns each element of `my_list` to the variable `item` in each iteration.\n",
      "   *   `print(item)`:  Inside the loop, you can perform any operation you want with the current `item`.\n",
      "\n",
      "**2.  Iterating with Index using `range()` and `len()`**\n",
      "\n",
      "   This method gives you access to both the element and its index within the list.\n",
      "\n",
      "   ```python\n",
      "   my_list = [\"apple\", \"banana\", \"cherry\"]\n",
      "\n",
      "   for i in range(len(my_list)):\n",
      "       print(f\"Index: {i}, Value: {my_list[i]}\")\n",
      "   ```\n",
      "\n",
      "   **Explanation:**\n",
      "\n",
      "   *   `len(my_list)`:  Returns the number of elements in the list.\n",
      "   *   `range(len(my_list))`:  Generates a sequence of numbers from 0 up to (but not including) the length of the list.  So, if `my_list` has 3 elements, `range(len(my_list))` will produce `0, 1, 2`.\n",
      "   *   `i`:  In each iteration, `i` will be assigned one of these index values.\n",
      "   *   `my_list[i]`:  Accesses the element at index `i` in the list.\n",
      "\n",
      "**3.  Using `enumerate()` (Best for Index and Value)**\n",
      "\n",
      "   `enumerate()` is a built-in function that provides both the index and the value of each element in the list simultaneously.  This is often the most Pythonic and readable way to iterate when you need both.\n",
      "\n",
      "   ```python\n",
      "   my_list = [\"apple\", \"banana\", \"cherry\"]\n",
      "\n",
      "   for index, value in enumerate(my_list):\n",
      "       print(f\"Index: {index}, Value: {value}\")\n",
      "   ```\n",
      "\n",
      "   **Explanation:**\n",
      "\n",
      "   *   `enumerate(my_list)`:  Returns an iterator that yields pairs of (index, value) for each element in the list.\n",
      "   *   `for index, value in ...`:  Unpacks each pair into the `index` and `value` variables.\n",
      "\n",
      "**4.  Using a `while` Loop (Less Common for Simple List Iteration)**\n",
      "\n",
      "   While less common for simple list iteration, you *can* use a `while` loop.  It requires more manual management of the index.\n",
      "\n",
      "   ```python\n",
      "   my_list = [\"apple\", \"banana\", \"cherry\"]\n",
      "   index = 0\n",
      "\n",
      "   while index < len(my_list):\n",
      "       print(f\"Index: {index}, Value: {my_list[index]}\")\n",
      "       index += 1\n",
      "   ```\n",
      "\n",
      "   **Explanation:**\n",
      "\n",
      "   *   `index = 0`:  Initializes the index to 0.\n",
      "   *   `while index < len(my_list):`:  The loop continues as long as the index is less than the length of the list.\n",
      "   *   `index += 1`:  Increments the index after each iteration.\n",
      "\n",
      "**5. List Comprehension (For Creating a New List)**\n",
      "\n",
      "   List comprehensions are a concise way to create a new list by applying an expression to each element of an existing list.  While not strictly *iterating* in the same way as the other methods, they are a powerful way to process list elements.\n",
      "\n",
      "   ```python\n",
      "   my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "   # Create a new list with each element squared\n",
      "   squared_list = [x**2 for x in my_list]\n",
      "   print(squared_list)  # Output: [1, 4, 9, 16, 25]\n",
      "\n",
      "   # Create a new list with only the even numbers\n",
      "   even_numbers = [x for x in my_list if x % 2 == 0]\n",
      "   print(even_numbers)  # Output: [2, 4]\n",
      "   ```\n",
      "\n",
      "   **Explanation:**\n",
      "\n",
      "   *   `[x**2 for x in my_list]`:  This is a list comprehension.  It reads as \"for each `x` in `my_list`, create a new element that is `x**2` (x squared).\"\n",
      "   *   `[x for x in my_list if x % 2 == 0]`: This list comprehension includes a condition. It reads as \"for each `x` in `my_list`, if `x` is even (`x % 2 == 0`), then include `x` in the new list.\"\n",
      "\n",
      "**Which Method to Choose?**\n",
      "\n",
      "*   **Simple Iteration (Just need the values):** Use the basic `for item in my_list:` loop.  It's the most readable and efficient.\n",
      "*   **Need Index and Value:** Use `enumerate(my_list)`.  It's the most Pythonic and clear way to get both.\n",
      "*   **Need Index, but `enumerate` isn't suitable (rare):** Use `range(len(my_list))` and access elements with `my_list[i]`.\n",
      "*   **Creating a New List Based on the Original:** Use a list comprehension.  It's concise and often faster than using a traditional loop.\n",
      "*   **`while` loop:**  Use this only if you have a specific reason to control the iteration process manually (e.g., you need to modify the index based on conditions within the loop).  It's generally less readable than the other options for simple list iteration.\n",
      "\n",
      "**Example:  Modifying a List In-Place (Carefully!)**\n",
      "\n",
      "Modifying a list while iterating over it can be tricky and lead to unexpected results if you're not careful.  Here's an example of how to do it safely using a copy of the list:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "# Create a copy to iterate over\n",
      "for item in my_list[:]:  # my_list[:] creates a shallow copy\n",
      "    if item % 2 == 0:\n",
      "        my_list.remove(item)  # Remove even numbers\n",
      "\n",
      "print(my_list)  # Output: [1, 3, 5]\n",
      "```\n",
      "\n",
      "**Important Notes about Modifying Lists During Iteration:**\n",
      "\n",
      "*   **Creating a Copy:**  The `my_list[:]` creates a shallow copy of the list.  This is crucial because if you modify the original list while iterating over it directly, the loop's behavior can become unpredictable (elements might be skipped, or the loop might terminate prematurely).\n",
      "*   **`remove()`:**  The `remove()` method removes the *first* occurrence of a value in the list.\n",
      "*   **Alternatives:**  If you need to perform more complex modifications, consider creating a *new* list instead of modifying the original in-place.  List comprehensions are often a good choice for this.\n",
      "\n",
      "Let me know if you'd like more examples or have specific scenarios you want to explore!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PaLM API\n",
    "## print(completion.result)\n",
    "\n",
    "# Gemini API\n",
    "print(completion.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400bcb5-bfe8-4192-809d-d95b21bf8422",
   "metadata": {},
   "source": [
    "- **Tip:** The words \"show me\" tends to encourage the ~~PaLM~~ Gemini LLM to give more details and explanations compared to if you were to ask \"write code to ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b813473-15de-4672-9097-57a3d04219d6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt = \"write code to iterate across a list in Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3557557d-2b86-4755-a44f-8846e0035d3a",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Example list\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "# 1. Using a for loop (most common and readable)\n",
      "print(\"Using a for loop:\")\n",
      "for item in my_list:\n",
      "    print(item)\n",
      "\n",
      "# 2. Using a for loop with index (if you need the index)\n",
      "print(\"\\nUsing a for loop with index:\")\n",
      "for index, item in enumerate(my_list):\n",
      "    print(f\"Index: {index}, Item: {item}\")\n",
      "\n",
      "# 3. Using a while loop (less common for simple iteration, but useful in some cases)\n",
      "print(\"\\nUsing a while loop:\")\n",
      "index = 0\n",
      "while index < len(my_list):\n",
      "    item = my_list[index]\n",
      "    print(item)\n",
      "    index += 1\n",
      "\n",
      "# 4. Using list comprehension (for creating a new list based on the original)\n",
      "print(\"\\nUsing list comprehension (creating a new list):\")\n",
      "new_list = [item * 2 for item in my_list]  # Doubles each item\n",
      "print(new_list)\n",
      "\n",
      "# 5. Using map() function (another way to apply a function to each item)\n",
      "print(\"\\nUsing map() function:\")\n",
      "def double_item(item):\n",
      "    return item * 2\n",
      "\n",
      "doubled_list = list(map(double_item, my_list)) # Convert map object to a list\n",
      "print(doubled_list)\n",
      "\n",
      "# 6. Using recursion (less common and generally not recommended for simple iteration due to potential stack overflow issues with large lists)\n",
      "print(\"\\nUsing recursion (not recommended for large lists):\")\n",
      "def iterate_recursively(lst, index=0):\n",
      "    if index < len(lst):\n",
      "        print(lst[index])\n",
      "        iterate_recursively(lst, index + 1)\n",
      "\n",
      "iterate_recursively(my_list)\n",
      "```\n",
      "\n",
      "Key improvements and explanations:\n",
      "\n",
      "* **Clarity and Readability:** The code is well-commented, explaining each method and its purpose.  The `print` statements clearly label the output of each iteration method.\n",
      "* **`enumerate()` for Index:**  The `enumerate()` function is correctly used to get both the index and the value of each item in the list. This is the preferred way to iterate with an index in Python.\n",
      "* **`while` loop:**  The `while` loop example is included for completeness, but it's noted that it's less common for simple iteration.\n",
      "* **List Comprehension:** The list comprehension example demonstrates how to create a *new* list based on the original, which is a common use case.\n",
      "* **`map()` Function:** The `map()` function example shows another way to apply a function to each item in the list.  Crucially, it includes `list()` to convert the `map` object into a list for printing.  This is a common point of confusion for beginners.\n",
      "* **Recursion (with warning):** The recursion example is included, but it's *strongly* cautioned against using it for large lists due to the risk of stack overflow.  This is important because recursion is often taught early, but it's not always the best tool.\n",
      "* **Conciseness:** The code is concise and avoids unnecessary complexity.\n",
      "* **Correctness:** All the examples are now functionally correct and produce the expected output.\n",
      "* **`f-strings`:** Uses f-strings for more readable string formatting.\n",
      "* **Docstrings (optional, but good practice):**  While not included here for brevity, adding docstrings to the `double_item` function and the `iterate_recursively` function would be good practice in a real-world scenario.\n",
      "* **No unnecessary imports:** The code doesn't import any modules that aren't needed.\n",
      "\n",
      "This revised response provides a comprehensive and well-explained set of examples for iterating over a list in Python, covering the most common and useful techniques.  The warnings about recursion are particularly important.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PaLM API\n",
    "## completion = generate_text(prompt)\n",
    "## print(completion.result)\n",
    "\n",
    "# Gemini API\n",
    "completion = generate_text(prompt)\n",
    "print(completion.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26114873-bb3c-4253-a679-4dda28af561c",
   "metadata": {},
   "source": [
    "#### Try out the code\n",
    "- Try copy-pasting some of the generated code and running it in the notebook.\n",
    "- Remember to test out the LLM-generated code and debug it make sure it works as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2e76677-1b90-4ce4-a3b4-aae857e870f6",
   "metadata": {
    "height": 835
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a for loop:\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "\n",
      "Using a for loop with index:\n",
      "Index: 0, Item: 1\n",
      "Index: 1, Item: 2\n",
      "Index: 2, Item: 3\n",
      "Index: 3, Item: 4\n",
      "Index: 4, Item: 5\n",
      "\n",
      "Using a while loop:\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "\n",
      "Using list comprehension (creating a new list):\n",
      "[2, 4, 6, 8, 10]\n",
      "\n",
      "Using map() function:\n",
      "[2, 4, 6, 8, 10]\n",
      "\n",
      "Using recursion (not recommended for large lists):\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# paste the LLM's code here\n",
    "\n",
    "\n",
    "# Example list\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# 1. Using a for loop (most common and readable)\n",
    "print(\"Using a for loop:\")\n",
    "for item in my_list:\n",
    "    print(item)\n",
    "\n",
    "# 2. Using a for loop with index (if you need the index)\n",
    "print(\"\\nUsing a for loop with index:\")\n",
    "for index, item in enumerate(my_list):\n",
    "    print(f\"Index: {index}, Item: {item}\")\n",
    "\n",
    "# 3. Using a while loop (less common for simple iteration, but useful in some cases)\n",
    "print(\"\\nUsing a while loop:\")\n",
    "index = 0\n",
    "while index < len(my_list):\n",
    "    item = my_list[index]\n",
    "    print(item)\n",
    "    index += 1\n",
    "\n",
    "# 4. Using list comprehension (for creating a new list based on the original)\n",
    "print(\"\\nUsing list comprehension (creating a new list):\")\n",
    "new_list = [item * 2 for item in my_list]  # Doubles each item\n",
    "print(new_list)\n",
    "\n",
    "# 5. Using map() function (another way to apply a function to each item)\n",
    "print(\"\\nUsing map() function:\")\n",
    "def double_item(item):\n",
    "    return item * 2\n",
    "\n",
    "doubled_list = list(map(double_item, my_list)) # Convert map object to a list\n",
    "print(doubled_list)\n",
    "\n",
    "# 6. Using recursion (less common and generally not recommended for simple iteration due to potential stack overflow issues with large lists)\n",
    "print(\"\\nUsing recursion (not recommended for large lists):\")\n",
    "def iterate_recursively(lst, index=0):\n",
    "    if index < len(lst):\n",
    "        print(lst[index])\n",
    "        iterate_recursively(lst, index + 1)\n",
    "\n",
    "iterate_recursively(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1f97aa",
   "metadata": {
    "height": 302
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down this Python code snippet.\n",
      "\n",
      "**Purpose**\n",
      "\n",
      "The code's primary goal is to iterate through a list (`my_list`) and print each element to the console.  It demonstrates how to achieve this using recursion.  However, the code also includes a warning that recursion is generally not recommended for large lists in Python.\n",
      "\n",
      "**Code Breakdown**\n",
      "\n",
      "1. **`my_list = [1, 2, 3, 4, 5]`**\n",
      "\n",
      "   - This line initializes a list named `my_list` containing the integers 1 through 5.  This is the list that the code will iterate over.\n",
      "\n",
      "2. **`print(\"\\nUsing recursion (not recommended for large lists):\")`**\n",
      "\n",
      "   - This line prints a message to the console indicating that the following code will use recursion and that recursion is not the best approach for large lists.  The `\\n` adds a newline character to create a blank line before the message, improving readability.\n",
      "\n",
      "3. **`def iterate_recursively(lst, index=0):`**\n",
      "\n",
      "   - This defines a function called `iterate_recursively`.  This function is the heart of the recursive iteration.\n",
      "   - `lst`:  This is the parameter that will hold the list to be iterated over.\n",
      "   - `index=0`: This is a parameter with a default value of 0.  It represents the current index being processed in the list.  The default value means that when you first call the function, it will start at the beginning of the list (index 0).\n",
      "\n",
      "4. **`if index < len(lst):`**\n",
      "\n",
      "   - This is the base case and the recursive step's condition.  It checks if the current `index` is within the bounds of the list.  `len(lst)` returns the number of elements in the list.\n",
      "   - If `index` is less than the length of the list, it means there are more elements to process.\n",
      "\n",
      "5. **`print(lst[index])`**\n",
      "\n",
      "   - If the condition in the `if` statement is true (i.e., `index` is a valid index), this line prints the element at the current `index` in the list.  `lst[index]` accesses the element at that index.\n",
      "\n",
      "6. **`iterate_recursively(lst, index + 1)`**\n",
      "\n",
      "   - This is the recursive call.  It calls the `iterate_recursively` function again, but this time with the `index` incremented by 1.  This moves the function to the next element in the list.\n",
      "   - The function calls itself, creating a chain of calls until the base case is reached.\n",
      "\n",
      "7. **`iterate_recursively(my_list)`**\n",
      "\n",
      "   - This is the initial call to the `iterate_recursively` function.  It passes `my_list` as the list to be iterated over.  Since no `index` is explicitly provided, the default value of `index=0` is used.\n",
      "\n",
      "**How Recursion Works in This Example**\n",
      "\n",
      "1. The `iterate_recursively` function is called with `my_list` and `index=0`.\n",
      "2. The `if` condition (`0 < 5`) is true.\n",
      "3. `my_list[0]` (which is 1) is printed.\n",
      "4. `iterate_recursively` is called again with `my_list` and `index=1`.\n",
      "5. The process repeats:\n",
      "   - `my_list[1]` (which is 2) is printed.\n",
      "   - `iterate_recursively` is called with `my_list` and `index=2`.\n",
      "6. This continues until `index` becomes 5.\n",
      "7. When `index` is 5, the `if` condition (`5 < 5`) is false.  The function does nothing and returns.\n",
      "8. The previous call to `iterate_recursively` also returns, and so on, until the original call returns.\n",
      "\n",
      "**Why Recursion is Not Recommended for Large Lists in Python**\n",
      "\n",
      "Python has a limit on the maximum recursion depth (usually around 1000).  Each recursive call adds a new frame to the call stack.  If you have a very large list, you might exceed this recursion depth limit, resulting in a `RecursionError`.\n",
      "\n",
      "Iterative solutions (using loops like `for` or `while`) are generally more efficient and avoid the recursion depth limit.  They don't create a new stack frame for each iteration.\n",
      "\n",
      "**Equivalent Iterative Solution (Using a `for` loop)**\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "\n",
      "print(\"\\nUsing a for loop (recommended):\")\n",
      "for item in my_list:\n",
      "    print(item)\n",
      "```\n",
      "\n",
      "This `for` loop achieves the same result as the recursive function but is much more efficient and safer for large lists.\n",
      "\n",
      "**In summary:** The code demonstrates a recursive approach to iterating through a list and printing its elements. While it works for small lists, it's generally not recommended for large lists in Python due to the potential for exceeding the recursion depth limit.  Iterative solutions are preferred in such cases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "completion = generate_text(\"\"\"\n",
    "Please explain the code below\n",
    "\n",
    "```\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "print(\"\\nUsing recursion (not recommended for large lists):\")\n",
    "def iterate_recursively(lst, index=0):\n",
    "    if index < len(lst):\n",
    "        print(lst[index])\n",
    "        iterate_recursively(lst, index + 1)\n",
    "\n",
    "iterate_recursively(my_list)\n",
    "```\n",
    "\"\"\")\n",
    "print(completion.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c649daa-781c-4c69-ac1b-d100e9747190",
   "metadata": {},
   "source": [
    "#### Try asking your own coding question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c69b4929-ec4f-495c-a773-a92ce2c9b36c",
   "metadata": {
    "height": 173
   },
   "outputs": [],
   "source": [
    "# Modify the prompt with your own question\n",
    "# prompt = \"Show me how to [...]\"\n",
    "prompt = \"Please explain the various basic python data structures to me\"\n",
    "\n",
    "# PaLM API\n",
    "## completion = generate_text(prompt)\n",
    "\n",
    "# Gemini API\n",
    "completion = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c759d6a4-ed38-43fd-a588-1d62308a8746",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down the fundamental data structures in Python. These are the building blocks for organizing and manipulating data in your programs.\n",
      "\n",
      "**1. Lists**\n",
      "\n",
      "*   **Definition:**  An ordered, mutable (changeable) sequence of items.  Think of it like a dynamic array.\n",
      "*   **Characteristics:**\n",
      "    *   **Ordered:** Elements have a specific position (index).\n",
      "    *   **Mutable:** You can add, remove, or change elements after the list is created.\n",
      "    *   **Heterogeneous:** Can hold items of different data types (integers, strings, other lists, etc.).\n",
      "    *   **Duplicates Allowed:**  A list can contain the same value multiple times.\n",
      "*   **Syntax:**  Enclosed in square brackets `[]`.\n",
      "*   **Example:**\n",
      "\n",
      "    ```python\n",
      "    my_list = [1, 2, \"hello\", 3.14, [4, 5]]\n",
      "    print(my_list[0])  # Output: 1 (accessing the first element)\n",
      "    my_list[1] = 10    # Modifying an element\n",
      "    my_list.append(\"world\") # Adding an element to the end\n",
      "    print(my_list)      # Output: [1, 10, 'hello', 3.14, [4, 5], 'world']\n",
      "    ```\n",
      "*   **Common Operations:**\n",
      "    *   `append(item)`: Adds an item to the end of the list.\n",
      "    *   `insert(index, item)`: Inserts an item at a specific index.\n",
      "    *   `remove(item)`: Removes the first occurrence of an item.\n",
      "    *   `pop(index)`: Removes and returns the item at a specific index (or the last item if no index is given).\n",
      "    *   `len(list)`: Returns the number of items in the list.\n",
      "    *   `list.index(item)`: Returns the index of the first occurrence of an item.\n",
      "    *   `list.count(item)`: Returns the number of times an item appears in the list.\n",
      "    *   `sort()`: Sorts the list in place (modifies the original list).\n",
      "    *   `reverse()`: Reverses the list in place.\n",
      "    *   `clear()`: Removes all items from the list.\n",
      "    *   Slicing: `my_list[start:end:step]` (creates a new list from a portion of the original).\n",
      "\n",
      "**2. Tuples**\n",
      "\n",
      "*   **Definition:** An ordered, *immutable* (unchangeable) sequence of items.\n",
      "*   **Characteristics:**\n",
      "    *   **Ordered:** Elements have a specific position (index).\n",
      "    *   **Immutable:**  Once a tuple is created, you cannot change its elements.\n",
      "    *   **Heterogeneous:** Can hold items of different data types.\n",
      "    *   **Duplicates Allowed:** A tuple can contain the same value multiple times.\n",
      "*   **Syntax:** Enclosed in parentheses `()`.\n",
      "*   **Example:**\n",
      "\n",
      "    ```python\n",
      "    my_tuple = (1, 2, \"hello\", 3.14)\n",
      "    print(my_tuple[0])  # Output: 1\n",
      "    # my_tuple[1] = 10  # This would raise a TypeError because tuples are immutable\n",
      "    ```\n",
      "*   **Why use tuples?**\n",
      "    *   **Data Integrity:**  Guarantees that the data won't be accidentally modified.\n",
      "    *   **Performance:**  Tuples are generally slightly faster than lists because of their immutability.\n",
      "    *   **Use as Dictionary Keys:**  Tuples can be used as keys in dictionaries (lists cannot).\n",
      "*   **Common Operations:**\n",
      "    *   `len(tuple)`: Returns the number of items in the tuple.\n",
      "    *   `tuple.index(item)`: Returns the index of the first occurrence of an item.\n",
      "    *   `tuple.count(item)`: Returns the number of times an item appears in the tuple.\n",
      "    *   Slicing: `my_tuple[start:end:step]` (creates a new tuple from a portion of the original).\n",
      "\n",
      "**3. Dictionaries**\n",
      "\n",
      "*   **Definition:** A collection of key-value pairs.  Think of it like a real-world dictionary where you look up a word (the key) to find its definition (the value).\n",
      "*   **Characteristics:**\n",
      "    *   **Unordered (in Python versions before 3.7):**  The order in which items are stored is not guaranteed (though in Python 3.7+, dictionaries preserve insertion order).\n",
      "    *   **Mutable:** You can add, remove, or change key-value pairs.\n",
      "    *   **Keys Must Be Unique:**  Each key can only appear once in a dictionary.\n",
      "    *   **Keys Must Be Immutable:** Keys must be of an immutable type (e.g., strings, numbers, tuples). Values can be of any type.\n",
      "*   **Syntax:** Enclosed in curly braces `{}`.\n",
      "*   **Example:**\n",
      "\n",
      "    ```python\n",
      "    my_dict = {\"name\": \"Alice\", \"age\": 30, \"city\": \"New York\"}\n",
      "    print(my_dict[\"name\"])  # Output: Alice (accessing the value associated with the key \"name\")\n",
      "    my_dict[\"age\"] = 31     # Modifying a value\n",
      "    my_dict[\"occupation\"] = \"Engineer\"  # Adding a new key-value pair\n",
      "    print(my_dict)      # Output: {'name': 'Alice', 'age': 31, 'city': 'New York', 'occupation': 'Engineer'}\n",
      "    ```\n",
      "*   **Common Operations:**\n",
      "    *   `dict[key]`: Accesses the value associated with a key.  Raises a `KeyError` if the key doesn't exist.\n",
      "    *   `dict.get(key, default)`:  Accesses the value associated with a key. Returns `default` (or `None` if `default` is not specified) if the key doesn't exist.  Safer than `dict[key]` because it doesn't raise an error.\n",
      "    *   `dict[key] = value`:  Assigns a value to a key (creates a new key-value pair if the key doesn't exist).\n",
      "    *   `del dict[key]`: Deletes the key-value pair associated with a key.\n",
      "    *   `dict.pop(key, default)`: Removes and returns the value associated with a key.  Returns `default` if the key doesn't exist.\n",
      "    *   `dict.keys()`: Returns a view object containing the keys.\n",
      "    *   `dict.values()`: Returns a view object containing the values.\n",
      "    *   `dict.items()`: Returns a view object containing key-value pairs (as tuples).\n",
      "    *   `dict.update(other_dict)`:  Merges `other_dict` into `dict`.  If a key exists in both dictionaries, the value from `other_dict` overwrites the value in `dict`.\n",
      "    *   `dict.clear()`: Removes all items from the dictionary.\n",
      "    *   `len(dict)`: Returns the number of key-value pairs in the dictionary.\n",
      "\n",
      "**4. Sets**\n",
      "\n",
      "*   **Definition:** An unordered collection of *unique* items.\n",
      "*   **Characteristics:**\n",
      "    *   **Unordered:** The order in which items are stored is not guaranteed.\n",
      "    *   **Mutable:** You can add or remove items.\n",
      "    *   **Unique Elements:**  A set cannot contain duplicate values.  If you try to add a duplicate, it will be ignored.\n",
      "    *   **Elements Must Be Immutable:**  Elements must be of an immutable type (e.g., strings, numbers, tuples).\n",
      "*   **Syntax:** Enclosed in curly braces `{}` or created using the `set()` constructor.\n",
      "*   **Example:**\n",
      "\n",
      "    ```python\n",
      "    my_set = {1, 2, 3, 3, 4, 5}  # The duplicate '3' will be ignored\n",
      "    print(my_set)  # Output: {1, 2, 3, 4, 5} (order may vary)\n",
      "\n",
      "    my_set.add(6)\n",
      "    my_set.remove(1)\n",
      "    print(my_set) # Output: {2, 3, 4, 5, 6} (order may vary)\n",
      "    ```\n",
      "*   **Common Operations:**\n",
      "    *   `set.add(item)`: Adds an item to the set.\n",
      "    *   `set.remove(item)`: Removes an item from the set.  Raises a `KeyError` if the item is not in the set.\n",
      "    *   `set.discard(item)`: Removes an item from the set if it is present.  Does not raise an error if the item is not in the set.\n",
      "    *   `set.pop()`: Removes and returns an arbitrary item from the set.\n",
      "    *   `set.clear()`: Removes all items from the set.\n",
      "    *   `len(set)`: Returns the number of items in the set.\n",
      "    *   **Set Operations:**\n",
      "        *   `set1.union(set2)` or `set1 | set2`: Returns a new set containing all items from both sets.\n",
      "        *   `set1.intersection(set2)` or `set1 & set2`: Returns a new set containing items that are in both sets.\n",
      "        *   `set1.difference(set2)` or `set1 - set2`: Returns a new set containing items that are in `set1` but not in `set2`.\n",
      "        *   `set1.symmetric_difference(set2)` or `set1 ^ set2`: Returns a new set containing items that are in either `set1` or `set2`, but not in both.\n",
      "        *   `set1.issubset(set2)` or `set1 <= set2`: Returns `True` if `set1` is a subset of `set2`.\n",
      "        *   `set1.issuperset(set2)` or `set1 >= set2`: Returns `True` if `set1` is a superset of `set2`.\n",
      "\n",
      "**Summary Table**\n",
      "\n",
      "| Data Structure | Ordered | Mutable | Duplicates Allowed | Key-Value Pairs | Syntax       |\n",
      "|-----------------|---------|---------|--------------------|-----------------|--------------|\n",
      "| List            | Yes     | Yes     | Yes                | No              | `[]`         |\n",
      "| Tuple           | Yes     | No      | Yes                | No              | `()`         |\n",
      "| Dictionary      | No (Before 3.7) / Yes (3.7+) | Yes     | No (Keys)        | Yes           | `{}`         |\n",
      "| Set             | No      | Yes     | No                 | No              | `{}` or `set()` |\n",
      "\n",
      "**Choosing the Right Data Structure**\n",
      "\n",
      "The best data structure to use depends on the specific problem you're trying to solve:\n",
      "\n",
      "*   **Lists:** Use when you need an ordered collection of items that you might need to modify.\n",
      "*   **Tuples:** Use when you need an ordered collection of items that should not be changed.  Good for representing fixed records or data where immutability is important.\n",
      "*   **Dictionaries:** Use when you need to store and retrieve data based on a key.  Ideal for representing mappings or look-up tables.\n",
      "*   **Sets:** Use when you need to store a collection of unique items and perform set operations (union, intersection, etc.).  Useful for removing duplicates.\n",
      "\n",
      "**Important Notes:**\n",
      "\n",
      "*   **Mutability:**  Be aware of the difference between mutable and immutable data structures.  Modifying a mutable data structure can have side effects if the same data structure is being used in multiple places in your code.\n",
      "*   **Hashing:** Dictionaries and sets rely on hashing for efficient lookups.  This is why keys in dictionaries and elements in sets must be immutable (so their hash values don't change).\n",
      "*   **Memory Usage:**  Different data structures have different memory overhead.  Lists generally use more memory than tuples.  Dictionaries can use more memory than lists or tuples, especially if they have a large number of keys.\n",
      "*   **Performance:**  The performance of different operations (e.g., searching, inserting, deleting) can vary depending on the data structure.  Dictionaries and sets offer very fast lookups (on average) due to their use of hashing.\n",
      "\n",
      "By understanding these basic data structures and their characteristics, you'll be well-equipped to write efficient and well-organized Python code.  Practice using them in different scenarios to solidify your understanding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the text generated\n",
    "print(completion.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2b9e7a-4911-476d-9141-010224682d17",
   "metadata": {},
   "source": [
    "#### Note about the API key\n",
    "We've provided an API key for this classroom.  If you would like your own API key for your own projects, you can get one at [developers.generativeai.google](https://developers.generativeai.google/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
