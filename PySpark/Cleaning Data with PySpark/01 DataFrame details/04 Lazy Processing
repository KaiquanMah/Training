Using lazy processing
Lazy processing operations will usually return in about the same amount of time regardless of the actual quantity of data. Remember that this is due to Spark not performing any transformations until an action is requested.
For this exercise, we'll be defining a Data Frame (aa_dfw_df) and add a couple transformations. Note the amount of time required for the transformations to complete when defined vs when the data is actually queried. These differences may be short, but they will be noticeable. When working with a full Spark cluster with larger quantities of data the difference will be more apparent.


Load the Data Frame.
Add the transformation for F.lower() to the Destination Airport column.
Drop the Destination Airport column from the Data Frame aa_dfw_df. Note the time for these operations to complete.
Show the Data Frame, noting the time difference for this action to complete.


# Load the CSV file
aa_dfw_df = spark.read.format('csv').options(Header=True).load('AA_DFW_2018.csv.gz')

# Add the airport column using the F.lower() method
aa_dfw_df = aa_dfw_df.withColumn('airport', F.lower(aa_dfw_df['Destination Airport']))

# Drop the Destination Airport column
aa_dfw_df = aa_dfw_df.drop(aa_dfw_df['Destination Airport'])

# Show the DataFrame
aa_dfw_df.show()


<script.py> output:
    +-----------------+-------------+-----------------------------+-------+
    |Date (MM/DD/YYYY)|Flight Number|Actual elapsed time (Minutes)|airport|
    +-----------------+-------------+-----------------------------+-------+
    |       01/01/2018|         0005|                          498|    hnl|
    |       01/01/2018|         0007|                          501|    ogg|
    |       01/01/2018|         0043|                            0|    dtw|
    |       01/01/2018|         0051|                          100|    stl|
    |       01/01/2018|         0075|                          147|    dca|
    |       01/01/2018|         0096|                           92|    stl|
    |       01/01/2018|         0103|                          227|    sjc|
    |       01/01/2018|         0119|                          517|    ogg|
    |       01/01/2018|         0123|                          489|    hnl|
    |       01/01/2018|         0128|                          141|    mco|
    |       01/01/2018|         0132|                          201|    ewr|
    |       01/01/2018|         0140|                          215|    sjc|
    |       01/01/2018|         0174|                          140|    rdu|
    |       01/01/2018|         0190|                           68|    sat|
    |       01/01/2018|         0200|                          215|    sfo|
    |       01/01/2018|         0209|                          169|    mia|
    |       01/01/2018|         0217|                          178|    las|
    |       01/01/2018|         0229|                          534|    koa|
    |       01/01/2018|         0244|                          115|    cvg|
    |       01/01/2018|         0262|                          159|    mia|
    +-----------------+-------------+-----------------------------+-------+
    only showing top 20 rows

Great! You've just seen how lazy processing works in action. Remember when working with Spark that no transformations take effect until you apply an action. This can be confusing at times, but is one of the underpinnings of Spark's power.

