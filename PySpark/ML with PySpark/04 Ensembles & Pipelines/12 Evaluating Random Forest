Evaluating Random Forest
In this final exercise you'll be evaluating the results of cross-validation on a Random Forest model.

The following have already been created:
cv - a cross-validator which has already been fit to the training data
evaluator — a BinaryClassificationEvaluator object and
flights_test — the testing data.



Retrieve a list of average AUC metrics across all models in the parameter grid.
What is the average AUC for the best model? This will be the largest AUC in the list.
Find the value of the maxDepth and featureSubsetStrategy parameters for the best model.
Calculate the AUC for the best model predictions on the testing data.


# Average AUC for each parameter combination in grid
avg_auc = cv.avgMetrics

In [2]: avg_auc
Out[2]: 
[0.61550451929848,
 0.661275302749083,
 0.6832959983649716,
 0.6790399103856084,
 0.6404890400309002,
 0.6659871420567183,
 0.6808977119243277,
 0.6867946590518151,
 0.6414270561540629,
 0.6653385916148042,
 0.6832494433718275,
 0.6851695159338953,
 0.6414270561540629,
 0.6653385916148042,
 0.6832494433718275,
 0.6851695159338953]
 
 
 
 
# Average AUC for the best model
#What is the average AUC for the best model? This will be the largest AUC in the list.
best_model_auc =  max(avg_auc)

# What's the optimal parameter value?
opt_max_depth = cv.bestModel.explainParam('maxDepth')
opt_feat_substrat = cv.bestModel.explainParam('featureSubsetStrategy')

# AUC for best model on testing data
best_auc = evaluator.evaluate(cv.transform(flights_test))



Optimized Random Forest > Random Forest > Decision Tree
