Shell pipelines to Bash scripts
In this exercise, you are working as a sports analyst for a Bulgarian soccer league. You have received some data on the results of the grand final from 1932 in a csv file. The file is comma-delimited in the format Year,Winner,Winner Goals which lists the year of the match, the team that won and how many goals the winning team scored, such as 1932,Arda,4.
Your job is to create a Bash script from a shell piped command which will aggregate to see how many times each team has won.
Don't worry about the tail -n +2 part, this just ensures we don't aggregate the CSV headers!


Create a single-line pipe to cat the file, cut out the relevant field and aggregate (sort & uniq -c will help!) based on winning team.
Save your script and run from the console.
#!/usr/bash

# Create a single-line pipe
# go through the data set
# split on spaces
# give me the 2nd col of each line
# dont aggregate the CSV headers
# sort
# unique count
cat soccer_scores.csv | cut -d "," -f 2 | tail -n +2 | sort | uniq -c

# Now save and run!




repl:~/workspace$ bash script.sh
     13 Arda
      8 Beroe
      9 Botev
      8 Cherno
     17 Dunav
     15 Etar
      4 Levski
      1 Lokomotiv


Nice work! You have now turned a very manual pipe into a succinct Bash script. This could now easily form part of a data analytics pipeline without you needing to manually input the pipe each time. Let's practice this some more with other command-line utilities and pipes.

