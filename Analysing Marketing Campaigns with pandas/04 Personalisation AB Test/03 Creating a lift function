Creating a lift function
Lift can be calculated by calculating the difference between the treatment effect (or the mean) of the treatment compared to the treatment effect of the control divided by the treatment effect of the control. The formula for lift can be found below:
Treatment conversion rate - Control conversion rateControl conversion rate
The result is the percent difference between the control and treatment.
In this exercise, you will create a function to automate the process of calculating lift. Many marketing teams run tests constantly. The more that you can automate the parts of the process that occur within every test, the more time you will have to do more interesting analyses.

Calculate the mean of a and b using np.mean().
Use a_mean and b_mean to calculate the lift of the treatment.
Print the results of the lift() function you created using the control and personalization variables.

def lift(a,b):
    # Calcuate the mean of a and b
    a_mean = np.mean(a)
    b_mean = np.mean(b)
    
    # Calculate the lift using a_mean and b_mean
    lift = (b_mean-a_mean)/a_mean
  
    return str(round(lift*100, 2)) + '%'
  
# Print lift() with control and personalization as inputs
print(lift(control, personalization))

<script.py> output:
    38.85%
    
As you can see, there's a large lift, but are your results statistically significant? You will find out in the next exercise.













Evaluating statistical significance
Now that you know the personalization variant outperformed the control, it's time for you to determine whether the result is statistically significant. Remember, statistical significance is vital to understanding whether a test showed a positive result by chance or if it is reflective of a true difference between the variants. This will enable your marketing team to make an informed choice about whether to roll out the feature or not.
Test out the stats.ttest_ind() using control and personalization as the inputs.

Is the difference between the control and personalization statistically significant?
Yes, the results are statistically significant with p = 0.510.
No, the results are not statistically significant with p = 0.510.
No, the results are not statistically significant with p = 0.006.

#yes Yes, the results are statistically significant with p = 0.006.
The personalization results are highly statistically significant. In the next lesson, you will explore whether that holds up across all demographics.

stats.ttest_ind(control, personalization)
In [1]: stats.ttest_ind(control, personalization)
Out[1]: Ttest_indResult(statistic=-2.7343299447505074, pvalue=0.006451487844694175)


