Using geom_smooth()
Our logistic regression model can be visualized in the data space by overlaying the appropriate logistic curve. We can use the geom_smooth() function to do this. Recall that geom_smooth() takes a method argument that allows you to specify what type of smoother you want to see. In our case, we need to specify that we want to use the glm() function to do the smoothing.
However we also need to tell the glm() function which member of the GLM family we want to use. To do this, we will pass the family argument to glm() as a list using the method.args argument to geom_smooth(). This mechanism is common in R, and allows one function to pass a list of arguments to another function.

Create a scatterplot called data_space for Acceptance as a function of GPA. Use geom_jitter() to apply a small amount of jitter to the points in the y-direction. Set width = 0 and height = 0.05 in geom_jitter().
Use geom_smooth() to add the logistic regression line to data_space by specifying the method and method.args arguments to fit a logistic glm.

# scatterplot with jitter
data_space <- ggplot(MedGPA, aes(x=GPA, y=Acceptance)) + 
  geom_jitter(width=0, height=0.05, alpha = .5)

# add logistic curve
data_space +
  geom_smooth(method="glm",
              se=FALSE,
              method.args=list(family="binomial"))









Using bins
One of the difficulties in working with a binary response variable is understanding how it "changes." The response itself (y) is either 0 or 1, while the fitted values (y^)—which are interpreted as probabilities—are between 0 and 1. But if every medical school applicant is either admitted or not, what does it mean to talk about the probability of being accepted?
What we'd like is a larger sample of students, so that for each GPA value (e.g. 3.54) we had many observations (say n), and we could then take the average of those n observations to arrive at the estimated probability of acceptance. Unfortunately, since the explanatory variable is continuous, this is hopeless—it would take an infinite amount of data to make these estimates robust.
Instead, what we can do is put the observations into bins based on their GPA value. Within each bin, we can compute the proportion of accepted students, and we can visualize our model as a smooth logistic curve through those binned values.
We have created a data.frame called MedGPA_binned that aggregates the original data into separate bins for each 0.25 of GPA. It also contains the fitted values from the logistic regression model.

Here we are plotting y as a function of x, where that function is
y = exp(β^0 + β^1⋅x) / [1+exp(β^0 + β^1⋅x)]
Note that the left hand side is the expected probability y of being accepted to medical school.

Create a scatterplot called data_space for acceptance_rate as a function of mean_GPA using the binned data in MedGPA_binned. Use geom_line() to connect the points.
Augment the model mod. Create predictions on the scale of the response variable by using the type.predict argument.
Use geom_line() to illustrate the model through the fitted values.


> glimpse(MedGPA_binned)
Observations: 6
Variables: 3
$ bin             <fct> "[2.72,3.3]", "(3.3,3.44]", "(3.44,3.58]", "(3.58,3...
$ mean_GPA        <dbl> 3.110000, 3.388000, 3.536250, 3.651111, 3.785556, 3...
$ acceptance_rate <dbl> 0.2000000, 0.2000000, 0.7500000, 0.3333333, 0.88888...


> MedGPA_binned
# A tibble: 6 x 3
  bin         mean_GPA acceptance_rate
  <fct>          <dbl>           <dbl>
1 [2.72,3.3]      3.11           0.2  
2 (3.3,3.44]      3.39           0.2  
3 (3.44,3.58]     3.54           0.75 
4 (3.58,3.7]      3.65           0.333
5 (3.7,3.87]      3.79           0.889
6 (3.87,3.97]     3.91           1

> head(augment(mod))
  Acceptance  GPA    .fitted   .se.fit     .resid       .hat   .sigma
1          0 3.62  0.5375777 0.3394241 -1.4125389 0.02681777 1.026465
2          1 3.84  1.7374942 0.5509012  0.5693601 0.03862222 1.042388
3          1 3.23 -1.5895470 0.6121296  1.8842565 0.05274316 1.010435
4          1 3.69  0.9193694 0.3859177  0.8192601 0.03035531 1.039108
5          1 3.38 -0.7714221 0.4302574  1.5175443 0.04002682 1.023193
6          1 3.72  1.0829943 0.4133604  0.7636877 0.03228887 1.039936
      .cooksd .std.resid
1 0.024236585 -1.4318691
2 0.003676503  0.5806842
3 0.144056249  1.9360035
4 0.006437280  0.8319850
5 0.046970726  1.5488588
6 0.005837044  0.7763239



# binned points and line
data_space <- MedGPA_binned %>%
  ggplot(aes(x= mean_GPA, y=acceptance_rate)) +
  geom_point() +
  geom_line()

# augmented model
MedGPA_plus <- augment(mod, type.predict="response")

# logistic model on probability scale
data_space +
  geom_line(data = MedGPA_plus, aes(x=GPA, y= .fitted), color = "red")
  

