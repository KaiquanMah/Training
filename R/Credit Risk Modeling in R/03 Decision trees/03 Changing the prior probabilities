As mentioned in the video, you can also change the prior probabilities to obtain a decision tree. This is an indirect way of adjusting the importance of misclassifications for each class. You can specify another argument inside rpart() to include prior probabities. The argument you are looking for has the following form
parms = list(prior=c(non_default_proportion, default_proportion))
The rpart package is now already loaded in your workspace.


Change the code provided such that a decision tree is constructed , including the argument parms and changing the proportion of non-defaults to 0.7, and of defaults to 0.3 (they should always sum up to 1). Additionally, include control = rpart.control(cp = 0.001) as well.
Plot the decision tree using the function plot and the tree object name. Add a second argument "uniform=TRUE" to get equal-sized branches.
Add labels to the tree using function text() and the decision tree object name.

> c(0.7, 0.3)
[1] 0.7 0.3

> prior=c(0.7, 0.3)
> prior
[1] 0.7 0.3

> list(prior=c(0.7, 0.3))
$prior
[1] 0.7 0.3



# Change the code below such that a tree is constructed with adjusted prior probabilities.
tree_prior <- rpart(loan_status ~ ., method = "class",data = training_set,control = rpart.control(cp = 0.001),parms = list(prior=c(0.7, 0.3)))

# Plot the decision tree
plot(tree_prior, uniform=TRUE)

# Add labels to the decision tree
text(tree_prior)
