Assessing simple linear model fit
Recall that the coefficient of determination (R2), can be computed as
R^2 = 1 − SSE/SST = 1 − Var(e)/Var(y),
where e is the vector of residuals and y is the response variable. This gives us the interpretation of R2 as the percentage of the variability in the response that is explained by the model, since the residuals are the part of that variability that remains unexplained by the model.

The bdims_tidy data frame is the result of augment()-ing the bdims data frame with the mod for wgt as a function of hgt.
Use the summary() function to view the full results of mod.
Use the bdims_tidy data frame to compute the R2 of mod manually using the formula above, by computing the ratio of the variance of the residuals to the variance of the response variable.


> bdims_tidy
# A tibble: 507 x 9
     wgt   hgt .fitted .se.fit  .resid    .hat .sigma   .cooksd .std.resid
   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>  <dbl>     <dbl>      <dbl>
 1  65.6  174     72.1   0.432  -6.45  0.00215   9.31 0.000520     -0.694 
 2  71.8  175.    73.4   0.452  -1.58  0.00236   9.32 0.0000340    -0.170 
 3  80.7  194.    91.9   1.07  -11.2   0.0131    9.30 0.00976      -1.21  
 4  72.6  186.    84.8   0.792 -12.2   0.00724   9.30 0.00628      -1.31  
 5  78.8  187.    85.5   0.818  -6.69  0.00773   9.31 0.00203      -0.721 
 6  74.8  182.    79.7   0.615  -4.89  0.00437   9.31 0.000607     -0.526 
 7  86.4  184     82.2   0.700   4.17  0.00566   9.32 0.000575      0.449 
 8  78.4  184.    82.7   0.718  -4.34  0.00596   9.32 0.000655     -0.468 
 9  62    175     73.1   0.447 -11.1   0.00230   9.30 0.00164      -1.19  
10  81.6  184     82.2   0.700  -0.630 0.00566   9.32 0.0000131    -0.0679
# ... with 497 more rows





# View model summary
summary(mod)
> summary(mod)

Call:
lm(formula = wgt ~ hgt, data = bdims)

Residuals:
    Min      1Q  Median      3Q     Max 
-18.743  -6.402  -1.231   5.059  41.103 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -105.01125    7.53941  -13.93   <2e-16 ***
hgt            1.01762    0.04399   23.14   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 9.308 on 505 degrees of freedom
Multiple R-squared:  0.5145,	Adjusted R-squared:  0.5136 
F-statistic: 535.2 on 1 and 505 DF,  p-value: < 2.2e-16


# Compute R-squared
bdims_tidy %>%
  summarize(var_y = var(wgt), var_e = var(.resid)) %>%
  mutate(R_squared = 1- (var_e/var_y))
# A tibble: 1 x 3
  var_y var_e R_squared
  <dbl> <dbl>     <dbl>
1  178.  86.5     0.515  

This means that 51.4% of the variability in weight is explained by height.







Interpretation of R^2
The R2 reported for the regression model for poverty rate of U.S. counties in terms of high school graduation rate is 0.464.
lm(formula = poverty ~ hs_grad, data = countyComplete) %>%
  summary()
How should this result be interpreted?

#yes 46.4% of the variability in poverty rate among U.S. counties can be explained by high school graduation rate.

46.4% of the variability in high school graduate rate among U.S. counties can be explained by poverty rate.
This model is 46.4% effective.
The correlation between poverty rate and high school graduation rate is 0.464.









Linear vs. average
The R2 gives us a numerical measurement of the strength of fit relative to a null model based on the average of the response variable:
y^null=y¯

This model has an R2 of zero because SSE=SST. That is, since the fitted values (y^null) are all equal to the average (y¯), the residual for each observation is the distance between that observation and the mean of the response. Since we can always fit the null model, it serves as a baseline against which all other models will be compared.
In the graphic, we visualize the residuals for the null model (mod_null at left) vs. the simple linear regression model (mod_hgt at right) with height as a single explanatory variable. Try to convince yourself that, if you squared the lengths of the grey arrows on the left and summed them up, you would get a larger value than if you performed the same operation on the grey arrows on the right.
It may be useful to preview these augment()-ed data frames with glimpse():
glimpse(mod_null)
glimpse(mod_hgt)

Compute the sum of the squared residuals (SSE) for the null model mod_null.
Compute the sum of the squared residuals (SSE) for the regression model mod_hgt.

> glimpse(mod_null)
Observations: 507
Variables: 32
$ bia.di     <dbl> 42.9, 43.7, 40.1, 44.3, 42.5, 43.3, 43.5, 44.4, 43.5, 42...
$ bii.di     <dbl> 26.0, 28.5, 28.2, 29.9, 29.9, 27.0, 30.0, 29.8, 26.5, 28...
$ bit.di     <dbl> 31.5, 33.5, 33.3, 34.0, 34.0, 31.5, 34.0, 33.2, 32.1, 34...
$ che.de     <dbl> 17.7, 16.9, 20.9, 18.4, 21.5, 19.6, 21.9, 21.8, 15.5, 22...
$ che.di     <dbl> 28.0, 30.8, 31.7, 28.2, 29.4, 31.3, 31.7, 28.8, 27.5, 28...
$ elb.di     <dbl> 13.1, 14.0, 13.9, 13.9, 15.2, 14.0, 16.1, 15.1, 14.1, 15...
$ wri.di     <dbl> 10.4, 11.8, 10.9, 11.2, 11.6, 11.5, 12.5, 11.9, 11.2, 12...
$ kne.di     <dbl> 18.8, 20.6, 19.7, 20.9, 20.7, 18.8, 20.8, 21.0, 18.9, 21...
$ ank.di     <dbl> 14.1, 15.1, 14.1, 15.0, 14.9, 13.9, 15.6, 14.6, 13.2, 15...
$ sho.gi     <dbl> 106.2, 110.5, 115.1, 104.5, 107.5, 119.8, 123.5, 120.4, ...
$ che.gi     <dbl> 89.5, 97.0, 97.5, 97.0, 97.5, 99.9, 106.9, 102.5, 91.0, ...
$ wai.gi     <dbl> 71.5, 79.0, 83.2, 77.8, 80.0, 82.5, 82.0, 76.8, 68.5, 77...
$ nav.gi     <dbl> 74.5, 86.5, 82.9, 78.8, 82.5, 80.1, 84.0, 80.5, 69.0, 81...
$ hip.gi     <dbl> 93.5, 94.8, 95.0, 94.0, 98.5, 95.3, 101.0, 98.0, 89.5, 9...
$ thi.gi     <dbl> 51.5, 51.5, 57.3, 53.0, 55.4, 57.5, 60.9, 56.0, 50.0, 59...
$ bic.gi     <dbl> 32.5, 34.4, 33.4, 31.0, 32.0, 33.0, 42.4, 34.1, 33.0, 36...
$ for.gi     <dbl> 26.0, 28.0, 28.8, 26.2, 28.4, 28.0, 32.3, 28.0, 26.0, 29...
$ kne.gi     <dbl> 34.5, 36.5, 37.0, 37.0, 37.7, 36.6, 40.1, 39.2, 35.5, 38...
$ cal.gi     <dbl> 36.5, 37.5, 37.3, 34.8, 38.6, 36.1, 40.3, 36.7, 35.0, 38...
$ ank.gi     <dbl> 23.5, 24.5, 21.9, 23.0, 24.4, 23.5, 23.6, 22.5, 22.0, 22...
$ wri.gi     <dbl> 16.5, 17.0, 16.9, 16.6, 18.0, 16.9, 18.8, 18.0, 16.5, 16...
$ age        <int> 21, 23, 28, 23, 22, 21, 26, 27, 23, 21, 23, 22, 20, 26, ...
$ wgt        <dbl> 65.6, 71.8, 80.7, 72.6, 78.8, 74.8, 86.4, 78.4, 62.0, 81...
$ hgt        <dbl> 174.0, 175.3, 193.5, 186.5, 187.2, 181.5, 184.0, 184.5, ...
$ sex        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...
$ .fitted    <dbl> 69.14753, 69.14753, 69.14753, 69.14753, 69.14753, 69.147...
$ .se.fit    <dbl> 0.5927061, 0.5927061, 0.5927061, 0.5927061, 0.5927061, 0...
$ .resid     <dbl> -3.5475345, 2.6524655, 11.5524655, 3.4524655, 9.6524655,...
$ .hat       <dbl> 0.001972387, 0.001972387, 0.001972387, 0.001972387, 0.00...
$ .sigma     <dbl> 13.35803, 13.35845, 13.34906, 13.35808, 13.35205, 13.356...
$ .cooksd    <dbl> 1.399179e-04, 7.822033e-05, 1.483780e-03, 1.325192e-04, ...
$ .std.resid <dbl> -0.26607983, 0.19894594, 0.86648293, 0.25894926, 0.72397...


> glimpse(mod_hgt)
Observations: 507
Variables: 32
$ bia.di     <dbl> 42.9, 43.7, 40.1, 44.3, 42.5, 43.3, 43.5, 44.4, 43.5, 42...
$ bii.di     <dbl> 26.0, 28.5, 28.2, 29.9, 29.9, 27.0, 30.0, 29.8, 26.5, 28...
$ bit.di     <dbl> 31.5, 33.5, 33.3, 34.0, 34.0, 31.5, 34.0, 33.2, 32.1, 34...
$ che.de     <dbl> 17.7, 16.9, 20.9, 18.4, 21.5, 19.6, 21.9, 21.8, 15.5, 22...
$ che.di     <dbl> 28.0, 30.8, 31.7, 28.2, 29.4, 31.3, 31.7, 28.8, 27.5, 28...
$ elb.di     <dbl> 13.1, 14.0, 13.9, 13.9, 15.2, 14.0, 16.1, 15.1, 14.1, 15...
$ wri.di     <dbl> 10.4, 11.8, 10.9, 11.2, 11.6, 11.5, 12.5, 11.9, 11.2, 12...
$ kne.di     <dbl> 18.8, 20.6, 19.7, 20.9, 20.7, 18.8, 20.8, 21.0, 18.9, 21...
$ ank.di     <dbl> 14.1, 15.1, 14.1, 15.0, 14.9, 13.9, 15.6, 14.6, 13.2, 15...
$ sho.gi     <dbl> 106.2, 110.5, 115.1, 104.5, 107.5, 119.8, 123.5, 120.4, ...
$ che.gi     <dbl> 89.5, 97.0, 97.5, 97.0, 97.5, 99.9, 106.9, 102.5, 91.0, ...
$ wai.gi     <dbl> 71.5, 79.0, 83.2, 77.8, 80.0, 82.5, 82.0, 76.8, 68.5, 77...
$ nav.gi     <dbl> 74.5, 86.5, 82.9, 78.8, 82.5, 80.1, 84.0, 80.5, 69.0, 81...
$ hip.gi     <dbl> 93.5, 94.8, 95.0, 94.0, 98.5, 95.3, 101.0, 98.0, 89.5, 9...
$ thi.gi     <dbl> 51.5, 51.5, 57.3, 53.0, 55.4, 57.5, 60.9, 56.0, 50.0, 59...
$ bic.gi     <dbl> 32.5, 34.4, 33.4, 31.0, 32.0, 33.0, 42.4, 34.1, 33.0, 36...
$ for.gi     <dbl> 26.0, 28.0, 28.8, 26.2, 28.4, 28.0, 32.3, 28.0, 26.0, 29...
$ kne.gi     <dbl> 34.5, 36.5, 37.0, 37.0, 37.7, 36.6, 40.1, 39.2, 35.5, 38...
$ cal.gi     <dbl> 36.5, 37.5, 37.3, 34.8, 38.6, 36.1, 40.3, 36.7, 35.0, 38...
$ ank.gi     <dbl> 23.5, 24.5, 21.9, 23.0, 24.4, 23.5, 23.6, 22.5, 22.0, 22...
$ wri.gi     <dbl> 16.5, 17.0, 16.9, 16.6, 18.0, 16.9, 18.8, 18.0, 16.5, 16...
$ age        <int> 21, 23, 28, 23, 22, 21, 26, 27, 23, 21, 23, 22, 20, 26, ...
$ wgt        <dbl> 65.6, 71.8, 80.7, 72.6, 78.8, 74.8, 86.4, 78.4, 62.0, 81...
$ hgt        <dbl> 174.0, 175.3, 193.5, 186.5, 187.2, 181.5, 184.0, 184.5, ...
$ sex        <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...
$ .fitted    <dbl> 72.05406, 73.37697, 91.89759, 84.77427, 85.48661, 79.686...
$ .se.fit    <dbl> 0.4320546, 0.4520060, 1.0667332, 0.7919264, 0.8183471, 0...
$ .resid     <dbl> -6.4540648, -1.5769666, -11.1975919, -12.1742745, -6.686...
$ .hat       <dbl> 0.002154570, 0.002358152, 0.013133942, 0.007238576, 0.00...
$ .sigma     <dbl> 9.312824, 9.317005, 9.303732, 9.301360, 9.312471, 9.3147...
$ .cooksd    <dbl> 5.201807e-04, 3.400330e-05, 9.758463e-03, 6.282074e-03, ...
$ .std.resid <dbl> -0.69413418, -0.16961994, -1.21098084, -1.31269063, -0.7...


# Compute SSE for null model
mod_null %>%
  summarize(SSE = var(.resid))
# A tibble: 1 x 1
    SSE
  <dbl>
1  178.


# Compute SSE for regression model
mod_hgt %>%
  summarize(SSE = var(.resid))
# A tibble: 1 x 1
    SSE
  <dbl>
1  86.5  


